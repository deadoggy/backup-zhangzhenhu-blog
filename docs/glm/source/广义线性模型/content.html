<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>7. 广义线性模型 &mdash; 张振虎的博客 张振虎 文档</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
    <link rel="canonical" href="https://zhangzhenhu.github.io/blog/glm/source/广义线性模型/content.html" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/translations.js"></script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"macros": {"RR": "{\\bf R}", "bold": ["{\\bf #1}", 1], "KL": ["{D_\\textrm{KL}\\left ( #1 \\| #2 \\right )}", 2], "EE": ["{\\mathbb{E}_{#1} \\left [ #2 \\right ]}", 2, ""], "scalemath": ["{\\scalebox{#1}{\\mbox{\\ensuremath{\\displaystyle #2}}}}", 2], "ind": ["{\\perp\\!\\!\\!\\!\\perp}"]}}}</script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" />
    <link rel="next" title="8. 参数估计" href="estimate.html" />
    <link rel="prev" title="6. 线性回归模型" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> 张振虎的博客
          </a>
              <div class="version">
                acmtiger@outlook.com
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">目录:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">广义线性模型</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html">1. 概率基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id2">1.1. 概率模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id3">1.1.1. 概率律</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id4">1.1.2. 离散模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id5">1.1.3. 连续模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id6">1.2. 条件概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id7">1.3. 联合概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id8">1.4. 全概率与贝叶斯定理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id9">1.5. 独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id10">1.6. 随机变量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id11">1.6.1. 离散随机变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id12">1.6.2. 连续随机变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id13">1.6.3. 累积分布函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id14">1.6.4. 随机变量的函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id15">1.6.5. 期望与方差</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id16">1.7. 边缘化</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id17">1.8. 常见概率分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#ch-basic-bernoulli">1.8.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id19">1.8.2. 二项式分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id20">1.8.3. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id21">1.8.4. 多项式分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id22">1.8.5. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id23">1.8.6. 卡方分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#t">1.8.7. t分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#f">1.8.8. F分布</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html">2. 最大似然估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#ch-liklihood">2.1. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id3">2.2. 伯努利分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id4">2.3. 类别分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#ch-2-gaussian-ml">2.4. 高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id6">2.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html">3. 推断与检验</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id2">3.1. 统计量和充分统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-sample-distribution">3.2. 抽样分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-sample-distribution-normal">3.2.1. 正态分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#t">3.2.2. 学生t分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id5">3.2.3. 卡方分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id6">3.3. 极限理论</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id7">3.3.1. 马尔可夫和切比雪夫不等式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id8">3.3.2. 弱大数定律</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id9">3.3.3. 依概率收敛</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-clt">3.3.4. 中心极限定理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id11">3.3.5. 强大数定理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id12">3.4. 似然估计量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id13">3.4.1. 估计量的偏差与方差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-2-fisher-information">3.4.2. 信息量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-2-mle-estimator">3.4.3. 最大似然估计的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-influence-test-interval">3.5. 置信区间</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#z">3.5.1. 均值参数的 Z 区间估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id18">3.5.2. 均值参数的 T 区间估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id19">3.5.3. 方差参数的区间估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-influence-test-test">3.6. 简单假设检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id22">3.6.1. Z检验</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id23">3.6.2. T检验</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id24">3.6.3. 卡方检验</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html">4. 贝叶斯估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id2">4.1. 贝叶斯估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id3">4.1.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id4">4.1.2. 类别分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id5">4.2. 最大后验估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id6">4.2.1. 伯努利变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id7">4.2.2. 类别变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id8">4.3. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html">5. 指数族</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#ch-24-1">5.1. 指数族的定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id3">5.1.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id4">5.1.2. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id5">5.1.3. 泊松分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id6">5.1.4. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id7">5.1.5. 其它常见指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#ch-24-moments">5.2. 指数族的期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id9">5.3. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#kl">5.4. 最大似然估计与KL散度的关系</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html">6. 线性回归模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id2">6.1. 最小二乘</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id3">6.1.1. 最小误差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id4">6.1.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id5">6.2. 线性回归的概率解释</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id6">6.2.1. 高斯假设</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id7">6.2.2. 参数估计</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">7. 广义线性模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">7.1. 指数族分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">7.1.1. 自然指数族</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">7.1.2. 示例：高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id5">7.1.3. 示例：伯努利分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id6">7.2. 广义线性模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">7.3. 例子</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="estimate.html">8. 参数估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="estimate.html#ch-glm-estimate">8.1. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="estimate.html#id3">8.2. 泰勒级数</a></li>
<li class="toctree-l3"><a class="reference internal" href="estimate.html#id4">8.3. 梯度下降法</a></li>
<li class="toctree-l3"><a class="reference internal" href="estimate.html#id6">8.4. 牛顿法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="estimate.html#id7">8.4.1. 算法推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="estimate.html#id8">8.4.2. 标准连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="estimate.html#id9">8.4.3. 迭代初始值的设定</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="estimate.html#irls">8.5. 迭代重加权最小二乘(IRLS)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="estimate.html#id10">8.5.1. 算法推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="estimate.html#id11">8.5.2. 算法过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="estimate.html#id12">8.6. 估计量的标准误差</a></li>
<li class="toctree-l3"><a class="reference internal" href="estimate.html#ch-glm-estimate-phi">8.7. 分散参数的估计</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html">9. 模型评估</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#id2">9.1. 拟合优度</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#id3">9.1.1. 嵌套模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#likelihood-ratio">9.1.2. 对数似然比(Likelihood ratio)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#deviance">9.1.3. 偏差(deviance)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#r-2">9.1.4. 决定系数 <span class="math notranslate nohighlight">\(R^2\)</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#ch-glm-gof-chi">9.1.5. 广义皮尔逊卡方统计量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#residual-analysis">9.2. 残差分析(Residual analysis)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#response-residuals">9.2.1. Response residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#working-residuals">9.2.2. Working residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#partial-residuals">9.2.3. Partial residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#pearson-residuals">9.2.4. Pearson residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#deviance-residuals">9.2.5. Deviance residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#score-residuals">9.2.6. Score residuals</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#model-selection">9.3. 模型选择(model selection)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#aic">9.3.1. AIC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#bic">9.3.2. BIC</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html">10. 模型检验</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id2">10.1. 拉格朗日乘子检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id3">10.1.1. 得分统计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id4">10.1.2. 检验过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#wald">10.2. wald 检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id5">10.2.1. 参数估计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id6">10.2.2. 检验过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id7">10.3. 似然比检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id8">10.3.1. 抽样分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id9">10.3.2. 模型比较</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id10">10.3.3. 偏差统计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#f">10.3.4. F 检验</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id11">10.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html">11. 高斯模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id2">11.1. 传统线性回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id3">11.2. 高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id4">11.3. 高斯回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id5">11.4. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id6">11.4.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#irls">11.4.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id7">11.4.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id10">11.5. 其它连接函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html">12. 逆高斯模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id2">12.1. 逆高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id3">12.2. 逆高斯回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id4">12.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id5">12.3.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#irls">12.3.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id6">12.3.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id7">12.4. 其它连接函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html">13. 二项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id2">13.1. 伯努利分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id3">13.2. 逻辑回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id4">13.2.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id5">13.2.2. 参数估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#odds-logit">13.2.3. odds 与 logit</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id6">13.3. 二项式分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id7">13.4. 二项式回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id8">13.4.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id9">13.4.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id10">13.5. 其它连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id11">13.5.1. 恒等连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#probit">13.5.2. probit 回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#log-log-clog-log">13.5.3. log-log 和 clog-log</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id12">13.6. 分组数据与比例数据</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html">14. 泊松模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#poisson">14.1. 泊松(Poisson)分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id2">14.1.1. 推导过程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id3">14.1.2. 泊松分布的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id5">14.2. 泊松回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id6">14.3. 参数估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id7">14.4. 拟合统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id8">14.5. 频率模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id9">14.6. 泊松模型的局限性</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html">15. 指数模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#exponential">15.1. 指数(exponential)分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id2">15.1.1. 推导过程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id3">15.1.2. 分布的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id6">15.2. 指数回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id7">15.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id8">15.3.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id9">15.3.2. 拟合优度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#irls">15.3.3. IRLS</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html">16. Gamma 模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id1">16.1. Gamma 函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id2">16.2. Gamma 分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id3">16.3. Gamma 回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id4">16.4. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id5">16.4.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#irls">16.4.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id6">16.4.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id7">16.5. 其他连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id8">16.5.1. 对数 Gamma 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#identity-gamma">16.5.2. 恒等(identity) Gamma 模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html">17. 过度分散</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id2">17.1. 什么是过度分散</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id3">17.2. 过度分散的检测</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id4">17.3. 过度分散的影响</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id5">17.4. 标准误差的修正</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html">18. 负二项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id2">18.1. 负二项式分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id3">18.1.1. 从二项式分布推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id4">18.1.2. 泊松-伽马混合分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#alpha">18.1.3. 辅助参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的影响</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id5">18.2. 负二项回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id6">18.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#irls">18.3.1. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id7">18.3.2. 参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id8">18.4. 负二项式模型扩展</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id9">18.4.1. 对数连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id10">18.4.2. 参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id11">18.4.3. 几何模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id12">18.4.4. 广义负二项式模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html">19. 零计数问题</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id2">19.1. 零截断模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id3">19.1.1. 零截断泊松模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id4">19.1.2. 零截断负二项式模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id5">19.2. 零膨胀模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#hurdle">19.2.1. Hurdle 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#zero-inflate">19.2.2. Zero-inflate 模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html">20. 多项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id2">20.1. 类别分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#softmax">20.2. softmax 回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id3">20.2.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id4">20.2.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id5">20.3. 多项式分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id6">20.4. 多项式回归模型</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html">21. 有序离散模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id2">21.1. 有序逻辑回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id3">21.2. 参数估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id4">21.3. 连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#logit">21.3.1. logit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#probit">21.3.2. probit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#clog-log">21.3.3. clog-log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#log-log">21.3.4. log-log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#cauchit">21.3.5. cauchit</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id5">21.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html">附录</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html#id2">标准正态累积分布表</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html#id3">卡方分布临界值表</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/content.html">参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../probability_model/index_html.html">概率图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html">1. 概率基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id2">1.1. 概率分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id3">1.2. 独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#marginalization">1.3. 边缘化(marginalization)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id6">1.4. 贝叶斯定理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id7">1.5. 期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id8">1.6. 常见概率分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id9">1.6.1. 离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id10">1.6.2. 连续变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id11">1.6.3. 计数变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id12">1.7. 大数定律</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id13">1.7.1. 独立同分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id14">1.7.2. 中心极限定理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id15">1.8. 信息论基础</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id16">1.8.1. 信息熵</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#kl">1.8.2. KL散度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id18">1.8.3. 互信息</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html">2. 参数估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-liklihood">2.1. 极大似然估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id3">2.1.1. 二值离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id4">2.1.2. 一般离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-2-gaussian-ml">2.1.3. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id6">2.1.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-bayesian-estimation">2.2. 贝叶斯估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id8">2.2.1. 伯努利变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id9">2.2.2. 类别变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id10">2.3. 最大后验估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id11">2.3.1. 伯努利变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id12">2.3.2. 类别变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id13">2.4. 最大似然估计与贝叶斯估计的对比</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id14">2.5. 统计量和充分统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#fisher-information">2.6. Fisher Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id15">2.7. 估计量的评价</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id16">2.7.1. 估计量的方差与偏差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id17">2.7.2. 大数定律和中心极限定理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-2-mle-estimator">2.7.3. 最大似然估计的特性</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html">3. 指数族</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#ch-24-1">3.1. 指数族的定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id3">3.1.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id4">3.1.2. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id5">3.1.3. 泊松分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id6">3.1.4. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id7">3.1.5. 其它常见指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#ch-24-moments">3.2. 指数族的期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id9">3.3. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#kl">3.4. 最大似然估计与KL散度的关系</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/19.%E5%A4%9A%E7%BB%B4%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83_26.html">4. 多维高斯分布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html">5. 有向图(Directed Graphical Models)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id1">5.1. 有向图</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id2">5.2. 条件独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id3">5.3. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html">6. 无向图(Undirected Graphical Models)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id1">6.1. 无向图的定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id2">6.2. 条件独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id3">6.3. 图的分解</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#vs">6.4. 有向图 vs 无向图</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id4">6.5. 树</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id5">6.6. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html">7. 因子图</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id2">7.1. 因子图的定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id3">7.2. 图模型之间的转换</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id4">7.2.1. 转换为因子图</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id5">7.2.2. 因子图转换为有向图</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id6">7.3. 图模型的评价</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#i-map">7.3.1. I-map</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#d-map">7.3.2. D-map</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#p-map">7.3.3. P-map</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html">8. 模型推断：消元法</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id2">8.1. 什么是模型的推断</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id3">8.2. 消元法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id4">8.2.1. 有向图消元算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#ch-condition-margin">8.2.2. 条件概率和边缘概率</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id6">8.2.3. 无向图的消元法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id7">8.3. 图消除</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id9">8.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html">9. 加和乘积算法(sum-product algorithm)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id1">9.1. 树结构</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id2">9.2. 从消元法到信息传播</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id3">9.3. 树模型的和积算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id4">9.4. 因子图的和积算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id5">9.5. 类树结构图模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#polytrees">9.6. 多重树(polytrees)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id6">9.7. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html">10. 最大后验估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id2">10.1. 最大后验概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id3">10.2. 最大化后验的状态</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id4">10.3. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html">11. 完整观测的参数学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id2">11.1. 有向图的参数学习</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id3">11.2. 无向图的参数学习</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id4">11.2.1. 成对二值变量模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id5">11.2.2. 一般二值变量模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html">12. 不完整观测的学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html#id2">12.1. 隐变量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html#em">12.2. 期望最大化算法(EM)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/14.%E5%9B%BE%E5%BD%A2%E7%BB%93%E6%9E%84%E7%9A%84%E5%AD%A6%E4%B9%A0_lecture_23.html">13. 有向图结构学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/16.%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD_lecture_17.html">14. 变分推断</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html">15. 马尔科夫蒙特卡洛</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#why-sampling">15.1. Why sampling？</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#monte-carlo">15.2. 蒙特卡罗(Monte Carlo)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#markov-chain">15.3. 马尔科夫链(Markov Chain)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id2">15.3.1. 一个例子</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#time-reversibility">15.3.2. 时间可逆性(Time Reversibility)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id3">15.3.3. 总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#markov-chain-monte-carlo">15.4. Markov Chain Monte Carlo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#metropolis-hastings">15.4.1. Metropolis-Hastings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id4">15.4.2. 例子：正态分布的采样</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id5">15.4.3. 多变量采样</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#gibbs">15.4.4. Gibbs 采样</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#mixing-time">15.5. Mixing Time</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#approximate-map-and-partitioning">15.6. Approximate MAP and Partitioning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html">16. 贝叶斯分类器</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id2">16.1. 朴素贝叶斯模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id3">16.1.1. 模型表示</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id4">16.1.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id5">16.2. 高斯判别模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id6">16.2.1. 一元高斯模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id7">16.2.2. 多元高斯模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id8">16.3. 逻辑回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id9">16.4. 生成模型和判别模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id10">16.5. 多分类</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id11">16.6. 其它扩展</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html">17. 回归模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id2">17.1. 机器学习的概率解释</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id3">17.2. 经典线性回归</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id4">17.2.1. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id5">17.3. 线性回归的概率解释</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id6">17.3.1. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id7">17.4. 凸函数最优化问题</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id8">17.5. 岭回归</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html">18. 分类模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id2">18.1. 生成模型与判别模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id3">18.2. 线性回归与线性分类</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id4">18.3. 生成模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id5">18.3.1. 高斯判别模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id6">18.3.2. 朴素贝叶斯模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id7">18.3.3. 指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id8">18.4. 判别模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id9">18.4.1. 逻辑回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id10">18.4.2. 多分类</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id11">18.4.3. 最大熵模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#probit">18.4.4. Probit 回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#noisy-or">18.4.5. Noisy-OR 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id12">18.4.6. 其它指数模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html">19. 广义线性模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id2">19.1. 定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id3">19.1.1. 指数族分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id4">19.1.2. 链接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id5">19.1.3. 例子</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id6">19.2. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id7">19.2.1. 梯度下降法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id8">19.2.2. 牛顿法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#irls">19.2.3. 迭代重加权最小二乘(IRLS)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#goodness-of-fit">19.3. goodness of fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id9">19.4. 连续值响应模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id10">19.4.1. 高斯族</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#gamma">19.4.2. Gamma族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id12">19.5. 二项响应模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id13">19.6. 多项响应模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id14">19.7. 计数响应模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id15">19.7.1. 泊松分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id16">19.8. GLM扩展</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html">20. 混合模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id2">20.1. 一般混合模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id3">20.1.1. 模型的有向图表示</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id5">20.1.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id8">20.2. 高斯混合模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id9">20.2.1. 模型的表示</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id10">20.2.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#k-means">20.3. K-means</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/32.%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90_42.html">21. 因子分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/%E4%BA%8C%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B.html">22. 二变量模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/33.LDA_43.html">23. 主题模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/33.LDA_43.html#plsa">23.1. PLSA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/33.LDA_43.html#lda">23.2. LDA</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html">24. 隐马尔可夫模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id2">24.1. 隐马尔可夫模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id3">24.1.1. 马尔可夫模型和朴素贝叶斯模型的关系</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id4">24.2. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/27.%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA_37.html">25. 条件随机场</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/28.%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%99%A8_38.html">26. 卡尔曼滤波器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/40.%E9%A1%B9%E7%9B%AE%E5%8F%8D%E5%BA%94%E7%90%86%E8%AE%BA_50.html">27. 项目反应理论</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/41.%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA_51.html">28. 贝叶斯知识追踪</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE.html">29. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../aigc/index.html">AI内容生成（ai-gc）</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html">1. 变分自编码器（Variational Autoencoder）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#evidence-lower-bound-elbo">1.1. 证据下界(Evidence Lower Bound,ELBO)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#id2">1.2. 编码-解码</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#id3">1.3. 总结</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#em">1.3.1. 和EM算法的关系</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#variational">1.3.2. 为什么叫变分（variational）？</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#vq-vae">1.4. VQ-VAE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#id4">1.5. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html">2. 扩散概率模型（diffusion probabilistic models）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#diffusion-probabilistic-model">2.1. 扩散概率模型（diffusion probabilistic model）</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#markovian-hierarchical-variational-autoencoder-mhvae">2.1.1. 马尔科夫分层自编码器（Markovian Hierarchical Variational Autoencoder,MHVAE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#id6">2.1.2. 扩散模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#id8">2.1.3. 前向-后向</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#elbo">2.1.4. ELBO</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#denoising-diffusion-probabilistic-model-ddpm">2.2. 降噪扩散概率模型（Denoising diffusion probabilistic model,DDPM）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#guidance">2.3. Guidance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#unet">2.4. UNET</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#improved-denoising-diffusion-probabilistic-models-ddpm">2.5. 改进降噪扩散概率模型（Improved Denoising Diffusion Probabilistic Models,DDPM）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#id17">2.6. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../aigc/%E7%A8%B3%E5%AE%9A%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B.html">3. 稳定扩散模型（Stable diffusion model）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E7%A8%B3%E5%AE%9A%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B.html#latent-diffusion-model-ldm">3.1. 潜在扩散模型（Latent diffusion model,LDM）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E7%A8%B3%E5%AE%9A%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B.html#stable-diffusion-probabilistic-model-sdm">3.2. 稳定扩散模型（Stable diffusion probabilistic model,SDM）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E7%A8%B3%E5%AE%9A%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B.html#id3">3.3. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../aigc/dalle2.html">4. DALL·E 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../aigc/imgen.html">5. Imagen</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../audio/index.html">语音技术</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../audio/feature.html">1. 音频特征</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id2">1.1. 认识声音</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id3">1.2. 认识声波</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id4">1.2.1. 物体的振动以及简谐振动</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id7">1.2.2. 什么是声波</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id8">1.2.3. 纯音和复合音</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#spectrum">1.2.4. 频谱 Spectrum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id10">1.2.5. 名词</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id13">1.3. 语音学</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id14">1.3.1. 发声原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id15">1.3.2. 听觉感应</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id16">1.4. 数字信号处理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id17">1.4.1. 模数转换</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#wav">1.4.2. 音频文件–WAV</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id18">1.5. 分帧与加窗</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id19">1.5.1. 预加重处理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id20">1.5.2. 分帧与加窗处理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id21">1.6. 声音的感官度量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#sound-pressure-level-spl">1.6.1. 声压与声压级(Sound Pressure Level,SPL)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#intensity-level-il">1.6.2. 声强与声强级(Intensity Level,IL）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id22">1.6.3. 声压与声强的关系</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id23">1.6.4. 响度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id24">1.6.5. 音量计算</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id25">1.6.6. 频率与音高</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id26">1.7. 时域分析</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id27">1.7.1. 短时能量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id28">1.7.2. 短时平均幅度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id29">1.7.3. 短时过零率</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id31">1.8. 频域分析</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#spectrum-spectrogram">1.8.1. 声谱(spectrum)和时频谱(spectrogram)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#short-time-fourier-transform-stft">1.8.2. 短时傅里叶变换 Short-time Fourier transform (STFT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id33">1.8.3. 倒频谱</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id34">1.8.4. 色谱图</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id35">1.9. 小波域特征</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id36">1.9.1. 离散小波域变换</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id37">1.9.2. 小波域过零率</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id38">1.9.3. 小波域质心</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id39">1.9.4. 小波域子带能量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#mfcc">1.10. 语音识别的音频特征–MFCC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id40">1.11. 参考资料</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../edm/index.html">教育领域数据挖掘</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../edm/bkt.html">1. 贝叶斯知识追踪(Bayesian Knowledge Tracing,BKT)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id1">1.1. 简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#hidden-markov-model-hmm">1.2. 隐马尔科夫模型(Hidden Markov Model,HMM)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#bayesian-knowledge-tracing">1.3. 贝叶斯知识追踪(Bayesian Knowledge Tracing)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#bkt">1.3.1. BKT的参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#item-response-theory-irt">1.4. 项目反映理论(Item Response Theory,IRT)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#bktirt">1.5. BKT结合IRT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id5">1.6. 实验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id6">1.6.1. 数据集</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id7">1.6.2. 实验方法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id8">1.6.3. 实验结果</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id9">1.6.4. 项目代码</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id10">1.7. 未来工作</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id11">1.7.1. 题目难度的计算</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#irt">1.7.2. 多参数IRT模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id12">1.7.3. 参数估计算法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id13">1.8. 参考文献</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../nlp/index.html">自然语言处理</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html">1. 文本去重</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id2">1.1. 背景</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id3">1.2. 技术思路</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id4">1.3. 相似（距离）算法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#euclidean-distance">1.3.1. 欧氏距离（Euclidean Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#minkowski-distance">1.3.2. 闵科夫斯基距离（Minkowski Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#manhattan-distance">1.3.3. 曼哈顿距离（Manhattan Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#chebyshev-distance">1.3.4. 切比雪夫距离（Chebyshev Distance ）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#mahalanobis-distance">1.3.5. 马氏距离(Mahalanobis Distance)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#cosine-similarity">1.3.6. 余弦夹角相似度(Cosine Similarity)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#hamming-distance">1.3.7. 汉明距离（Hamming Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#jaccard">1.3.8. Jaccard 系数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id5">1.3.9. 编辑距离</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id6">1.3.10. 最长公共字串</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id7">1.3.11. 最长公共子序列</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id8">1.4. 文本去重</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#kshingle">1.4.1. KShingle算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#minhash">1.4.2. Minhash算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#simhash">1.4.3. simhash</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#ksentence">1.4.4. KSentence算法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id9">1.5. 话术去重</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../nlp/bert/content.html">2. Attention&amp;Transformer&amp;Bert 简介</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/bert/content.html#transformer">2.1. Transformer 从宏观到微观</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#seq2seq">2.1.1. seq2seq</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#id1">2.1.2. 模型的输入</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/bert/content.html#self-attention">2.2. Self-Attention</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#id2">2.2.1. 什么是注意力？</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#id3">2.2.2. 加权求和</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#id4">2.2.3. 位置编码</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#multi-head">2.2.4. 多头注意力（Multi-head）</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/bert/content.html#attention">2.3. Attention 机制</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/bert/content.html#id5">2.4. 其它参考资料</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../rst_tutorial/latex.html">latex demo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../rst_tutorial/latex.html#latex">latex</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rst_tutorial/latex.html#how-to-write-an-m-x-n-matrix-in-latex">How to write an m x n matrix in LaTeX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-big-parentheses">With big parentheses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-parentheses">With parentheses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-brackets">With brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#latex-matrix-with-no-bracket">LateX matrix with no bracket</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-vertical-bar-brackets">With vertical bar brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-curly-brackets">with curly brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-double-vertical-bar-brackets">with double vertical bar brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#small-inline-matrix">small inline matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#examples-matrix-2-x-2-in-latex">Examples matrix 2 x 2 in LaTeX</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../rst_tutorial/graphviz.html">graphviz demo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../rst_tutorial/graphviz.html#id1">布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rst_tutorial/graphviz.html#id2">其它</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/index.html">读书笔记</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/index.html">《统计因果推断推理入门》读书笔记</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html">1. 第三章 干预的效果</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html#id2">1.1. 第3.1节 干预</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html#id3">1.2. 第3.2节 校正公式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html#id8">1.3. 第3.3节 后门准则</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html">《深度学习推荐系统》读书笔记</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id2">重点</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id3">冷启动</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id4">探索与利用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id5">召回层的主要策略</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#embedding">协同过滤 &amp; Embedding 向量</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">张振虎的博客</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">广义线性模型</a> &raquo;</li>
      <li><span class="section-number">7. </span>广义线性模型</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/glm/source/广义线性模型/content.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1><span class="section-number">7. </span>广义线性模型<a class="headerlink" href="#id1" title="永久链接至标题"></a></h1>
<p>线性回归模型是算法领域的入门模型，是每个新人入门的必须课。
在线性回归模型中假设响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 是由两部分组成：系统组件（system component）
和误差组件（error component）。
其中系统组件是一个线性预测器 <span class="math notranslate nohighlight">\(\eta=x^T \beta\)</span>
，误差组件是一个服从标准正态分布的随机量 <span class="math notranslate nohighlight">\(\epsilon \sim \mathcal{N}(0,1)\)</span>
。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-0">
<span class="eqno">(7.1)<a class="headerlink" href="#equation-glm-source-content-0" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}y &amp;= \beta_0 + x_1 \beta_1 +x_2 \beta_2 +\cdots + x_p \beta_p  + \epsilon\\&amp;= x^T \beta + \epsilon\end{aligned}\end{align} \]</div>
<p>虽然线性预测器 <span class="math notranslate nohighlight">\(\eta\)</span> 是一个数值变量，
但误差项 <span class="math notranslate nohighlight">\(\epsilon\)</span> 是一个高斯随机变量，
响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 作为二者的加和，也是一个高斯随机量，
并有 <span class="math notranslate nohighlight">\(\mathbb{E}[Y]=\eta=x^T \beta\)</span>
。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-1">
<span class="eqno">(7.2)<a class="headerlink" href="#equation-glm-source-content-1" title="公式的永久链接"></a></span>\[Y \sim  \mathcal{N}(x^T \beta,1)\]</div>
<p>因此，在线性回归中，可以把响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 解释成一个高斯随机变量。</p>
<p>那么，响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 是不是可以解释成其它概率分布的随机变量呢？比如，伯努利变量、泊松变量等等，
答案显然是可以的。如果把 <span class="math notranslate nohighlight">\(Y\)</span> 解释成伯努利变量，得到就是逻辑回归模型，
如果把 <span class="math notranslate nohighlight">\(Y\)</span> 解释成泊松变量，得到的就是泊松回归模型，等等，还有很多种类的回归模型。
实际上，对于常见的概率分布，都有对应的回归模型。
但是在早期，这些回归模型，都是独立开发，独立应用的。
虽然这些模型都是使用最大似然估计进行参数估计，但每种模型都需要独立对似然函数就行求导等操作。</p>
<p>直到1972年，John Nelder 和 Robert Wedderburn
提出了一种统一的框架：广义线性模型（Generalized linear models,GLM）。
<code class="docutils literal notranslate"><span class="pre">GLM</span></code> 将多种统计回归模型归一到一个框架下，并且提出了一个统一的参数估计算法：
迭代重加权最小二乘法(iteratively reweighted least squares method,IRLS)。
在 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 框架中，
误差项的概率分布可以是指数族分布中的任意一种，
因此，在 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 中，响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 可以解释成指数族分布中的任意一种。
线性预测器部分保持不变，仅仅是误差项扩展到了指数族分布，因此称为
<strong>广义线性模型</strong> 。</p>
<p>本章我们正式讨论广义线性模型，<code class="docutils literal notranslate"><span class="pre">GLM</span></code> 是建立在指数族分布的技术上，
因此我们首先介绍下指数族概率分布的标准形式，然后再给出 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 的定义。</p>
<section id="id2">
<h2><span class="section-number">7.1. </span>指数族分布<a class="headerlink" href="#id2" title="永久链接至标题"></a></h2>
<section id="id3">
<h3><span class="section-number">7.1.1. </span>自然指数族<a class="headerlink" href="#id3" title="永久链接至标题"></a></h3>
<p>在 <a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#ch-24-1"><span class="std std-numref">节 3.1</span></a> 我们讨论了指数族分布，所有指数族的概率密度(质量)函数都可以写成如下的形式。</p>
<div class="math notranslate nohighlight" id="equation-eq-glm-08">
<span class="eqno">(7.1.1)<a class="headerlink" href="#equation-eq-glm-08" title="公式的永久链接"></a></span>\[p(y|\theta) = \exp \{\theta^T T(y) - A(\theta) + S(y)\}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\theta\)</span>
称为自然参数(natural parameter)或者规范参数(canonical parameter)，
其代表了模型中所有的未知参数。
通常指数族分布会有两个参数，一个代表位置(location)的参数，
一个代表尺度(scale)的参数。
位置参数和分布的期望相关，尺度参数和分布的方差相关。</p>
<p>本章我们讨论的广义线性模型并不使用上述形式的指数族，而是指数族的一个子集，
自然指数族(natural exponential family)，
自然指数族是满足 <span class="math notranslate nohighlight">\(T(y)=y\)</span> 的指数族。</p>
<div class="math notranslate nohighlight" id="equation-eq-glm-111">
<span class="eqno">(7.1.2)<a class="headerlink" href="#equation-eq-glm-111" title="公式的永久链接"></a></span>\[p(y|\theta) = \exp \{\theta^T y - A(\theta) + S(y)\}\]</div>
<p>指数族的这个形式被称为自然形式(natural form)或者规范形式(canonical form)，
<strong>虽然指数族中大部分分布都可以写成上述自然形式，但是也有一些分布，虽然属于指数族，但是不能写成上述自然形式，</strong>
<strong>比如对数正态分布(LogNormal distribution)。</strong></p>
<div class="admonition important">
<p class="admonition-title">重要</p>
<p>这里有个容易搞混的地方，虽然参数 <span class="math notranslate nohighlight">\(\theta\)</span> 叫规范参数(canonical parameter)，
但是必须满足 <span class="math notranslate nohighlight">\(T(y)=y\)</span> 的形式才叫做规范形式(canonical form)。</p>
</div>
<p>指数族分布中，有的分布只有一个参数，有的分布有两个参数，
规范参数 <span class="math notranslate nohighlight">\(\theta\)</span> 包含了分布所有的原始参数，
当分布只有一个参数时，<span class="math notranslate nohighlight">\(\theta\)</span>  就是一个标量参数，
当分布有两个参数时，<span class="math notranslate nohighlight">\(\theta\)</span> 就是一个二元向量参数。
并且指数族分布的两个参数分别和分布的期望与方差相关，分别代表了位置(location)与尺度(scale)。</p>
<p>规范参数 <span class="math notranslate nohighlight">\(\theta\)</span> 和指数族分布的原始参数是存在一一映射的，
规范参数 <span class="math notranslate nohighlight">\(\theta\)</span> 可以是一个标量参数，也可以包含两个参数的向量，
对于单参数的指数族分布，原始参数通常就是分布的期望 <span class="math notranslate nohighlight">\(\mu\)</span> ，此时 <span class="math notranslate nohighlight">\(\theta\)</span> 是 <span class="math notranslate nohighlight">\(\mu\)</span> 的函数。
对于双参数的指数族分布，原始参数通常就是分布的期望 <span class="math notranslate nohighlight">\(\mu\)</span> 和方差 <span class="math notranslate nohighlight">\(\sigma^2\)</span> ，
此时 <span class="math notranslate nohighlight">\(\theta\)</span> 是含有两个参数的向量，并 <span class="math notranslate nohighlight">\(\theta\)</span> 是期望 <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma^2\)</span> 的函数。</p>
<p>指数族的规范形式( <a class="reference internal" href="#equation-eq-glm-111">公式(7.1.2)</a> ) 规范参数 <span class="math notranslate nohighlight">\(\theta\)</span> 包含了所有参数，这不方便处理。
因此我们把参数拆分一下，在规范形式的基础上再引入一个代表尺度(scale)的参数 <span class="math notranslate nohighlight">\(\phi\)</span>
。</p>
<div class="math notranslate nohighlight" id="equation-eq-glm-121">
<span class="eqno">(7.1.3)<a class="headerlink" href="#equation-eq-glm-121" title="公式的永久链接"></a></span>\[p(y|\theta) = \exp \{\frac{\theta y - b(\theta)}{a(\phi)} + c(y,\phi)\}\]</div>
<p>这种形式的指数族通常被称为指数分散族(exponential dispersion family,EDF)，
<span class="math notranslate nohighlight">\(a(\phi)\)</span> 称为分散函数(dispersion function)，是已知的。
<span class="math notranslate nohighlight">\(\phi\)</span> 称为分散参数(dispersion parameter)。
<span class="math notranslate nohighlight">\(\theta\)</span> 仍然称作自然参数(natural parameter)或者规范参数(canonical parameter)。</p>
<p><a class="reference internal" href="#equation-eq-glm-121">公式(7.1.3)</a> 形式的指数族，其实就是对参数 <span class="math notranslate nohighlight">\(\theta\)</span> 进行了拆分，
把期望参数和方差参数拆分开。
<strong>使得自然参数</strong> <span class="math notranslate nohighlight">\(\theta\)</span> <strong>仅和期望</strong> <span class="math notranslate nohighlight">\(\mu\)</span> <strong>相关</strong> ，
分散参数 <span class="math notranslate nohighlight">\(\phi\)</span> 和分布的方差参数相关。
分拆后，规范参数
<span class="math notranslate nohighlight">\(\theta\)</span> 仅和分布的期望参数 <span class="math notranslate nohighlight">\(\mu\)</span> 相关，
并且和 <span class="math notranslate nohighlight">\(\mu\)</span> 之间存在一一映射的函数关系，
换句话说，<span class="math notranslate nohighlight">\(\theta\)</span> 和 <span class="math notranslate nohighlight">\(\mu\)</span> 可以互相转化。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-2">
<span class="eqno">(7.1.4)<a class="headerlink" href="#equation-glm-source-content-2" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\theta &amp;=f(\mu)\\\mu &amp;= f^{-1}(\theta)\end{aligned}\end{align} \]</div>
<p><strong>分散参数(dispersion parameter)</strong></p>
<p>在最初的GLM论文中(Nelder and Wedderburn, 1972)把 <span class="math notranslate nohighlight">\(a(\phi)\)</span>
称为尺度因子(scale factor)， 并且没有给参数 <span class="math notranslate nohighlight">\(\phi\)</span>
单独命名。后来在1974年 Royal Statistical Society 发布了首个
GLM的软件工具包(Generalized Linear Interactive Modelling,GLIM)，
在GLIM中把 <span class="math notranslate nohighlight">\(a(\phi)\)</span> 定义成：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-3">
<span class="eqno">(7.1.5)<a class="headerlink" href="#equation-glm-source-content-3" title="公式的永久链接"></a></span>\[a(\phi) = \frac{\phi}{w}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(w\)</span> 是样本的先验权重(prior weight)，<span class="math notranslate nohighlight">\(\phi\)</span>
称为尺度参数(scale parameter)，
这就是导致了对 <span class="math notranslate nohighlight">\(\phi\)</span> 命名产生了歧义。
因为”scale”这个词在统计学还有其它用法，容易产生混淆，
所以在1980s(McCullagh and Nelder)初版的 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 书籍中，
把 <span class="math notranslate nohighlight">\(\phi\)</span> 命名为”dispersion parameter”，
后来也就沿用了这种叫法。
但是由于 <code class="docutils literal notranslate"><span class="pre">GLIM</span></code> 流行了很久，导致”scale”的叫法还存在很多资料中。</p>
<p>在很多GLM的工具包中，都会把 <span class="math notranslate nohighlight">\(a(\phi)\)</span> 定义成如下形式：</p>
<div class="math notranslate nohighlight" id="equation-eq-glm-1010">
<span class="eqno">(7.1.6)<a class="headerlink" href="#equation-eq-glm-1010" title="公式的永久链接"></a></span>\[a(\phi)_i = \frac{\phi}{w_i}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(w_i\)</span> 是观测样本的权重，一般是已知的。
不同的样本可以拥有不同的权重值，
比如进行参数估计时，对于某些样本设置成 <span class="math notranslate nohighlight">\(w_i=0\)</span>
，这就相当于抛弃了这些样本。</p>
<p><span class="math notranslate nohighlight">\(a(\phi)\)</span> 的函数形式并没有严格的要求，其函数形式并不重要，
本质上 <span class="math notranslate nohighlight">\(a(\phi)\)</span> 就是代表了分散参数(dispersion parameter)，
所以通常直接令 <span class="math notranslate nohighlight">\(a(\phi)=\phi\)</span> 。
如果你需要不同的样本有不同的值，那么就使用 <a class="reference internal" href="#equation-eq-glm-1010">公式(7.1.6)</a> 的形式。
<a class="reference internal" href="#equation-eq-glm-1010">公式(7.1.6)</a> 的形式中，当所有样本拥有相同的 <span class="math notranslate nohighlight">\(w\)</span> 权重时，
就等价于 <span class="math notranslate nohighlight">\(a(\phi)=\phi\)</span> 。</p>
<p>通常在 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 中，只有参数 <span class="math notranslate nohighlight">\(\theta\)</span> 作为模型的未知参数，此时称为单参数模。
单参数模型指的是模型中只有 <span class="math notranslate nohighlight">\(\theta\)</span> 是未知参数，而 <span class="math notranslate nohighlight">\(\phi\)</span> 是已知的，
反之，如果 <span class="math notranslate nohighlight">\(\theta\)</span> 和 <span class="math notranslate nohighlight">\(\phi\)</span> 都是未知的，则成为双参数模型。
指数族的某些分布，是不存在分散参数的，
比如对于伯努利分布、泊松分布、二项式分布等等离散分布。</p>
<p>自然参数 <span class="math notranslate nohighlight">\(\theta\)</span> 和分布的期望相关，它是期望的一个函数。
而分散参数 <span class="math notranslate nohighlight">\(\phi\)</span> 和分布的方差相关，它影响着方差的大小，
具体的关系在之后的内容中会详细说明。</p>
<p><strong>累积函数(cumulant function)</strong></p>
<p>我们知道在 <a class="reference internal" href="#equation-eq-glm-08">公式(7.1.1)</a> 的指数族形式中 <span class="math notranslate nohighlight">\(A(\theta)\)</span> 称为累积函数(cumulant function)，
可以用 <span class="math notranslate nohighlight">\(A(\theta)\)</span> 的导数求出分布的矩，一阶导数是分布的期望，
二阶导数是分布的方差。
然而在GLM中我们使用的是 <a class="reference internal" href="#equation-eq-glm-121">公式(7.1.3)</a> 的形式，
其中 <span class="math notranslate nohighlight">\(b(\theta)\)</span> 本质上就是 <span class="math notranslate nohighlight">\(A(\theta)\)</span>
，二者关系是：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-4">
<span class="eqno">(7.1.7)<a class="headerlink" href="#equation-glm-source-content-4" title="公式的永久链接"></a></span>\[A(\theta) = \frac{ b(\theta) }{a(\phi)}\]</div>
<p>所以我们同样把 <span class="math notranslate nohighlight">\(b(\theta)\)</span> 被称为累积函数(cumulant function)，
并且它同样和分布的矩(moments)有关。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-5">
<span class="eqno">(7.1.8)<a class="headerlink" href="#equation-glm-source-content-5" title="公式的永久链接"></a></span>\[\mathbb{E}[Y] = b'(\theta)=\mu\]</div>
<div class="math notranslate nohighlight" id="equation-eq-34-20">
<span class="eqno">(7.1.9)<a class="headerlink" href="#equation-eq-34-20" title="公式的永久链接"></a></span>\[V(Y) = A''(\theta)=a(\phi)b''(\theta)\]</div>
<p>由于 <span class="math notranslate nohighlight">\(b(\theta)\)</span> 是在 <span class="math notranslate nohighlight">\(A(\theta)\)</span> 的基础上拆分出去 <span class="math notranslate nohighlight">\(a(\phi)\)</span>
，所以 <span class="math notranslate nohighlight">\(b(\theta)\)</span> 的二阶导数不再分布的方差，需要再乘上 <span class="math notranslate nohighlight">\(a(\phi)\)</span> 才能得到分布的方差。</p>
<p><strong>方差结构</strong></p>
<p>在 <code class="docutils literal notranslate"><span class="pre">EDF</span></code> (指数分散族，Exponential Dispersion Family)中，
分布的方差可以表示成两部分的乘积（ <a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#equation-eq-34-20">公式(19.1.17)</a> ），
一部分是分散函数 <span class="math notranslate nohighlight">\(a(\phi)\)</span>
，另一部分是累计函数的二阶导数 <span class="math notranslate nohighlight">\(b''(\theta)\)</span> 。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-6">
<span class="eqno">(7.1.10)<a class="headerlink" href="#equation-glm-source-content-6" title="公式的永久链接"></a></span>\[V(Y)  = b''(\theta) a(\phi) = \nu(\mu)a(\phi)\]</div>
<p>累积函数 <span class="math notranslate nohighlight">\(b(\theta)\)</span> 是一个关于 <span class="math notranslate nohighlight">\(\theta\)</span> 的函数，
其二阶导数要么是一个常数，要么是一个关于自然参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的函数。
而自然参数 <span class="math notranslate nohighlight">\(\theta\)</span> 和均值参数 <span class="math notranslate nohighlight">\(\mu\)</span>
存在一一对应关系，所以一定可以把 <span class="math notranslate nohighlight">\(\theta\)</span> 替换成 <span class="math notranslate nohighlight">\(\mu\)</span>
。</p>
<p>我们定义累计函数 <span class="math notranslate nohighlight">\(b(\theta)\)</span> 的二阶导数为方差函数(variance function)，
方差函数是一个关于期望 <span class="math notranslate nohighlight">\(\mu\)</span> 的函数。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-7">
<span class="eqno">(7.1.11)<a class="headerlink" href="#equation-glm-source-content-7" title="公式的永久链接"></a></span>\[b''(\theta) = \nu(\mu)\]</div>
<p>方差函数 <span class="math notranslate nohighlight">\(\nu(\mu)\)</span> 存在两种情况：</p>
<ol class="arabic simple">
<li><p>方差函数是一个常量值， <span class="math notranslate nohighlight">\(\nu(\mu)=b''(\theta)=constant\)</span> ，<strong>此时分布的方差与均值无关</strong> 。</p></li>
<li><p>方差函数是一个关于均值 <span class="math notranslate nohighlight">\(\mu\)</span> 的函数，<span class="math notranslate nohighlight">\(\nu(\mu)=b''(\theta)=f(\theta)=f(\mu)\)</span> ，<strong>此时分布的方差与均值有关</strong></p></li>
</ol>
<p>方差函数(variance function)，是一个平滑函数，它把分布的均值参数 <span class="math notranslate nohighlight">\(\mu\)</span>
和分布的方差关联在一起。
<strong>如果其值一个常数值，说明均值和方差是独立无关的</strong>；
<strong>反之，如果是</strong> <span class="math notranslate nohighlight">\(\mu\)</span> <strong>的函数，说明均值和方差是相关联的</strong>。
在高斯分布中， <span class="math notranslate nohighlight">\(b''(\theta)=1\)</span> ，所以方差和均值是相互独立的，
对于其他分布，这是不成立的，高斯分布是特例。</p>
<p>影响方差的，除了方差函数 <span class="math notranslate nohighlight">\(\nu(\mu)\)</span> 以外，还有分散参数 <span class="math notranslate nohighlight">\(a(\phi)=\phi\)</span>
，它起到一个缩放的作用。
参数 <span class="math notranslate nohighlight">\(\theta\)</span> 和 <span class="math notranslate nohighlight">\(\phi\)</span> 本质上是位置(locate)和尺度(scale)参数，
位置参数反映数据的均值，尺度参数反映数据方差。</p>
<p>当 <span class="math notranslate nohighlight">\(a(\phi)=1\)</span> 时，分布的方差可以通过 <span class="math notranslate nohighlight">\(\nu(\mu)\)</span> 计算得到，
模型只有一个未知参数 <span class="math notranslate nohighlight">\(\mu\)</span> (或者说是 <span class="math notranslate nohighlight">\(\theta\)</span> ，因为 <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\theta\)</span> 是可以转换的)，
此时就是单参数指数族分布。
当 <span class="math notranslate nohighlight">\(a(\phi)=\phi\)</span> 时，分布就多了一个未知参数 <span class="math notranslate nohighlight">\(\phi\)</span>
，此时就是双参数指数族分布。
之后我们会看到，高斯分布是一个双参数分布，而
最大似然估计是无法同时估计出参数 <span class="math notranslate nohighlight">\(\theta\)</span> 和 <span class="math notranslate nohighlight">\(\phi\)</span> 的，
需要做一些改动才行，在以后的章节中我们会讨论这个问题。</p>
<p>在经典线性回归模型中，输入特征数据 <span class="math notranslate nohighlight">\(x\)</span> 通过线性组合 <span class="math notranslate nohighlight">\(\eta=\beta^T x\)</span>
影响着响应变量 <span class="math notranslate nohighlight">\(Y\)</span> (高斯分布) 的均值 <span class="math notranslate nohighlight">\(\mu=\eta=\beta^T x\)</span> ，
所有的观测样本共用参数 <span class="math notranslate nohighlight">\(\beta\)</span> (对于任意 <span class="math notranslate nohighlight">\(x\)</span> ，都是同样的 <span class="math notranslate nohighlight">\(\beta\)</span> 值)，
当 <span class="math notranslate nohighlight">\(x\)</span> 不同时， 高斯变量 <span class="math notranslate nohighlight">\(Y\)</span> 拥有不同的均值 <span class="math notranslate nohighlight">\(\mu\)</span> ，
通过这种方式实现了条件概率分布 <span class="math notranslate nohighlight">\(p(Y|X)\)</span> 的表达。
但是对于高斯变量 <span class="math notranslate nohighlight">\(Y\)</span> 的方差参数 <span class="math notranslate nohighlight">\(\sigma^2\)</span> 并没有假设为未知参数，而是假设其为已知的值，
并且对于任意的观测样本 <span class="math notranslate nohighlight">\(x\)</span> 都是一样的值。
然而，在GLM的框架下，是可以允许不同观测样本有不同的方差，
而这是通过 <span class="math notranslate nohighlight">\(a(\phi)\)</span> 实现的。
此时函数 <span class="math notranslate nohighlight">\(a(\phi)\)</span> 通常被定义成如下的形式：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-8">
<span class="eqno">(7.1.12)<a class="headerlink" href="#equation-glm-source-content-8" title="公式的永久链接"></a></span>\[a(\phi) = \frac{\phi}{w_i}\]</div>
<p>通常对于所有的观测样本来说，<span class="math notranslate nohighlight">\(\phi\)</span> 是一个相同的，而 <span class="math notranslate nohighlight">\(w\)</span> 可以根据不同的观测样本取不同的值，
下标 <span class="math notranslate nohighlight">\(i\)</span> 表示样本编号。
<span class="math notranslate nohighlight">\(w\)</span> 被称为先验权重(prior weight)，通常是根据额外的先验信息确定的。
如果所有观测样本具有相同的方差假设，那么 <span class="math notranslate nohighlight">\(w\)</span> 值通常就是1；反之，<span class="math notranslate nohighlight">\(w\)</span> 可以是和样本相关的，
不同的样本采用不同的值。</p>
<table class="docutils align-default" id="id8">
<caption><span class="caption-number">表 7.1.1 </span><span class="caption-text">常见分布的方差函数</span><a class="headerlink" href="#id8" title="永久链接至表格"></a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>分布</p></th>
<th class="head"><p>方差函数 <span class="math notranslate nohighlight">\(\nu(\mu)\)</span></p></th>
<th class="head"><p>约束</p></th>
<th class="head"><p>导数 <span class="math notranslate nohighlight">\(\partial \nu(\mu) / \partial\mu\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Gaussian</p></td>
<td><p><span class="math notranslate nohighlight">\(1\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} \mu \in \mathcal{R} \\ y \in \mathcal{R} \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(0\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Bernoulli</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu(1-\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} 0&lt;\mu&lt;1 \\ 0 \le y \le 1 \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1-2\mu\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Binomial(k)</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu(1-\mu/k)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} 0&lt;\mu&lt;k \\ 0 \le y \le k \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1-2\mu/k\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Poisson</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} \mu &gt;0 \\  y \ge 0 \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Gamma</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} \mu &gt;0 \\  y &gt; 0 \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(2\mu\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Inverse Gaussian</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu^3\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} \mu &gt;0 \\  y &gt; 0 \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(3\mu^2\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Negative binomial(<span class="math notranslate nohighlight">\(\alpha\)</span>)</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu+\alpha\mu^3\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} \mu &gt;0 \\  y \ge 0 \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1+2\alpha\mu\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Power(<span class="math notranslate nohighlight">\(k\)</span>)</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu^k\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} \mu &gt;0 \\  k \ne 0,1,2  \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(k\mu^{k-1}\)</span></p></td>
</tr>
</tbody>
</table>
</section>
<section id="id4">
<h3><span class="section-number">7.1.2. </span>示例：高斯分布<a class="headerlink" href="#id4" title="永久链接至标题"></a></h3>
<p>高斯分布的概率密度函数为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-9">
<span class="eqno">(7.1.13)<a class="headerlink" href="#equation-glm-source-content-9" title="公式的永久链接"></a></span>\[f(y) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp \{ -\frac{1}{2}\frac{(y-\mu)^2}{\sigma^2} \}\]</div>
<p>把其改写成指数分散族的形式：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-10">
<span class="eqno">(7.1.14)<a class="headerlink" href="#equation-glm-source-content-10" title="公式的永久链接"></a></span>\[f(y) = \exp \{ \frac{y\mu-\frac{1}{2}\mu^2}{\sigma^2} - \frac{y^2}{2\sigma^2}
- \frac{1}{2} \ln (2\pi\sigma^2) \}\]</div>
<p>和 <a class="reference internal" href="#equation-eq-glm-121">公式(7.1.3)</a> 进行对比，各个标准项为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-11">
<span class="eqno">(7.1.15)<a class="headerlink" href="#equation-glm-source-content-11" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\theta &amp;=\mu\\b(\theta) &amp;= \frac{1}{2}\mu^2\\a(\phi) &amp;= \sigma^2\end{aligned}\end{align} \]</div>
<p>高斯分布的均值和方差为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-12">
<span class="eqno">(7.1.16)<a class="headerlink" href="#equation-glm-source-content-12" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\mathbb{E}[Y]=b'(\theta) = \mu\\Var(Y) = b''(\theta)a(\phi) = \sigma^2\end{aligned}\end{align} \]</div>
<p>对于高斯分布来说，方差和均值是独立无关的。</p>
</section>
<section id="id5">
<h3><span class="section-number">7.1.3. </span>示例：伯努利分布<a class="headerlink" href="#id5" title="永久链接至标题"></a></h3>
<p>在 <a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#ch-basic-bernoulli"><span class="std std-numref">节 1.8.1</span></a> 我们已经介绍过伯努利分布，伯努利分布的概率质量函数一般写作</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-13">
<span class="eqno">(7.1.17)<a class="headerlink" href="#equation-glm-source-content-13" title="公式的永久链接"></a></span>\[P(Y) = \pi^y (1-\pi)^{1-y}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\pi\)</span> 是它的原始参数，表示变量 <span class="math notranslate nohighlight">\(Y=1\)</span> 的概率。
现在我们把它变成指数族分布的形式。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-14">
<span class="eqno">(7.1.18)<a class="headerlink" href="#equation-glm-source-content-14" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}P(Y) &amp;= \pi^y (1-\pi)^{1-y}\\&amp;= \exp \left \{ \ln \left [   \pi^y (1-\pi)^{1-y}  \right  ]   \right  \}\\&amp;= \exp  \left \{ \ln   \pi^y  + \ln  (1-\pi)^{1-y}    \right  \}\\&amp;= \exp  \left \{  y \ln \pi +  (1-y)\ln  (1-\pi)   \right  \}\\&amp;= \exp  \left \{  y \ln \pi +  \ln  (1-\pi)  - y \ln  (1-\pi)  \right  \}\\&amp;= \exp  \left \{  y \ln \frac{ \pi} {(1-\pi)} +  \ln  (1-\pi)   \right  \}\end{aligned}\end{align} \]</div>
<p>和指数族的标准形式 <a class="reference internal" href="#equation-eq-glm-121">公式(7.1.3)</a> 进行对比，首先能看出分散函数部分是没有的，也就是相当于</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-15">
<span class="eqno">(7.1.19)<a class="headerlink" href="#equation-glm-source-content-15" title="公式的永久链接"></a></span>\[a(\phi) =  1\]</div>
<p>不同于高斯分布，伯努利分布没有分散参数，或者是分散参数是常量 <span class="math notranslate nohighlight">\(1\)</span>
。事实上，指数族中大部分离散分布都是没有额外的分散参数的。</p>
<p>接下来，看下自然参数 <span class="math notranslate nohighlight">\(\theta\)</span> 和原始参数 <span class="math notranslate nohighlight">\(\pi\)</span> 之间的关系。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-16">
<span class="eqno">(7.1.20)<a class="headerlink" href="#equation-glm-source-content-16" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\theta &amp;= \ln \frac{ \pi} {1-\pi}\\ \pi &amp;=  \frac{\exp\{\theta\} }{ 1+ \exp\{\theta\}  }\end{aligned}\end{align} \]</div>
<p>然后是累积分布函数 <span class="math notranslate nohighlight">\(b(\theta)\)</span>
，</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-17">
<span class="eqno">(7.1.21)<a class="headerlink" href="#equation-glm-source-content-17" title="公式的永久链接"></a></span>\[b(\theta) = - \ln(1-\pi) = \ln ( 1 + \exp \{\theta\})\]</div>
<p>再来看它的期望。注意，这里 <span class="math notranslate nohighlight">\(b'(\theta)\)</span> 是对 <span class="math notranslate nohighlight">\(\theta\)</span> 的导数，不是对 <span class="math notranslate nohighlight">\(\pi\)</span> 的导数。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-18">
<span class="eqno">(7.1.22)<a class="headerlink" href="#equation-glm-source-content-18" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\mathbb{E}[Y] &amp;=b'(\theta)\\&amp;=  \frac{1}{ 1 + \exp \{\theta\} } \cdot 1 \cdot  \exp \{\theta\}\\&amp;=   \frac{ \exp \{\theta\}}{ 1 + \exp \{\theta\} }\\&amp;=  \pi \triangleq \mu\end{aligned}\end{align} \]</div>
<p>从这可以看出，对于伯努利分布，原始参数 <span class="math notranslate nohighlight">\(\pi\)</span> 就是它的期望参数 <span class="math notranslate nohighlight">\(\mu\)</span>
。最后，伯努利分布的方差为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-19">
<span class="eqno">(7.1.23)<a class="headerlink" href="#equation-glm-source-content-19" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}Var(Y) &amp;= a(\phi) \nu(\mu)\\&amp;= b''(\theta)\\&amp;= \pi(1-\pi) \triangleq  \mu(1-\mu)\end{aligned}\end{align} \]</div>
<p>从中可以看出，伯努利分布是没有额外的分散参数的，同时它的方差是和期望成二次关系。
这个特性会产生很大的影响，之后的章节会详细讨论这个问题。</p>
</section>
</section>
<section id="id6">
<h2><span class="section-number">7.2. </span>广义线性模型<a class="headerlink" href="#id6" title="永久链接至标题"></a></h2>
<p>我们在学习统计分析、数据挖掘、机器学习等领域相关内容时，入门模型就是线性回归模型，
除此之外还有逻辑回归，泊松回归，二项式回归等等，实际上这些都是线性模型。
这些模型都是由不同的人提出的，我们也是一个一个去学习的，并在不同的场景下去应用。
后来有人发现，这些模型其实都是一家人，到1972年，<code class="docutils literal notranslate"><span class="pre">John</span> <span class="pre">Nelder</span></code> 和 <code class="docutils literal notranslate"><span class="pre">Robert</span> <span class="pre">Wedderburn</span></code> 提出了一种模型框架：广义线性模型
。这些常见的回归模型都可以纳入到这个框架解释，并用统一的参数估计方法去估计模型参数。
广义线性模型直接用指数族的标准形式对随机变量 <span class="math notranslate nohighlight">\(Y\)</span> 进行建模，
不同的回归模型意味着随机变量 <span class="math notranslate nohighlight">\(Y\)</span> 是不同的指数族分布而已。</p>
<p>在 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 框架中，我们假设响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 是服从指数族分布的，
我们的目的是通过输入变量 <span class="math notranslate nohighlight">\(X\)</span> 预测响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 的值，
并且GLM是线性模型，也就是通过输入变量 <span class="math notranslate nohighlight">\(X\)</span> 的线性组合预测 <span class="math notranslate nohighlight">\(Y\)</span> 。</p>
<p><strong>线性预测器</strong></p>
<p>既然是线性模型，所以显然，
我们需要把多维变量 <span class="math notranslate nohighlight">\(X\)</span> 进行线性组合。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-20">
<span class="eqno">(7.2.1)<a class="headerlink" href="#equation-glm-source-content-20" title="公式的永久链接"></a></span>\[\eta = \beta^T x + b\]</div>
<p><span class="math notranslate nohighlight">\(x\)</span> 可以是一个向量，<span class="math notranslate nohighlight">\(\eta\)</span> 是关于 <span class="math notranslate nohighlight">\(x\)</span> 的
一个线性函数。为了简洁性，通常会人为的为 <span class="math notranslate nohighlight">\(x\)</span> 加入一维常量值1，
并且把截距参数 <span class="math notranslate nohighlight">\(b\)</span> 算在 <span class="math notranslate nohighlight">\(\beta\)</span> 中，
这样上述线性函数可以写成向量內积的形式。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-21">
<span class="eqno">(7.2.2)<a class="headerlink" href="#equation-glm-source-content-21" title="公式的永久链接"></a></span>\[\eta = \beta^T x\]</div>
<p>在广义线性模型中，通常把 <span class="math notranslate nohighlight">\(\eta\)</span> 成为线性预测器。</p>
<p><strong>连接函数</strong></p>
<p>回顾一下我们的初衷，我们需要用输入变量 <span class="math notranslate nohighlight">\(X\)</span> 的线性结果 <span class="math notranslate nohighlight">\(\eta\)</span> 去预测输出变量 <span class="math notranslate nohighlight">\(Y\)</span> 的值，
<span class="math notranslate nohighlight">\(Y\)</span> 是一个指数族的 <strong>随机变量</strong> ，对于一个随机变量，其值可以是其值域空间中任意的一个值，
只不过每个值的概率可能不同（当然对于均匀分布其每个值的概率是相同的）。
但是，我们期望得到 <span class="math notranslate nohighlight">\(Y\)</span> 的一个具体的值，显然随机变量 <span class="math notranslate nohighlight">\(Y\)</span> 的期望值是最好不过选择。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-22">
<span class="eqno">(7.2.3)<a class="headerlink" href="#equation-glm-source-content-22" title="公式的永久链接"></a></span>\[\mu = \mathbb{E}[Y]\]</div>
<p>现在，我们需要通过 <span class="math notranslate nohighlight">\(\eta\)</span> 得到 <span class="math notranslate nohighlight">\(\mu\)</span> ，然后把 <span class="math notranslate nohighlight">\(\mu\)</span> 作为模型的输出值，
也就是模型预测出的 <span class="math notranslate nohighlight">\(Y\)</span> 的值。
那要如何做到呢？显然，可以定义一个函数，将两者连接起来。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-23">
<span class="eqno">(7.2.4)<a class="headerlink" href="#equation-glm-source-content-23" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\eta &amp;= g(\mu)\\\mu &amp;= g^{-1}(\eta)\end{aligned}\end{align} \]</div>
<p>在 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 框架中，把函数 <span class="math notranslate nohighlight">\(g\)</span> 称为连接函数(link function)，
连接函数 <span class="math notranslate nohighlight">\(g\)</span> 是用来连接线性预测器 <span class="math notranslate nohighlight">\(\eta\)</span> 和均值 <span class="math notranslate nohighlight">\(\mu\)</span> 的。
连接函数的反函数 <span class="math notranslate nohighlight">\(g^{-1}\)</span> 可以称为响应函数(response function)，或者激活函数(active function)，
连接函数可以有很多种选择。
在高斯线性模型（传统线性回归模型）中，连接函数是恒等函数 <span class="math notranslate nohighlight">\(\eta=g(\mu)=\mu\)</span> 。
在泊松分布中，均值 <span class="math notranslate nohighlight">\(\mu\)</span> 必须是正的，所以 <span class="math notranslate nohighlight">\(\eta=\mu\)</span> 不再适用，因为 <span class="math notranslate nohighlight">\(\eta=\beta^Tx\)</span>
的取值范围值整个实数域。对于泊松分布，连接函数可以选择对数函数 <span class="math notranslate nohighlight">\(\eta=log \mu\)</span> ，此时 <span class="math notranslate nohighlight">\(\mu=e^{\eta}\)</span>
确保了 <span class="math notranslate nohighlight">\(\mu\)</span> 为正数。
<strong>连接函数本质上，就是把实数域范围的</strong> <span class="math notranslate nohighlight">\(\eta\)</span> <strong>转换到特定分布合法的</strong> <span class="math notranslate nohighlight">\(\mu\)</span> <strong>值空间上。</strong></p>
<p><strong>广义线性模型</strong></p>
<p>显然，一个广义线性模型有三个关键组件：</p>
<ol class="arabic simple">
<li><p>一个线性预测器 <span class="math notranslate nohighlight">\(\eta=\beta^T x\)</span> ，被称为系统组件(systematic component)。</p></li>
<li><p>一个指数族分布作为响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 概率分布 <span class="math notranslate nohighlight">\(P(Y;\theta)\)</span> ，被称为随机组件(random component)。</p></li>
<li><p>一个连接函数 <span class="math notranslate nohighlight">\(g\)</span> 使得 <span class="math notranslate nohighlight">\(\eta=g(\mu)\)</span> ，<span class="math notranslate nohighlight">\(\mu\)</span> 是 <span class="math notranslate nohighlight">\(Y\)</span> 的期望，连接函数描述系统组件和随机组件之间的关系。</p></li>
</ol>
<figure class="align-center" id="id9">
<span id="fg-34-1"></span><a class="reference internal image-reference" href="../../../_images/34_1.jpg"><img alt="../../../_images/34_1.jpg" src="../../../_images/34_1.jpg" style="width: 706.0px; height: 245.0px;" /></a>
<figcaption>
<p><span class="caption-number">图 7.2.1 </span><span class="caption-text">广义线性模型变量之间的关系</span><a class="headerlink" href="#id9" title="永久链接至图片"></a></p>
</figcaption>
</figure>
<p>广义线性模型是对经典线性回归模型的扩展，将输出变量 <span class="math notranslate nohighlight">\(Y\)</span> 的条件概率分布扩展到指数族分布，
<a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#fg-34-1"><span class="std std-numref">图 19.1.1</span></a> 展示了广义线性模型框架下各个变量之间的关系。</p>
<ul class="simple">
<li><p>输入变量 <span class="math notranslate nohighlight">\(X\)</span> 和系数 <span class="math notranslate nohighlight">\(\beta\)</span> 组成一个线性关系， <span class="math notranslate nohighlight">\(\eta=\beta^T x\)</span> ，
<span class="math notranslate nohighlight">\(\eta\)</span> 被称为线性预测器(linear predictor)，<span class="math notranslate nohighlight">\(\beta\)</span> 是定义的未知参数。</p></li>
<li><p>在广义线性模型的框架下，响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 被看做是随机变量，并且其概率分布是指数族分布的一种，<span class="math notranslate nohighlight">\(\theta\)</span> 是分布的自然参数。
<span class="math notranslate nohighlight">\(\theta\)</span> 和 <span class="math notranslate nohighlight">\(\mu\)</span> 存在一一映射关系，我们用函数 <span class="math notranslate nohighlight">\(\psi\)</span> 表示这种关系。</p></li>
<li><p>通过一个连接函数(link function)将 <span class="math notranslate nohighlight">\(\eta\)</span> 和变量 <span class="math notranslate nohighlight">\(Y\)</span> 的期望 <span class="math notranslate nohighlight">\(\mu\)</span> 关联起来，<span class="math notranslate nohighlight">\(\eta=g(\mu)\)</span> ，
函数 <span class="math notranslate nohighlight">\(g\)</span> 称为连接函数。 <span class="math notranslate nohighlight">\(g\)</span> 的反函数就是激活函数(active function)，<span class="math notranslate nohighlight">\(\mu=g^{-1}(\eta)\)</span>
，有的资料中也称为响应函数(response function)、均值函数(mean function)。
激活函数可以是线性的，也可以是非线性的，
比如，经典线性回归模型的激活函数为 <span class="math notranslate nohighlight">\(\mu=g^{-1}(\eta)=\eta\)</span> ，逻辑回归模型的激活函数为 <span class="math notranslate nohighlight">\(\mu=g^{-1}(\eta)=sigmoid(\eta)\)</span> 。</p></li>
</ul>
<p>线性预测器 <span class="math notranslate nohighlight">\(\eta\)</span> 和指数族分布的期望 <span class="math notranslate nohighlight">\(\mu\)</span> 存在函数关系，<span class="math notranslate nohighlight">\(\mu=g^{-1}(\eta)\)</span>
。指数族分布的自然参数 <span class="math notranslate nohighlight">\(\theta\)</span>
又和期望 <span class="math notranslate nohighlight">\(\mu\)</span> 存在着一一映射的关系，<span class="math notranslate nohighlight">\(\theta=\psi(\mu)\)</span>
。因此，指数族分布的自然参数 <span class="math notranslate nohighlight">\(\theta\)</span> 一定是可以转换成一个关于 <span class="math notranslate nohighlight">\(\eta\)</span>
的函数，响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 的概率分布函数可以转化成和 <span class="math notranslate nohighlight">\(\eta\)</span> 相关。</p>
<div class="math notranslate nohighlight" id="equation-eq-34-glm-001">
<span class="eqno">(7.2.5)<a class="headerlink" href="#equation-eq-34-glm-001" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(y|\theta) &amp;= \exp \left \{\frac{\theta y - b(\theta)}{a(\phi)} + c(y,\phi) \right \}\\&amp;= \exp \left \{ \frac{\psi(\mu) y - b(\psi(\mu)}{a(\phi)} + c(y,\phi)  \right \}\\&amp;= \exp \left \{ \frac{ \psi(g^{-1}(\eta)) y - b(   \psi(g^{-1}(\eta)) )}{a(\phi)} + c(y,\phi)  \right \}\\&amp;= \exp \left \{ \frac{ \psi(g^{-1}(\beta^T x)) y - b(   \psi(g^{-1}(\beta^T x)) )}{a(\phi)} + c(y,\phi)  \right \}\\&amp;= P(Y|X;\beta)\end{aligned}\end{align} \]</div>
<p>至此，我们把输入变量 <span class="math notranslate nohighlight">\(X\)</span> 和响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 的概率分布函数连接到了一起，得到了条件概率分布 <span class="math notranslate nohighlight">\(P(Y|X)\)</span>
的概率分布，<a class="reference internal" href="#equation-eq-34-glm-001">公式(7.2.5)</a> 就是广义线性模型的一般形式。</p>
<p><strong>规范连接(canonical link)</strong></p>
<p>观察 <a class="reference internal" href="#equation-eq-34-glm-001">公式(7.2.5)</a> ，如果连接函数 <span class="math notranslate nohighlight">\(g\)</span> 和 <span class="math notranslate nohighlight">\(\psi\)</span> 相同，那么 <span class="math notranslate nohighlight">\(\psi\)</span>
和 <span class="math notranslate nohighlight">\(g^{-1}\)</span> 就互为反函数，二者可以抵消掉，此时满足 <span class="math notranslate nohighlight">\(\theta=\eta\)</span>
，上式就可以简化成如下形式。</p>
<div class="math notranslate nohighlight" id="equation-eq-34-glm-002">
<span class="eqno">(7.2.6)<a class="headerlink" href="#equation-eq-34-glm-002" title="公式的永久链接"></a></span>\[P(Y|X;\beta) = \exp \left \{ \frac{ (\beta^Tx )y - b(\beta^Tx  )}{a(\phi)} + c(y,\phi)  \right \}\]</div>
<p>当连接函数使得 <span class="math notranslate nohighlight">\(\eta=\theta\)</span> 时，称为规范连接(canonical link)函数。
实际上规范连接函数满足 <span class="math notranslate nohighlight">\(\eta=g(\mu)=\psi(\mu)=\theta\)</span> ，
换句话说，对于一个特定的指数族分布，其规范连接函数为 <span class="math notranslate nohighlight">\(g=\psi\)</span> 。
使用规范连接函数可以带来很多统计属性，最直接的就是可以简化参数估计的计算过程。</p>
<p><strong>传统线性回归模型</strong></p>
<p>传统的线性回归模型就是假设响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 服从高斯分布，高斯分布的概率密度函数用指数族的形式表示为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-24">
<span class="eqno">(7.2.7)<a class="headerlink" href="#equation-glm-source-content-24" title="公式的永久链接"></a></span>\[f(y) = \exp \{ \frac{y\mu-\frac{1}{2}\mu^2}{\sigma^2} - \frac{y^2}{2\sigma^2}
- \frac{1}{2} \ln (2\pi\sigma^2) \}\]</div>
<p>和 <a class="reference internal" href="#equation-eq-glm-121">公式(7.1.3)</a> 进行对比，各个标准项为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-25">
<span class="eqno">(7.2.8)<a class="headerlink" href="#equation-glm-source-content-25" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\theta &amp;=\mu\\b(\theta) &amp;= \frac{1}{2}\mu^2\\a(\phi) &amp;= \sigma^2\end{aligned}\end{align} \]</div>
<p>可以看到，高斯分布的自然参数 <span class="math notranslate nohighlight">\(\theta\)</span> 和其期望 <span class="math notranslate nohighlight">\(\mu\)</span> 之间的关系为恒等函数，
即 <span class="math notranslate nohighlight">\(\theta=\mu\)</span> 。
在传统线性回归模型中，连接函数采用的也是恒等函数，因此传统线性回归模型采用的是标准连接函数。
此时满足 <span class="math notranslate nohighlight">\(\theta=\mu=\eta=\beta^Tx\)</span>
，模型预测值 <span class="math notranslate nohighlight">\(\hat{y}\)</span> 为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-26">
<span class="eqno">(7.2.9)<a class="headerlink" href="#equation-glm-source-content-26" title="公式的永久链接"></a></span>\[\hat{y} = \mu = \eta =\beta^Tx\]</div>
<p>此外，传统线性回归模型中假设所有样本的都具有相同的方差，并且方差是常量1，<span class="math notranslate nohighlight">\(\sigma^2=1\)</span>
。</p>
<p>然而，当无法合理地假设数据是正态分布的或者响应变量的结果集有限集时，传统的线性回归模型是不合适的。
此外，在许多情况下，传统线性回归模型的同方差假设是站不住脚的，此时传统线性回归模型也是不合适的。
GLM允许对传统线性回归模型进行扩展，以突破这些限制。
我们可以根据 <span class="math notranslate nohighlight">\(y\)</span> 的数据分布选择合适的指数族概率分布，并且调整连接函数把实数域的 <span class="math notranslate nohighlight">\(\eta\)</span> 值映射到
<span class="math notranslate nohighlight">\(y\)</span> 的值域空间中。
同时我们能够开发一种适用于所有GLM框架下模型的参数估计算法，以应对不同情况下的参数估计问题。</p>
<table class="docutils align-default" id="id10">
<caption><span class="caption-number">表 7.2.1 </span><span class="caption-text">常见连接函数</span><a class="headerlink" href="#id10" title="永久链接至表格"></a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>名称</p></th>
<th class="head"><p>连接函数</p></th>
<th class="head"><p>激活函数(反连接)</p></th>
<th class="head"><blockquote>
<div><p><span class="math notranslate nohighlight">\(\mu\)</span> 的空间</p>
</div></blockquote>
</th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Identity</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\mu\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\eta\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu \in \mathcal{R}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Logit</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\ln\{\mu/(1-\mu)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=e^\eta/(1+e^\eta)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu \in (0,1)\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Log</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\ln(\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=e^\eta\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu &gt;0\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Negative binomial( <span class="math notranslate nohighlight">\(\alpha\)</span>)</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\ln\{\mu/(\mu+1/\alpha)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=e^\eta/\{ \alpha(1-e^\eta)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu &gt;0\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Log-complement</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\ln(1-\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=1-e^\eta\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu &lt;1\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Log-log</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=-ln \{- \ln(\mu)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\exp\{-\exp(-\eta)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu \in (0,1)\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Complementary log-log</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=ln \{- \ln(1-\mu)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=1-\exp\{-\exp(\eta)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu \in (0,1)\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Probit</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\Phi^{-1}(\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\Phi(\eta)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu \in (0,1)\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Reciprocal</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=1/\mu\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=1/\eta\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu \in \mathcal{R}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Power(<span class="math notranslate nohighlight">\(\alpha=-2\)</span>)</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=1/\mu^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=1/\sqrt{\eta}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu &gt;0\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Power(<span class="math notranslate nohighlight">\(\alpha\)</span>) <span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr}\alpha \ne 0\\ \alpha=0 \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\left\{  \begin{array}{lr}\mu^\alpha \\ \ln(\mu) \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\left\{  \begin{array}{lr}\eta^{1/\alpha} \\ \exp(\eta) \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu \in \mathcal{R}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Odds power(<span class="math notranslate nohighlight">\(\alpha\)</span>) <span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr}\alpha \ne 0\\ \alpha=0 \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\left\{  \begin{array}{lr} \frac{\mu/(1-\mu)^\alpha-1}{\alpha} \\ \ln \left( \frac{\mu}{1-\mu} \right) \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\left\{  \begin{array}{lr} \frac{(1+\alpha\eta)^{1/\alpha}}{1+(1+\alpha\eta)^{1/\alpha}} \\ \frac{e^\eta}{1+e^\eta} \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu \in (0,1)\)</span></p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default" id="id11">
<caption><span class="caption-number">表 7.2.2 </span><span class="caption-text">连接函数的导数</span><a class="headerlink" href="#id11" title="永久链接至表格"></a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>名称</p></th>
<th class="head"><p>连接函数</p></th>
<th class="head"><p>一阶导数 <span class="math notranslate nohighlight">\(\triangle=\partial \eta /\partial \mu\)</span></p></th>
<th class="head"><p>二阶导数</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Identity</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\mu\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(0\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Logit</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\ln\{\mu/(1-\mu)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1/\{\mu(1-\mu)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\((2\mu-1)\triangle^2\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Log</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\ln(\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1/\mu\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-\triangle^2\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Negative binomial( <span class="math notranslate nohighlight">\(\alpha\)</span>)</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\ln\{\alpha\mu/(1+\alpha\mu)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1/(\mu+\alpha\mu^2)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-\triangle^2(1+2\alpha\mu)\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Log-complement</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\ln(1-\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-1/(1-\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-\triangle^2\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Log-log</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=-ln \{- \ln(\mu)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-1/\{\mu\ln(\mu)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\{1+\ln(\mu)\}\triangle^2\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Complementary log-log</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=ln \{- \ln(1-\mu)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\{(\mu-1)\ln(1-\mu)\}^{-1}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-\{1+\ln(1-\mu)\}\triangle^2\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Probit</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\Phi^{-1}(\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1/\phi\{\Phi^{-1}(\mu)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\eta\triangle^2\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Reciprocal</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=1/\mu\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-1/\mu^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-2\triangle / \mu\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Power(<span class="math notranslate nohighlight">\(\alpha=-2\)</span>)</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=1/\mu^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-2/\mu^3\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-3\triangle / \mu\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Power(<span class="math notranslate nohighlight">\(\alpha\)</span>) <span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr}\alpha \ne 0\\ \alpha=0 \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\left\{  \begin{array}{lr}\mu^\alpha \\ \ln(\mu) \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} \alpha \mu ^{\alpha-1} \\ 1/\mu \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} (\alpha-1)\triangle/\alpha \\ -\triangle^2  \end{array} \right .\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Odds power(<span class="math notranslate nohighlight">\(\alpha\)</span>) <span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr}\alpha \ne 0\\ \alpha=0 \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\left\{  \begin{array}{lr} \frac{\mu/(1-\mu)^\alpha-1}{\alpha} \\ \ln \left( \frac{\mu}{1-\mu} \right) \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} \frac{\mu^{\alpha-1}}{(1-\mu)^{\alpha+1}} \\ \frac{1}{\mu(1-\mu)} \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} \triangle\left(\frac{1-1/\alpha}{1-\mu} +\alpha+1\right) \\ \mu\triangle^2  \end{array} \right .\)</span></p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default" id="id12">
<caption><span class="caption-number">表 7.2.3 </span><span class="caption-text">激活函数的导数</span><a class="headerlink" href="#id12" title="永久链接至表格"></a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>连接函数名称</p></th>
<th class="head"><p>激活函数(反连接)</p></th>
<th class="head"><p>一阶导数 <span class="math notranslate nohighlight">\(\triangle=\partial \mu /\partial \eta\)</span></p></th>
<th class="head"><p>二阶导数</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Identity</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\eta\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(1\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(0\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Logit</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=e^\eta/(1+e^\eta)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu(1-\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\triangle(1-2\mu)\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Log</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=e^\eta\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\triangle\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Negative binomial( <span class="math notranslate nohighlight">\(\alpha\)</span>)</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=e^\eta/\{ \alpha(1-e^\eta)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu+\alpha\mu^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\triangle(1+2\alpha\mu)\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Log-complement</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=1-e^\eta\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu-1\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\triangle\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Log-log</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\exp\{-\exp(-\eta)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-\mu\ln(\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\triangle\{ 1+\ln(\mu)\}\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Complementary log-log</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=1-\exp\{-\exp(\eta)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\((\mu-1)\ln(1-\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\triangle\{1+\ln(1-\mu)\}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Probit</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\Phi(\eta)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\phi(\eta)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-\triangle \eta\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Reciprocal</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=1/\eta\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-\mu^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-2\triangle\mu\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Power(<span class="math notranslate nohighlight">\(\alpha=-2\)</span>)</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=1/\sqrt{\eta}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-\mu^3/2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(3\triangle^2 / \mu\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Power(<span class="math notranslate nohighlight">\(\alpha\)</span>) <span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr}\alpha \ne 0\\ \alpha=0 \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\left\{  \begin{array}{lr}\eta^{1/\alpha} \\ \exp(\eta) \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} \frac{1}{\alpha} \mu^{1-\alpha} \\  \mu \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} \triangle(1/\alpha -1)/\mu^\alpha \\ \triangle  \end{array} \right .\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Odds power(<span class="math notranslate nohighlight">\(\alpha\)</span>) <span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr}\alpha \ne 0\\ \alpha=0 \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\left\{  \begin{array}{lr} \frac{(1+\alpha\eta)^{1/\alpha}}{1+(1+\alpha\eta)^{1/\alpha}} \\ \frac{e^\eta}{1+e^\eta} \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} \frac{\mu(1-\mu)}{1+\alpha\eta} \\ \mu(1-\mu)  \end{array} \right .\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left\{  \begin{array}{lr} \triangle \left ( 1-2\mu-\frac{\alpha}{1+\alpha\eta}   \right) \\  \triangle(1-2\mu) \end{array} \right .\)</span></p></td>
</tr>
</tbody>
</table>
</section>
<section id="id7">
<h2><span class="section-number">7.3. </span>例子<a class="headerlink" href="#id7" title="永久链接至标题"></a></h2>
<table class="docutils align-default" id="id13">
<caption><span class="caption-number">表 7.3.1 </span><span class="caption-text">常见GLM表(1)</span><a class="headerlink" href="#id13" title="永久链接至表格"></a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>Normal(Gaussian) <span class="math notranslate nohighlight">\(N(\mu,\sigma^2)\)</span></p></th>
<th class="head"><p>Bernoulli <span class="math notranslate nohighlight">\(B(\mu)\)</span></p></th>
<th class="head"><p>Binomial <span class="math notranslate nohighlight">\(B(N,\mu)\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Range of y</p></td>
<td><p>real: <span class="math notranslate nohighlight">\((-\infty,+\infty)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\{0,1\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\{0,\dots,N\}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>f(y)</p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{1}{\sqrt{2\pi\sigma^2}}\exp \{ -\frac{(y-\mu)^2}{2\sigma^2} \}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu^y(1-\mu)^{1-y}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\binom{N}{y}\mu^y(1-\mu)^{N-y}\)</span></p></td>
</tr>
<tr class="row-even"><td><p>EDF</p></td>
<td><p><span class="math notranslate nohighlight">\(\exp\{\frac{\mu y-\frac{\mu^2}{2}}{\sigma^2}-\frac{y^2}{2\sigma^2}-\frac{\ln 2\pi\sigma^2}{2}\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\exp\{y \ln \frac{\mu}{1-\mu} + \ln(1-\mu)\}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\exp\bigg[ \frac{y \ln(\frac{\mu}{1-\mu}) + \ln(1-\mu)}{1/N} + \ln({N \choose y})\bigg]\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\theta=\psi(\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\theta=\mu\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\theta=\ln \left ( \frac{\mu}{1-\mu} \right )=logit(\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\theta=\ln \left ( \frac{\mu}{1-\mu} \right )\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\mu=\psi^{-1}(\theta)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\theta\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\frac{1}{1+e^{-\theta}}=sigmoid(\theta)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\frac{1}{1+e^{-\theta}}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(b(\theta)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\theta^2}{2}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\ln(1+e^{\theta})\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\ln(1+e^{\theta})\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(b(\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\mu^2}{2}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-\ln(1-\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(-\ln(1-\mu)\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Link name</p></td>
<td><p>Identity</p></td>
<td><p>Logit</p></td>
<td><p>Logit</p></td>
</tr>
<tr class="row-even"><td><p>Link function</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\mu\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\ln \left( \frac{\mu}{1-\mu} \right)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\eta=\ln \left( \frac{\mu}{1-\mu} \right)\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Mean function</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\eta\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\frac{1}{1+e^{-\eta}}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=\frac{N}{1+e^{-\eta}}\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\nu(\mu)=b''(\theta)\)</span></p></td>
<td><p>1</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu(1-\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu(1-\mu)\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(a(\phi)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\sigma^2\)</span></p></td>
<td><p>1</p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{1}{N}\)</span></p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default" id="id14">
<caption><span class="caption-number">表 7.3.2 </span><span class="caption-text">常见GLM表(2)</span><a class="headerlink" href="#id14" title="永久链接至表格"></a></caption>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>Categorical <span class="math notranslate nohighlight">\(Cat(K,\mu)\)</span></p></th>
<th class="head"><p>Poisson <span class="math notranslate nohighlight">\(Poisson(\mu)\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Range of y</p></td>
<td><p><span class="math notranslate nohighlight">\(\{1,\dots,K\}\)</span></p></td>
<td><p>integer <span class="math notranslate nohighlight">\(0,1,2,\dots\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>f(y)</p></td>
<td><p><span class="math notranslate nohighlight">\(\prod_{k}\mu_k^{y_k}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\exp\{y\ln \mu - \ln\mu\}\)</span></p></td>
</tr>
<tr class="row-even"><td><p>EDF</p></td>
<td><p><span class="math notranslate nohighlight">\(\exp \left \{ \sum_{k=1}^{K-1} x_k \ln \left ( \frac{\mu_k}{ \mu_K} \right )+ \ln \left  (1-\sum_{k=1}^{K-1} \mu_k \right ) \right \}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\exp\{y\ln \mu - \ln\mu\}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\theta=\psi(\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\theta_k=\ln \left ( \frac{\mu_k}{\mu_K} \right )\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\theta=\ln \mu\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\mu=\psi^{-1}(\theta)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu_k = \frac{e^{\theta_k}}{\sum_{j=1}^K e^{\theta_j}}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu=e^{\theta}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(b(\theta)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\ln \left (  \sum_{k=1}^K e^{\theta_k}  \right )\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(e^{\theta}\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(b(\mu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(- \ln \left  (1-\sum_{k=1}^{K-1} \mu_k \right )\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\ln\mu\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Link name</p></td>
<td><p>Logit</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>Link function</p></td>
<td><p><span class="math notranslate nohighlight">\(\eta_k=\ln \left( \frac{\mu_k}{\mu_K} \right)\)</span></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Mean function</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu_k=\frac{e^{\eta_k}}{\sum_k e^{\eta_k}}\)</span></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\nu(\mu)=b''(\theta)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu_k(1-\mu_k)\)</span></p></td>
<td><p>mu</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(a(\phi)\)</span></p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html" class="btn btn-neutral float-left" title="6. 线性回归模型" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="estimate.html" class="btn btn-neutral float-right" title="8. 参数估计" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2018, zhangzhenhu(acmtiger@outlook.com) 禁止一切形式的转载！.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
  


    <script src="https://utteranc.es/client.js"
            repo="zhangzhenhu/blog"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>



</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>