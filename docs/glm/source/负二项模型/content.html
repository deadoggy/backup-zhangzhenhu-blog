<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>18. 负二项式模型 &mdash; 张振虎的博客 张振虎 文档</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
    <link rel="canonical" href="https://www.zhangzhenhu.com/glm/source/负二项模型/content.html" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/translations.js"></script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"macros": {"RR": "{\\bf R}", "bold": ["{\\bf #1}", 1], "KL": ["{D_\\textrm{KL}\\left ( #1 \\| #2 \\right )}", 2], "EE": ["{\\mathbb{E}_{#1} \\left [ #2 \\right ]}", 2, ""], "scalemath": ["{\\scalebox{#1}{\\mbox{\\ensuremath{\\displaystyle #2}}}}", 2], "argmin": ["{\\operatorname*{\\arg\\min}}"], "ind": ["{\\perp\\!\\!\\!\\!\\perp}"]}}}</script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" />
    <link rel="next" title="19. 零计数问题" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html" />
    <link rel="prev" title="17. 过度分散" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> 张振虎的博客
          </a>
              <div class="version">
                acmtiger@outlook.com
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">目录:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">广义线性模型</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html">1. 概率基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id2">1.1. 概率模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id3">1.1.1. 概率律</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id4">1.1.2. 离散模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id5">1.1.3. 连续模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id6">1.2. 条件概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id7">1.3. 联合概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id8">1.4. 全概率与贝叶斯定理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id9">1.5. 独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id10">1.6. 随机变量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id11">1.6.1. 离散随机变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id12">1.6.2. 连续随机变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id13">1.6.3. 累积分布函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id14">1.6.4. 随机变量的函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id15">1.6.5. 期望与方差</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id16">1.7. 边缘化</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id17">1.8. 常见概率分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#ch-basic-bernoulli">1.8.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id19">1.8.2. 二项式分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id20">1.8.3. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id21">1.8.4. 多项式分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id22">1.8.5. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id23">1.8.6. 卡方分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#t">1.8.7. t分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#f">1.8.8. F分布</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html">2. 最大似然估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#ch-liklihood">2.1. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id3">2.2. 伯努利分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id4">2.3. 类别分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#ch-2-gaussian-ml">2.4. 高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id6">2.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html">3. 推断与检验</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id2">3.1. 统计量和充分统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-sample-distribution">3.2. 抽样分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-sample-distribution-normal">3.2.1. 正态分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#t">3.2.2. 学生t分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id5">3.2.3. 卡方分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id6">3.3. 极限理论</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id7">3.3.1. 马尔可夫和切比雪夫不等式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id8">3.3.2. 弱大数定律</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id9">3.3.3. 依概率收敛</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-clt">3.3.4. 中心极限定理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id11">3.3.5. 强大数定理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id12">3.4. 似然估计量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id13">3.4.1. 估计量的偏差与方差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-2-fisher-information">3.4.2. 信息量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-2-mle-estimator">3.4.3. 最大似然估计的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-influence-test-interval">3.5. 置信区间</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#z">3.5.1. 均值参数的 Z 区间估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id18">3.5.2. 均值参数的 T 区间估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id19">3.5.3. 方差参数的区间估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-influence-test-test">3.6. 简单假设检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id22">3.6.1. Z检验</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id23">3.6.2. T检验</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id24">3.6.3. 卡方检验</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html">4. 贝叶斯估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id2">4.1. 贝叶斯估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id3">4.1.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id4">4.1.2. 类别分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id5">4.2. 最大后验估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id6">4.2.1. 伯努利变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id7">4.2.2. 类别变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/content.html#id8">4.3. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html">5. 指数族</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#ch-24-1">5.1. 指数族的定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id3">5.1.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id4">5.1.2. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id5">5.1.3. 泊松分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id6">5.1.4. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id7">5.1.5. 其它常见指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#ch-24-moments">5.2. 指数族的期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id9">5.3. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#kl">5.4. 最大似然估计与KL散度的关系</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html">6. 线性回归模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id2">6.1. 最小二乘</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id3">6.1.1. 最小误差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id4">6.1.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id5">6.2. 线性回归的概率解释</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id6">6.2.1. 高斯假设</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id7">6.2.2. 参数估计</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html">7. 广义线性模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id2">7.1. 指数族分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id3">7.1.1. 自然指数族</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id4">7.1.2. 示例：高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id5">7.1.3. 示例：伯努利分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id6">7.2. 广义线性模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id7">7.3. 例子</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html">8. 参数估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#ch-glm-estimate">8.1. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id3">8.2. 泰勒级数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id4">8.3. 梯度下降法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id6">8.4. 牛顿法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id7">8.4.1. 算法推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id8">8.4.2. 标准连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id9">8.4.3. 迭代初始值的设定</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#irls">8.5. 迭代重加权最小二乘(IRLS)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id10">8.5.1. 算法推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id11">8.5.2. 算法过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id12">8.6. 估计量的标准误差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#ch-glm-estimate-phi">8.7. 分散参数的估计</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html">9. 模型评估</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#id2">9.1. 拟合优度</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#id3">9.1.1. 嵌套模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#likelihood-ratio">9.1.2. 对数似然比(Likelihood ratio)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#deviance">9.1.3. 偏差(deviance)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#r-2">9.1.4. 决定系数 <span class="math notranslate nohighlight">\(R^2\)</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#ch-glm-gof-chi">9.1.5. 广义皮尔逊卡方统计量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#residual-analysis">9.2. 残差分析(Residual analysis)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#response-residuals">9.2.1. Response residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#working-residuals">9.2.2. Working residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#partial-residuals">9.2.3. Partial residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#pearson-residuals">9.2.4. Pearson residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#deviance-residuals">9.2.5. Deviance residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#score-residuals">9.2.6. Score residuals</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#model-selection">9.3. 模型选择(model selection)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#aic">9.3.1. AIC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#bic">9.3.2. BIC</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html">10. 模型检验</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id2">10.1. 拉格朗日乘子检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id3">10.1.1. 得分统计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id4">10.1.2. 检验过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#wald">10.2. wald 检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id5">10.2.1. 参数估计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id6">10.2.2. 检验过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id7">10.3. 似然比检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id8">10.3.1. 抽样分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id9">10.3.2. 模型比较</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id10">10.3.3. 偏差统计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#f">10.3.4. F 检验</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id11">10.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html">11. 高斯模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id2">11.1. 传统线性回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id3">11.2. 高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id4">11.3. 高斯回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id5">11.4. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id6">11.4.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#irls">11.4.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id7">11.4.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id10">11.5. 其它连接函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html">12. 逆高斯模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id2">12.1. 逆高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id3">12.2. 逆高斯回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id4">12.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id5">12.3.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#irls">12.3.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id6">12.3.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id7">12.4. 其它连接函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html">13. 二项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id2">13.1. 伯努利分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id3">13.2. 逻辑回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id4">13.2.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id5">13.2.2. 参数估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#odds-logit">13.2.3. odds 与 logit</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id6">13.3. 二项式分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id7">13.4. 二项式回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id8">13.4.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id9">13.4.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id10">13.5. 其它连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id11">13.5.1. 恒等连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#probit">13.5.2. probit 回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#log-log-clog-log">13.5.3. log-log 和 clog-log</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id12">13.6. 分组数据与比例数据</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html">14. 泊松模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#poisson">14.1. 泊松(Poisson)分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id2">14.1.1. 推导过程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id3">14.1.2. 泊松分布的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id5">14.2. 泊松回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id6">14.3. 参数估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id7">14.4. 拟合统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id8">14.5. 频率模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id9">14.6. 泊松模型的局限性</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html">15. 指数模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#exponential">15.1. 指数(exponential)分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id2">15.1.1. 推导过程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id3">15.1.2. 分布的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id6">15.2. 指数回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id7">15.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id8">15.3.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id9">15.3.2. 拟合优度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#irls">15.3.3. IRLS</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html">16. Gamma 模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id1">16.1. Gamma 函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id2">16.2. Gamma 分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id3">16.3. Gamma 回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id4">16.4. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id5">16.4.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#irls">16.4.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id6">16.4.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id7">16.5. 其他连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id8">16.5.1. 对数 Gamma 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#identity-gamma">16.5.2. 恒等(identity) Gamma 模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html">17. 过度分散</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id2">17.1. 什么是过度分散</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id3">17.2. 过度分散的检测</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id4">17.3. 过度分散的影响</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id5">17.4. 标准误差的修正</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">18. 负二项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">18.1. 负二项式分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">18.1.1. 从二项式分布推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">18.1.2. 泊松-伽马混合分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="#alpha">18.1.3. 辅助参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的影响</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id5">18.2. 负二项回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">18.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#irls">18.3.1. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id7">18.3.2. 参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id8">18.4. 负二项式模型扩展</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id9">18.4.1. 对数连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id10">18.4.2. 参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id11">18.4.3. 几何模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id12">18.4.4. 广义负二项式模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html">19. 零计数问题</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id2">19.1. 零截断模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id3">19.1.1. 零截断泊松模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id4">19.1.2. 零截断负二项式模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id5">19.2. 零膨胀模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#hurdle">19.2.1. Hurdle 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#zero-inflate">19.2.2. Zero-inflate 模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html">20. 多项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id2">20.1. 类别分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#softmax">20.2. softmax 回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id3">20.2.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id4">20.2.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id5">20.3. 多项式分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id6">20.4. 多项式回归模型</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html">21. 有序离散模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id2">21.1. 有序逻辑回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id3">21.2. 参数估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id4">21.3. 连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#logit">21.3.1. logit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#probit">21.3.2. probit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#clog-log">21.3.3. clog-log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#log-log">21.3.4. log-log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#cauchit">21.3.5. cauchit</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id5">21.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html">附录</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html#id2">标准正态累积分布表</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html#id3">卡方分布临界值表</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/content.html">参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../probability_model/index_html.html">概率图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html">1. 概率基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id2">1.1. 概率分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id3">1.2. 独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#marginalization">1.3. 边缘化(marginalization)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id6">1.4. 贝叶斯定理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id7">1.5. 期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id8">1.6. 常见概率分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id9">1.6.1. 离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id10">1.6.2. 连续变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id11">1.6.3. 计数变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id12">1.7. 大数定律</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id13">1.7.1. 独立同分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id14">1.7.2. 中心极限定理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id15">1.8. 信息论基础</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id16">1.8.1. 信息熵</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#kl">1.8.2. KL散度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id18">1.8.3. 互信息</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html">2. 参数估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-liklihood">2.1. 极大似然估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id3">2.1.1. 二值离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id4">2.1.2. 一般离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-2-gaussian-ml">2.1.3. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id6">2.1.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-bayesian-estimation">2.2. 贝叶斯估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id8">2.2.1. 伯努利变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id9">2.2.2. 类别变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id10">2.3. 最大后验估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id11">2.3.1. 伯努利变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id12">2.3.2. 类别变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id13">2.4. 最大似然估计与贝叶斯估计的对比</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id14">2.5. 统计量和充分统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#fisher-information">2.6. Fisher Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id15">2.7. 估计量的评价</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id16">2.7.1. 估计量的方差与偏差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id17">2.7.2. 大数定律和中心极限定理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-2-mle-estimator">2.7.3. 最大似然估计的特性</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html">3. 指数族</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#ch-24-1">3.1. 指数族的定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id3">3.1.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id4">3.1.2. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id5">3.1.3. 泊松分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id6">3.1.4. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id7">3.1.5. 其它常见指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#ch-24-moments">3.2. 指数族的期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id9">3.3. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#kl">3.4. 最大似然估计与KL散度的关系</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/19.%E5%A4%9A%E7%BB%B4%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83_26.html">4. 多维高斯分布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html">5. 有向图(Directed Graphical Models)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id1">5.1. 有向图</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id2">5.2. 条件独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id3">5.3. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html">6. 无向图(Undirected Graphical Models)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id1">6.1. 无向图的定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id2">6.2. 条件独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id3">6.3. 图的分解</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#vs">6.4. 有向图 vs 无向图</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id4">6.5. 树</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id5">6.6. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html">7. 因子图</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id2">7.1. 因子图的定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id3">7.2. 图模型之间的转换</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id4">7.2.1. 转换为因子图</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id5">7.2.2. 因子图转换为有向图</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id6">7.3. 图模型的评价</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#i-map">7.3.1. I-map</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#d-map">7.3.2. D-map</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#p-map">7.3.3. P-map</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html">8. 模型推断：消元法</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id2">8.1. 什么是模型的推断</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id3">8.2. 消元法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id4">8.2.1. 有向图消元算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#ch-condition-margin">8.2.2. 条件概率和边缘概率</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id6">8.2.3. 无向图的消元法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id7">8.3. 图消除</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id9">8.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html">9. 加和乘积算法(sum-product algorithm)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id1">9.1. 树结构</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id2">9.2. 从消元法到信息传播</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id3">9.3. 树模型的和积算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id4">9.4. 因子图的和积算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id5">9.5. 类树结构图模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#polytrees">9.6. 多重树(polytrees)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id6">9.7. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html">10. 最大后验估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id2">10.1. 最大后验概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id3">10.2. 最大化后验的状态</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id4">10.3. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html">11. 完整观测的参数学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id2">11.1. 有向图的参数学习</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id3">11.2. 无向图的参数学习</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id4">11.2.1. 成对二值变量模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id5">11.2.2. 一般二值变量模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html">12. 不完整观测的学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html#id2">12.1. 隐变量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html#em">12.2. 期望最大化算法(EM)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/14.%E5%9B%BE%E5%BD%A2%E7%BB%93%E6%9E%84%E7%9A%84%E5%AD%A6%E4%B9%A0_lecture_23.html">13. 有向图结构学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/16.%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD_lecture_17.html">14. 变分推断</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html">15. 马尔科夫蒙特卡洛</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#why-sampling">15.1. Why sampling？</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#monte-carlo">15.2. 蒙特卡罗(Monte Carlo)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#markov-chain">15.3. 马尔科夫链(Markov Chain)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id2">15.3.1. 一个例子</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#time-reversibility">15.3.2. 时间可逆性(Time Reversibility)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id3">15.3.3. 总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#markov-chain-monte-carlo">15.4. Markov Chain Monte Carlo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#metropolis-hastings">15.4.1. Metropolis-Hastings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id4">15.4.2. 例子：正态分布的采样</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id5">15.4.3. 多变量采样</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#gibbs">15.4.4. Gibbs 采样</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#mixing-time">15.5. Mixing Time</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#approximate-map-and-partitioning">15.6. Approximate MAP and Partitioning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html">16. 贝叶斯分类器</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id2">16.1. 朴素贝叶斯模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id3">16.1.1. 模型表示</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id4">16.1.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id5">16.2. 高斯判别模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id6">16.2.1. 一元高斯模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id7">16.2.2. 多元高斯模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id8">16.3. 逻辑回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id9">16.4. 生成模型和判别模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id10">16.5. 多分类</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id11">16.6. 其它扩展</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html">17. 回归模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id2">17.1. 机器学习的概率解释</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id3">17.2. 经典线性回归</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id4">17.2.1. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id5">17.3. 线性回归的概率解释</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id6">17.3.1. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id7">17.4. 凸函数最优化问题</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id8">17.5. 岭回归</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html">18. 分类模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id2">18.1. 生成模型与判别模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id3">18.2. 线性回归与线性分类</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id4">18.3. 生成模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id5">18.3.1. 高斯判别模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id6">18.3.2. 朴素贝叶斯模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id7">18.3.3. 指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id8">18.4. 判别模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id9">18.4.1. 逻辑回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id10">18.4.2. 多分类</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id11">18.4.3. 最大熵模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#probit">18.4.4. Probit 回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#noisy-or">18.4.5. Noisy-OR 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id12">18.4.6. 其它指数模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html">19. 广义线性模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id2">19.1. 定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id3">19.1.1. 指数族分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id4">19.1.2. 链接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id5">19.1.3. 例子</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id6">19.2. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id7">19.2.1. 梯度下降法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id8">19.2.2. 牛顿法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#irls">19.2.3. 迭代重加权最小二乘(IRLS)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#goodness-of-fit">19.3. goodness of fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id9">19.4. 连续值响应模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id10">19.4.1. 高斯族</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#gamma">19.4.2. Gamma族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id12">19.5. 二项响应模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id13">19.6. 多项响应模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id14">19.7. 计数响应模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id15">19.7.1. 泊松分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id16">19.8. GLM扩展</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html">20. 混合模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id2">20.1. 一般混合模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id3">20.1.1. 模型的有向图表示</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id5">20.1.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id8">20.2. 高斯混合模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id9">20.2.1. 模型的表示</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id10">20.2.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#k-means">20.3. K-means</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/32.%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90_42.html">21. 因子分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/%E4%BA%8C%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B.html">22. 二变量模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/33.LDA_43.html">23. 主题模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/33.LDA_43.html#plsa">23.1. PLSA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/33.LDA_43.html#lda">23.2. LDA</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html">24. 隐马尔可夫模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id2">24.1. 隐马尔可夫模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id3">24.1.1. 马尔可夫模型和朴素贝叶斯模型的关系</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id4">24.2. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/27.%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA_37.html">25. 条件随机场</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/28.%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%99%A8_38.html">26. 卡尔曼滤波器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/40.%E9%A1%B9%E7%9B%AE%E5%8F%8D%E5%BA%94%E7%90%86%E8%AE%BA_50.html">27. 项目反应理论</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/41.%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA_51.html">28. 贝叶斯知识追踪</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE.html">29. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../aigc/index.html">AI内容生成（ai-gc）</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html">1. 变分自编码器（Variational Autoencoder）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#evidence-lower-bound-elbo">1.1. 证据下界(Evidence Lower Bound,ELBO)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#id2">1.2. 编码-解码</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#id3">1.3. 总结</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#em">1.3.1. 和EM算法的关系</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#variational">1.3.2. 为什么叫变分（variational）？</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#vq-vae">1.4. VQ-VAE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html#id4">1.5. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html">2. 扩散概率模型（diffusion probabilistic models）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#diffusion-probabilistic-model">2.1. 扩散概率模型（diffusion probabilistic model）</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#markovian-hierarchical-variational-autoencoder-mhvae">2.1.1. 马尔科夫分层自编码器（Markovian Hierarchical Variational Autoencoder,MHVAE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#id6">2.1.2. 扩散模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#id8">2.1.3. 前向-后向</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#elbo">2.1.4. 目标函数（ELBO）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#id14">2.1.5. 图片生成（采样）过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#denoising-diffusion-probabilistic-model-ddpm">2.2. 降噪扩散概率模型（Denoising diffusion probabilistic model,DDPM）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#score-based-ddpm">2.3. 基于分数的解释（Score-based DDPM）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#id23">2.4. 扩散模型的三种等价表示</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#improved-denoising-diffusion-probabilistic-models-iddpm">2.5. 改进降噪扩散概率模型（Improved Denoising Diffusion Probabilistic Models,IDDPM）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B.html#id24">2.6. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../aigc/ddim.html">3. 去噪扩散隐式模型（Denoising Diffusion Implicit Models,DDIM）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/ddim.html#id1">3.1. 扩散模型的回顾</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/ddim.html#id2">3.2. 非马尔科夫前向过程</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/ddim.html#id4">3.3. 加速采样</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/ddim.html#id5">3.4. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../aigc/Score-Based_Generative_Models.html">4. 基于分数的生成模型（Score-based generative models）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/Score-Based_Generative_Models.html#id4">4.1. 基于分数的生成模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/Score-Based_Generative_Models.html#score-matching">4.1.1. 分数匹配算法（Score Matching）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/Score-Based_Generative_Models.html#id8">4.1.2. 基于分数的生成模型面临的困难</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/Score-Based_Generative_Models.html#id12">4.1.3. 通过加噪的方法估计分布的近似分数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/Score-Based_Generative_Models.html#id13">4.1.4. 基于分数的改进采样算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/Score-Based_Generative_Models.html#id15">4.1.5. 改进的分数生成模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/Score-Based_Generative_Models.html#id17">4.2. 随机微分方程</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/Score-Based_Generative_Models.html#id18">4.2.1. 微分方程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/Score-Based_Generative_Models.html#id19">4.2.2. 随机微分方程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/Score-Based_Generative_Models.html#id20">4.2.3. 基于随机微分方程的生成模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/Score-Based_Generative_Models.html#id21">4.3. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../aigc/Guidance.html">5. 条件控制扩散模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/Guidance.html#classifier-guidance">5.1. classifier guidance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/Guidance.html#classifier-free-guidance">5.2. Classifier-free guidance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/Guidance.html#clip-guidance">5.3. CLIP Guidance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../aigc/Guidance.html#id12">5.3.1. 参考文献</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../aigc/%E7%A8%B3%E5%AE%9A%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B.html">6. 稳定扩散模型（Stable diffusion model）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E7%A8%B3%E5%AE%9A%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B.html#latent-diffusion-model-ldm">6.1. 潜在扩散模型（Latent diffusion model,LDM）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E7%A8%B3%E5%AE%9A%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B.html#stable-diffusion-probabilistic-model-sdm">6.2. 稳定扩散模型（Stable diffusion probabilistic model,SDM）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/%E7%A8%B3%E5%AE%9A%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B.html#id3">6.3. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../aigc/dalle2.html">7. DALL·E 2</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/dalle2.html#glide">7.1. GLIDE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/dalle2.html#unclip">7.2. Unclip</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../aigc/dalle2.html#id1">7.3. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../aigc/imgen.html">8. Imagen</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../audio/index.html">语音技术</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../audio/feature.html">1. 音频特征</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id2">1.1. 认识声音</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id3">1.2. 认识声波</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id4">1.2.1. 物体的振动以及简谐振动</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id7">1.2.2. 什么是声波</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id8">1.2.3. 纯音和复合音</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#spectrum">1.2.4. 频谱 Spectrum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id10">1.2.5. 名词</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id13">1.3. 语音学</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id14">1.3.1. 发声原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id15">1.3.2. 听觉感应</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id16">1.4. 数字信号处理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id17">1.4.1. 模数转换</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#wav">1.4.2. 音频文件–WAV</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id18">1.5. 分帧与加窗</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id19">1.5.1. 预加重处理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id20">1.5.2. 分帧与加窗处理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id21">1.6. 声音的感官度量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#sound-pressure-level-spl">1.6.1. 声压与声压级(Sound Pressure Level,SPL)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#intensity-level-il">1.6.2. 声强与声强级(Intensity Level,IL）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id22">1.6.3. 声压与声强的关系</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id23">1.6.4. 响度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id24">1.6.5. 音量计算</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id25">1.6.6. 频率与音高</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id26">1.7. 时域分析</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id27">1.7.1. 短时能量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id28">1.7.2. 短时平均幅度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id29">1.7.3. 短时过零率</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id31">1.8. 频域分析</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#spectrum-spectrogram">1.8.1. 声谱(spectrum)和时频谱(spectrogram)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#short-time-fourier-transform-stft">1.8.2. 短时傅里叶变换 Short-time Fourier transform (STFT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id33">1.8.3. 倒频谱</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id34">1.8.4. 色谱图</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id35">1.9. 小波域特征</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id36">1.9.1. 离散小波域变换</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id37">1.9.2. 小波域过零率</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id38">1.9.3. 小波域质心</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id39">1.9.4. 小波域子带能量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#mfcc">1.10. 语音识别的音频特征–MFCC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id40">1.11. 参考资料</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../edm/index.html">教育领域数据挖掘</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../edm/bkt.html">1. 贝叶斯知识追踪(Bayesian Knowledge Tracing,BKT)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id1">1.1. 简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#hidden-markov-model-hmm">1.2. 隐马尔科夫模型(Hidden Markov Model,HMM)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#bayesian-knowledge-tracing">1.3. 贝叶斯知识追踪(Bayesian Knowledge Tracing)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#bkt">1.3.1. BKT的参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#item-response-theory-irt">1.4. 项目反映理论(Item Response Theory,IRT)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#bktirt">1.5. BKT结合IRT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id5">1.6. 实验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id6">1.6.1. 数据集</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id7">1.6.2. 实验方法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id8">1.6.3. 实验结果</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id9">1.6.4. 项目代码</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id10">1.7. 未来工作</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id11">1.7.1. 题目难度的计算</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#irt">1.7.2. 多参数IRT模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id12">1.7.3. 参数估计算法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id13">1.8. 参考文献</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../nlp/index.html">自然语言处理</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html">1. 文本去重</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id2">1.1. 背景</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id3">1.2. 技术思路</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id4">1.3. 相似（距离）算法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#euclidean-distance">1.3.1. 欧氏距离（Euclidean Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#minkowski-distance">1.3.2. 闵科夫斯基距离（Minkowski Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#manhattan-distance">1.3.3. 曼哈顿距离（Manhattan Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#chebyshev-distance">1.3.4. 切比雪夫距离（Chebyshev Distance ）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#mahalanobis-distance">1.3.5. 马氏距离(Mahalanobis Distance)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#cosine-similarity">1.3.6. 余弦夹角相似度(Cosine Similarity)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#hamming-distance">1.3.7. 汉明距离（Hamming Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#jaccard">1.3.8. Jaccard 系数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id5">1.3.9. 编辑距离</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id6">1.3.10. 最长公共字串</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id7">1.3.11. 最长公共子序列</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id8">1.4. 文本去重</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#kshingle">1.4.1. KShingle算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#minhash">1.4.2. Minhash算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#simhash">1.4.3. simhash</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#ksentence">1.4.4. KSentence算法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id9">1.5. 话术去重</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../nlp/bert/content.html">2. Attention&amp;Transformer&amp;Bert 简介</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/bert/content.html#transformer">2.1. Transformer 从宏观到微观</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#seq2seq">2.1.1. seq2seq</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#id1">2.1.2. 模型的输入</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/bert/content.html#self-attention">2.2. Self-Attention</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#id2">2.2.1. 什么是注意力？</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#id3">2.2.2. 加权求和</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#id4">2.2.3. 位置编码</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#multi-head">2.2.4. 多头注意力（Multi-head）</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/bert/content.html#attention">2.3. Attention 机制</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/bert/content.html#id5">2.4. 其它参考资料</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../rst_tutorial/latex.html">latex demo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../rst_tutorial/latex.html#latex">latex</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rst_tutorial/latex.html#how-to-write-an-m-x-n-matrix-in-latex">How to write an m x n matrix in LaTeX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-big-parentheses">With big parentheses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-parentheses">With parentheses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-brackets">With brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#latex-matrix-with-no-bracket">LateX matrix with no bracket</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-vertical-bar-brackets">With vertical bar brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-curly-brackets">with curly brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-double-vertical-bar-brackets">with double vertical bar brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#small-inline-matrix">small inline matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#examples-matrix-2-x-2-in-latex">Examples matrix 2 x 2 in LaTeX</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../rst_tutorial/graphviz.html">graphviz demo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../rst_tutorial/graphviz.html#id1">布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rst_tutorial/graphviz.html#id2">其它</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/index.html">读书笔记</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/index.html">《统计因果推断推理入门》读书笔记</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html">1. 第三章 干预的效果</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html#id2">1.1. 第3.1节 干预</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html#id3">1.2. 第3.2节 校正公式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html#id8">1.3. 第3.3节 后门准则</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html">《深度学习推荐系统》读书笔记</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id2">重点</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id3">冷启动</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id4">探索与利用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id5">召回层的主要策略</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#embedding">协同过滤 &amp; Embedding 向量</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">张振虎的博客</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">广义线性模型</a> &raquo;</li>
      <li><span class="section-number">18. </span>负二项式模型</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/glm/source/负二项模型/content.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1><span class="section-number">18. </span>负二项式模型<a class="headerlink" href="#id1" title="永久链接至标题"></a></h1>
<p>在计数数据中，应用最广泛的是泊松模型，
而泊松模型假设模型的方差和期望相等，<span class="math notranslate nohighlight">\(V(Y)=\mu\)</span>
这在多数情况下是无法满足的，大多数计数数据的方差和期望是不相等的，
比较常见的是方差大于期望，称之为过度分散现象。
面对过度分散的数据，传统的泊松模型就不太适合了。
本周讨论另一种计数模型，负二项式模型，它的方差为
<span class="math notranslate nohighlight">\(V(Y) = \mu+\alpha \mu^2\)</span>
，其模型方差和期望不再是相等的，而是多了一个可变的参数 <span class="math notranslate nohighlight">\(\alpha\)</span>
，通过 <span class="math notranslate nohighlight">\(\alpha\)</span> 可以调整方差和期望的关系，
进而能适应各种方差的计数数据，
负二项式分布可以更好地拟合过度分散的数据。</p>
<section id="id2">
<h2><span class="section-number">18.1. </span>负二项式分布<a class="headerlink" href="#id2" title="永久链接至标题"></a></h2>
<p>回顾指数族的各种分布，可以发现很多分布都和伯努利分布有关，二项式分布描述的是 <span class="math notranslate nohighlight">\(n\)</span> 次伯努利实验成功次数的概率分布，
而泊松分布又是二项式分布的极限形式，描述的是单位时间窗口内事件发生次数的概率分布。
指数分布又可以从泊松分布推导而来，描述的是下一次事件发生需要等待的时间。
指数分布的更一般化就得到了 <code class="docutils literal notranslate"><span class="pre">Gamma</span></code> 分布。
本章讨论的负二项式分布，从名字就可以看出一定是和二项式分布有关。
事实上，二项式分布、几何分布、负二项分布都是伯努利实验的扩展。
二项式分布描述的是n次实验中成功的次数；
几何分布描述的是第一次成功之前失败的次数；
负二项分布描述的是第r次成功之前失败的次数。
二项式分布、泊松分布、几何分布、负二项式分布都是建立在伯努利试验过程的基础上，
几何分布是负二项式分布的一个特例。</p>
<p>负二项式分布可以有多种定义(理解)方式，
有两种可以看做是二项式分布变种，另一种是可以看做是泊松-伽马混合模型。
关于负二项分布的”负”有多种解释，
最直观的一种就是，二项式分布描述的”成功”的次数，而负二项分布描述的是”失败”的次数，
因此是”负”。</p>
<section id="id3">
<h3><span class="section-number">18.1.1. </span>从二项式分布推导<a class="headerlink" href="#id3" title="永久链接至标题"></a></h3>
<p>二项式分布表示的时进行 <span class="math notranslate nohighlight">\(n\)</span> 次伯努利实验 <strong>成功的次数</strong> 的概率分布，其概率分布函数为</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-010">
<span class="eqno">(18.1.1)<a class="headerlink" href="#equation-eq-nb-010" title="公式的永久链接"></a></span>\[f(y;n,\pi) =\binom{n}{y} \pi^y(1-\pi)^{n-y}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\pi\)</span> 是单次伯努利实验成功的概率，
<span class="math notranslate nohighlight">\(1-\pi\)</span> 是伯努利实验失败的概率。符号 <span class="math notranslate nohighlight">\(\binom{n}{y}\)</span> 是组合数 <span class="math notranslate nohighlight">\(C_{n}^y\)</span> ，
表示 <span class="math notranslate nohighlight">\(n\)</span> 次实验中有任意 <span class="math notranslate nohighlight">\(y\)</span> 次成功的全部组合数。
二项式分布的期望和方差分别是
<span class="math notranslate nohighlight">\(\mathbb{E}[Y]=n\pi\)</span> 和 <span class="math notranslate nohighlight">\(V(Y) = n \pi(1-\pi)\)</span> 。
负二项式分布可以看做是二项式分布的变种，
并且有两种定义方式，事实上这两种定义方式是等价的。</p>
<p>首先回顾一些组合数计算的转换公式，其一有，</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-011">
<span class="eqno">(18.1.2)<a class="headerlink" href="#equation-eq-nb-011" title="公式的永久链接"></a></span>\[C_{a+b}^a=C_{a+b}^b\]</div>
<p>其二，组合数的计算可以转换成多个 <code class="docutils literal notranslate"><span class="pre">Gamma</span></code> 函数的计算。
<code class="docutils literal notranslate"><span class="pre">Gamma</span></code> 函数是阶乘在实数域的扩展，<span class="math notranslate nohighlight">\(\Gamma(n+1)=n!\)</span>,
因此有</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-013">
<span class="eqno">(18.1.3)<a class="headerlink" href="#equation-eq-nb-013" title="公式的永久链接"></a></span>\[C_n^k = \binom{n}{k} = \frac{n!}{k!(n-k)!}
= \frac{\Gamma(n+1)  }{\Gamma(k+1)\Gamma(n-k+1)}\]</div>
<p><strong>第一种定义方式</strong></p>
<p>随机变量 <span class="math notranslate nohighlight">\(Y\)</span> 表示，伯努利实验中要得到成功 <span class="math notranslate nohighlight">\(r\)</span> 次的结果，需要进行的实验总次数，
<span class="math notranslate nohighlight">\(r\)</span> 必须是一个正整数。注意，一共进行了 <span class="math notranslate nohighlight">\(y\)</span> 次实验，最后一次实验一定是成功的，并且是第 <span class="math notranslate nohighlight">\(r\)</span> 次成功。
因此只需要在前面 <span class="math notranslate nohighlight">\(y-1\)</span> 次实验中任意成功 <span class="math notranslate nohighlight">\(r-1\)</span> 次即可，这符合二项式分布的定义，
根据二项式分布的概率分布函数 <a class="reference internal" href="#equation-eq-nb-010">公式(18.1.1)</a> 可以得到 <span class="math notranslate nohighlight">\(y-1\)</span> 次实验中成功 <span class="math notranslate nohighlight">\(r-1\)</span> 的概率为
<span class="math notranslate nohighlight">\(Bin(y-1,r-1)\)</span> ，第 <span class="math notranslate nohighlight">\(y\)</span> 次是成功的，其概率是 <span class="math notranslate nohighlight">\(\pi\)</span>
，因此实验总次数的变量 <span class="math notranslate nohighlight">\(Y\)</span> 的概率分布函数为</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-014">
<span class="eqno">(18.1.4)<a class="headerlink" href="#equation-eq-nb-014" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}f(y;r,\pi) &amp; = \underbrace{Bin(y-1,r-1)}_{\text{前(y-1)次}} \times
\underbrace{\pi}_{\text{第y次}}\\&amp;= \binom{y-1}{r-1} \pi^{r-1}(1-\pi)^{y-r} \pi\\&amp;= \binom{y-1}{r-1} \pi^{r}(1-\pi)^{y-r}\\&amp;= \frac{\Gamma(y)}{\Gamma(r)\Gamma(y-r-1)  } \pi^{r}(1-\pi)^{y-r}\end{aligned}\end{align} \]</div>
<p><strong>第二种定义方式</strong></p>
<p>变量 <span class="math notranslate nohighlight">\(Y\)</span> 表示事件第 <span class="math notranslate nohighlight">\(r\)</span> 次成功前失败的次数。
注意是一共成功了 <span class="math notranslate nohighlight">\(r\)</span> 次，在这之前失败了 <span class="math notranslate nohighlight">\(y\)</span> 次，实验总次数是 <span class="math notranslate nohighlight">\(y+r\)</span> 。
由于第 <span class="math notranslate nohighlight">\(y+r\)</span> 次一定是成功的，故只要在前面的 <span class="math notranslate nohighlight">\(y+r-1\)</span> 次中找出成功的 <span class="math notranslate nohighlight">\(r-1\)</span>
次的组合次数即可，这符合二项式分布 <span class="math notranslate nohighlight">\(Bin(y+r-1,r-1)\)</span> ，
最终变量 <span class="math notranslate nohighlight">\(Y\)</span> 的概率分布为</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-015">
<span class="eqno">(18.1.5)<a class="headerlink" href="#equation-eq-nb-015" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}f(y;r,\pi) &amp;= \underbrace{ Bin(y+r-1,r-1) }_{\text{前(y+r-1)次}} \times
\underbrace{\pi}_{\text{第(y+r)次}}\\&amp;=\binom{y+r-1}{r-1} \pi^{r-1} (1-\pi)^{y} \pi\\&amp;=\binom{y+r-1}{r-1} \pi^{r} (1-\pi)^{y}\\&amp;=\binom{y+r-1}{y} \pi^{r} (1-\pi)^{y}\\&amp;= \frac{\Gamma(y+r)  }{\Gamma(y+1)\Gamma(r)}  \pi^{r}(1-\pi)^{y}\end{aligned}\end{align} \]</div>
<p>无论哪种方式，<span class="math notranslate nohighlight">\(r\)</span> 的含义都是一样的，
<a class="reference internal" href="#equation-eq-nb-015">公式(18.1.5)</a> 是 <a class="reference internal" href="#equation-eq-nb-014">公式(18.1.4)</a> 的平移，相当于把 <span class="math notranslate nohighlight">\(y\)</span>
平移到 <span class="math notranslate nohighlight">\(y+r\)</span> ，二者的概率分布曲线是完全一致的，
只是对变量 <span class="math notranslate nohighlight">\(Y\)</span> 的定义有些差异，但这不影响使用，
二者可以看做是等价的。</p>
</section>
<section id="id4">
<h3><span class="section-number">18.1.2. </span>泊松-伽马混合分布<a class="headerlink" href="#id4" title="永久链接至标题"></a></h3>
<p>假设变量 <span class="math notranslate nohighlight">\(Y\)</span> 是泊松变量，其概率质量函数为</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-020">
<span class="eqno">(18.1.6)<a class="headerlink" href="#equation-eq-nb-020" title="公式的永久链接"></a></span>\[P(Y) = \frac{\lambda^y e^{-\lambda}} {y!}\]</div>
<p>其中唯一的参数 <span class="math notranslate nohighlight">\(\lambda\)</span> 是泊松分布的期望参数，
在本书之前的所有内容中，都是假设概率分布的参数是数值参数，不是随机量。
现在我们假设泊松分布的期望参数 <span class="math notranslate nohighlight">\(\lambda\)</span> 也是一个随机量，
并且它的概率分布是 <code class="docutils literal notranslate"><span class="pre">Gamma</span></code> 分布，我们采用 <code class="docutils literal notranslate"><span class="pre">Gamma</span></code> 分布 <a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#equation-eq-gamma-012">公式(16.2.11)</a>
的参数化方法，两个参数分别是形状(shape)参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 和尺度(scale)参数 <span class="math notranslate nohighlight">\(\beta\)</span> 。</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-021">
<span class="eqno">(18.1.7)<a class="headerlink" href="#equation-eq-nb-021" title="公式的永久链接"></a></span>\[f(\lambda;\alpha,\beta) =
\frac{  \beta^{\alpha} }{ \Gamma(\alpha)} \lambda^{\alpha-1} e^{-\beta \lambda  }
\quad (\lambda,\alpha,\beta &gt; 0)\]</div>
<p>此时响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 和参数变量 <span class="math notranslate nohighlight">\(\lambda\)</span> 的联合概率分布为
<span class="math notranslate nohighlight">\(p(Y,\lambda)=p(\lambda) p(Y|\lambda)\)</span> ，
需要通过边缘化(积分消掉参数变量)的方法得到边缘概率 <span class="math notranslate nohighlight">\(p(Y)\)</span> 。</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-022">
<span class="eqno">(18.1.8)<a class="headerlink" href="#equation-eq-nb-022" title="公式的永久链接"></a></span>\[P(Y) = \int_0^{\infty} P(\lambda) P(Y|\lambda) d \lambda\]</div>
<p>把 <a class="reference internal" href="#equation-eq-nb-020">公式(18.1.6)</a> 和 <a class="reference internal" href="#equation-eq-nb-021">公式(18.1.7)</a> 代入到  <a class="reference internal" href="#equation-eq-nb-022">公式(18.1.8)</a>
，并计算积分得到变量 <span class="math notranslate nohighlight">\(Y\)</span> 边缘概率分布函数。</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-023">
<span class="eqno">(18.1.9)<a class="headerlink" href="#equation-eq-nb-023" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}f(y) &amp;=  \int_0^{\infty}
\frac{ \beta^{\alpha} \lambda^{\alpha-1} e^{-\beta \lambda  }   }{ \Gamma(\alpha)}
\frac{\lambda^y e^{-\lambda}} {y!} d \lambda\\&amp;= \int_0^{\infty} \frac{ \beta^{\alpha} }{ \Gamma(\alpha) y!}
  \lambda^{\alpha-1} e^{- \beta \lambda } \lambda^y e^{-\lambda}  d \lambda\\&amp;= \int_0^{\infty} \frac{ \beta^{\alpha} }{ \Gamma(\alpha) y!}
  \lambda^{\alpha+y-1} e^{- (\beta+1) \lambda }  d \lambda\\&amp;=  \frac{ \beta^{\alpha} }{ \Gamma(\alpha) y!} \int_0^{\infty}
  \lambda^{\alpha+y-1} e^{- (\beta+1) \lambda }  d \lambda\\&amp;=  \frac{ \beta^{\alpha} }{ \Gamma(\alpha) y!}
    \int_0^{\infty}
    \frac{ \Gamma(\alpha+y)}{ (\beta+1)^{\alpha+y} }
    \frac{  (\beta+1)^{\alpha+y} }{ \Gamma(\alpha+y)}
    \lambda^{\alpha+y-1} e^{- (\beta+1) \lambda }  d \lambda\\&amp;=  \frac{ \beta^{\alpha} }{ \Gamma(\alpha) y!}
    \frac{ \Gamma(\alpha+y)}{ (\beta+1)^{\alpha+y} }
    \underbrace{\int_0^{\infty}
    \underbrace{ \frac{  (\beta+1)^{\alpha+y} }{ \Gamma(\alpha+y)}
    \lambda^{\alpha+y-1} e^{- (\beta+1) \lambda } }_{ Gamma(\alpha+y,\beta+1)  }  d \lambda }_{\text{积分为1}}\\&amp;=  \frac{ \beta^{\alpha} }{ \Gamma(\alpha) y!}
    \frac{ \Gamma(\alpha+y)}{ (\beta+1)^{\alpha+y} }\\&amp;= \frac{\Gamma(y+\alpha)  }{\Gamma(y+1) \Gamma(\alpha) }
    \frac{\beta^{\alpha}}{(\beta+1)^{\alpha} (\beta+1)^{y} }\\&amp;= \frac{\Gamma(y+\alpha)  }{\Gamma(y+1) \Gamma(\alpha) }
    \left ( \frac{\beta}{\beta+1} \right )^{\alpha}
    \left ( \frac{1}{\beta+1} \right )^{y}\end{aligned}\end{align} \]</div>
<p>现在重新参数化 <a class="reference internal" href="#equation-eq-nb-023">公式(18.1.9)</a> ，令 <span class="math notranslate nohighlight">\(r=\alpha,\pi=\beta/(\beta+1)\)</span>
，则公式 <a class="reference internal" href="#equation-eq-nb-023">公式(18.1.9)</a> 可以转化成</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-024">
<span class="eqno">(18.1.10)<a class="headerlink" href="#equation-eq-nb-024" title="公式的永久链接"></a></span>\[f(y;r,\pi) =\frac{\Gamma(y+r)  }{\Gamma(y+1) \Gamma(r) }
\pi^r (1-\pi)^y\]</div>
<p>这和 <a class="reference internal" href="#equation-eq-nb-015">公式(18.1.5)</a> 完全一样的，可见泊松-伽马混合模型本质上就是负二项式分布。</p>
</section>
<section id="alpha">
<h3><span class="section-number">18.1.3. </span>辅助参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的影响<a class="headerlink" href="#alpha" title="永久链接至标题"></a></h3>
<p>负二项式分布有两个参数，一个是期望参数 <span class="math notranslate nohighlight">\(\mu\)</span> ，
一个是辅助参数 <span class="math notranslate nohighlight">\(\alpha\)</span> ，
根据前面的推导过程可知辅助参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 一定是大于0的，
首先给 <span class="math notranslate nohighlight">\(\alpha\)</span> 赋值一个接近 <span class="math notranslate nohighlight">\(0\)</span> 的值，
观察下当 <span class="math notranslate nohighlight">\(\alpha \approx 0\)</span> 时负二项式分布的特点。
<a class="reference internal" href="#fg-nb-alpha-0-001"><span class="std std-numref">图 18.1.1</span></a> 是 <span class="math notranslate nohighlight">\(\alpha=0.001\)</span> 时
负二项式分布概率质量函数的曲线图。</p>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>注意，负二项式分布是离散变量的的分布，离散分布的概率分布函数称为概率质量函数，
概率质量函数应该是离散的点图，为了方便观测概率的变化规律，
我们把点图用线连接起来，观察曲线的变化。</p>
</div>
<figure class="align-center" id="id13">
<span id="fg-nb-alpha-0-001"></span><a class="reference internal image-reference" href="../../../_images/负二项式分布_alpha_0.001.jpg"><img alt="../../../_images/负二项式分布_alpha_0.001.jpg" src="../../../_images/负二项式分布_alpha_0.001.jpg" style="width: 448.0px; height: 336.0px;" /></a>
<figcaption>
<p><span class="caption-number">图 18.1.1 </span><span class="caption-text">当 <span class="math notranslate nohighlight">\(\alpha=0.001\)</span> 时，不同 <span class="math notranslate nohighlight">\(\mu\)</span> 值下负二项式分布的概率质量函数</span><a class="headerlink" href="#id13" title="永久链接至图片"></a></p>
</figcaption>
</figure>
<p>对比下 <a class="reference internal" href="#fg-nb-alpha-0-001"><span class="std std-numref">图 18.1.1</span></a> 和泊松分布的概率质量函数的分布图
(<a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#fg-poisson-002"><span class="std std-numref">图 14.1.1</span></a>)，可以发现二者基本是一致的。
因此负二项式分布的辅助参数 <span class="math notranslate nohighlight">\(\alpha=0\)</span> 时，就等价于泊松分布，
<strong>泊松分布可以看做是负二项式分布的一个特例</strong> 。</p>
<figure class="align-center" id="id14">
<span id="fg-nb-alpha-0-33"></span><a class="reference internal image-reference" href="../../../_images/负二项式分布_alpha_0.33.jpg"><img alt="../../../_images/负二项式分布_alpha_0.33.jpg" src="../../../_images/负二项式分布_alpha_0.33.jpg" style="width: 448.0px; height: 336.0px;" /></a>
<figcaption>
<p><span class="caption-number">图 18.1.2 </span><span class="caption-text">当 <span class="math notranslate nohighlight">\(\alpha=0.33\)</span> 时，不同 <span class="math notranslate nohighlight">\(\mu\)</span> 值下负二项式分布的概率质量函数。
相比于 <span class="math notranslate nohighlight">\(\alpha=0.001\)</span> 时，曲线凸起的部分向左移动了。</span><a class="headerlink" href="#id14" title="永久链接至图片"></a></p>
</figcaption>
</figure>
<p>现在我们逐渐增大 <span class="math notranslate nohighlight">\(\alpha\)</span> 的值，
<a class="reference internal" href="#fg-nb-alpha-0-33"><span class="std std-numref">图 18.1.2</span></a> 是 <span class="math notranslate nohighlight">\(\alpha=0.33\)</span> 的分布图，
可以看出曲线上凸起的部分向左移动了一些。
我们继续增大 <span class="math notranslate nohighlight">\(\alpha\)</span> 的值，
如 <a class="reference internal" href="#fg-nb-alpha-0-67"><span class="std std-numref">图 18.1.3</span></a> ，
把 <span class="math notranslate nohighlight">\(\alpha\)</span> 设置为 <span class="math notranslate nohighlight">\(0.67\)</span> ，
可以发现原来凸起的部分逐渐消失。</p>
<figure class="align-center" id="id15">
<span id="fg-nb-alpha-0-67"></span><a class="reference internal image-reference" href="../../../_images/负二项式分布_alpha_0.67.jpg"><img alt="../../../_images/负二项式分布_alpha_0.67.jpg" src="../../../_images/负二项式分布_alpha_0.67.jpg" style="width: 448.0px; height: 336.0px;" /></a>
<figcaption>
<p><span class="caption-number">图 18.1.3 </span><span class="caption-text">当 <span class="math notranslate nohighlight">\(\alpha=0.67\)</span> 时，图形左侧凸起逐渐消失了。</span><a class="headerlink" href="#id15" title="永久链接至图片"></a></p>
</figcaption>
</figure>
<p>把 <span class="math notranslate nohighlight">\(\alpha\)</span> 的值进一步增大到 <span class="math notranslate nohighlight">\(1.0\)</span> ，
变成了 <a class="reference internal" href="#fg-nb-alpha-0-67"><span class="std std-numref">图 18.1.3</span></a> 所示的图形，
图形基本都变成了下凹的形状。
<span class="math notranslate nohighlight">\(\alpha=1.0\)</span> 的负二项式分布又叫做几何(geometric)分布，
<strong>几何分布是负二项式分布的一个特例</strong>。
对比下 <a class="reference internal" href="#fg-nb-alpha-1-0"><span class="std std-numref">图 18.1.4</span></a> 和指数分布的图形( <a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#exponential-distribution-pdf"><span class="std std-numref">图 15.1.1</span></a> )
，可以发现二者的图形几乎是一致的。
<strong>事实上几何分布是指数分布的离散版本，指数分布是一个连续值概率分布，而几何分布与指数分布是离散相关的</strong>。</p>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>指数分布是连续值概率分布，连续值随机变量的概率分布函数叫做概率密度函数(probability density function,pdf)；
离散随机变量的概率分布函数叫做概率质量函数(probability mass function,pmf)。
概率密度函数的曲线图纵坐标不是概率值，需要积分才能得到概率值；
而概率质量函数的曲线图纵坐标直接就是对应的概率值。</p>
</div>
<figure class="align-center" id="id16">
<span id="fg-nb-alpha-1-0"></span><a class="reference internal image-reference" href="../../../_images/负二项式分布_alpha_1.0.jpg"><img alt="../../../_images/负二项式分布_alpha_1.0.jpg" src="../../../_images/负二项式分布_alpha_1.0.jpg" style="width: 448.0px; height: 336.0px;" /></a>
<figcaption>
<p><span class="caption-number">图 18.1.4 </span><span class="caption-text">当 <span class="math notranslate nohighlight">\(\alpha=1.0\)</span> 时，负二项式分布又称为几何分布，并且和指数分布是离散相关的。</span><a class="headerlink" href="#id16" title="永久链接至图片"></a></p>
</figcaption>
</figure>
<p>继续增大 <span class="math notranslate nohighlight">\(\alpha\)</span> 的值，如 <a class="reference internal" href="#fg-nb-alpha-1-5"><span class="std std-numref">图 18.1.5</span></a> 和
<a class="reference internal" href="#fg-nb-alpha-3-0"><span class="std std-numref">图 18.1.6</span></a> 所示，图形的左下角会越来越凹陷，
并且随着 <span class="math notranslate nohighlight">\(\alpha\)</span> 的增加，各个不同的期望 <span class="math notranslate nohighlight">\(\mu\)</span> 值的曲线会逐渐重合在一起，
这意味着当 <span class="math notranslate nohighlight">\(\alpha\)</span> 足够大时，期望参数 <span class="math notranslate nohighlight">\(\mu\)</span> 的影响力逐渐变小。</p>
<figure class="align-center" id="id17">
<span id="fg-nb-alpha-1-5"></span><a class="reference internal image-reference" href="../../../_images/负二项式分布_alpha_1.5.jpg"><img alt="../../../_images/负二项式分布_alpha_1.5.jpg" src="../../../_images/负二项式分布_alpha_1.5.jpg" style="width: 448.0px; height: 336.0px;" /></a>
<figcaption>
<p><span class="caption-number">图 18.1.5 </span><span class="caption-text">当 <span class="math notranslate nohighlight">\(\alpha=1.0\)</span> 时，不同 <span class="math notranslate nohighlight">\(\mu\)</span> 值下负二项式分布的概率质量函数</span><a class="headerlink" href="#id17" title="永久链接至图片"></a></p>
</figcaption>
</figure>
<figure class="align-center" id="id18">
<span id="fg-nb-alpha-3-0"></span><a class="reference internal image-reference" href="../../../_images/负二项式分布_alpha_3.0.jpg"><img alt="../../../_images/负二项式分布_alpha_3.0.jpg" src="../../../_images/负二项式分布_alpha_3.0.jpg" style="width: 448.0px; height: 336.0px;" /></a>
<figcaption>
<p><span class="caption-number">图 18.1.6 </span><span class="caption-text">当 <span class="math notranslate nohighlight">\(\alpha=1.0\)</span> 时，不同 <span class="math notranslate nohighlight">\(\mu\)</span> 值下负二项式分布的概率质量函数</span><a class="headerlink" href="#id18" title="永久链接至图片"></a></p>
</figcaption>
</figure>
<p>最后我们固定 <span class="math notranslate nohighlight">\(\mu\)</span> 的值，直接对比不同的 <span class="math notranslate nohighlight">\(\alpha\)</span> 下图形的差异。
<a class="reference internal" href="#fg-nb-mu-4-0"><span class="std std-numref">图 18.1.7</span></a> 是 <span class="math notranslate nohighlight">\(\mu\)</span> 固定为 <span class="math notranslate nohighlight">\(4.0\)</span>
，<span class="math notranslate nohighlight">\(\alpha\)</span> 取不同值时负二项式分布的图形。
可以看出，<span class="math notranslate nohighlight">\(\alpha\)</span> 等于 <span class="math notranslate nohighlight">\(0\)</span> 时，
负二项式分布在期望值附近的概率时最大的，
而随着 <span class="math notranslate nohighlight">\(\alpha\)</span> 增大，负二项式分布中 <span class="math notranslate nohighlight">\(0\)</span> 的概率逐步增大。</p>
<figure class="align-center" id="id19">
<span id="fg-nb-mu-4-0"></span><a class="reference internal image-reference" href="../../../_images/负二项式分布_mu_4.0.jpg"><img alt="../../../_images/负二项式分布_mu_4.0.jpg" src="../../../_images/负二项式分布_mu_4.0.jpg" style="width: 448.0px; height: 336.0px;" /></a>
<figcaption>
<p><span class="caption-number">图 18.1.7 </span><span class="caption-text">固定 <span class="math notranslate nohighlight">\(\mu=4.0\)</span> ，不同 <span class="math notranslate nohighlight">\(\alpha\)</span> 的值对图形的影响。</span><a class="headerlink" href="#id19" title="永久链接至图片"></a></p>
</figcaption>
</figure>
<p>反过来，
固定 <span class="math notranslate nohighlight">\(\alpha\)</span> 的值，<span class="math notranslate nohighlight">\(\mu\)</span> 越大，<span class="math notranslate nohighlight">\(0\)</span> 的概率就越小，图形就越接近高斯分布。
最后我们总结下负二项式分布中 <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\alpha\)</span> 的关系。</p>
<ul class="simple">
<li><p>固定 <span class="math notranslate nohighlight">\(\mu\)</span> ，<span class="math notranslate nohighlight">\(\alpha\)</span> 越大，<span class="math notranslate nohighlight">\(0\)</span> 的概率越大。</p></li>
<li><p>固定 <span class="math notranslate nohighlight">\(\alpha\)</span> ，<span class="math notranslate nohighlight">\(\mu\)</span> 越大，<span class="math notranslate nohighlight">\(0\)</span> 的概率越小。</p></li>
</ul>
</section>
</section>
<section id="id5">
<h2><span class="section-number">18.2. </span>负二项回归模型<a class="headerlink" href="#id5" title="永久链接至标题"></a></h2>
<p>负二项式分布同样属于指数族分布，因此负二项式回归模型可以纳入到GLM框架中，
作为GLM的一员。
先把 <a class="reference internal" href="#equation-eq-nb-024">公式(18.1.10)</a> 作为负二项式分布的概率分布函数，并把它转化成指数族的形式。</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-031">
<span class="eqno">(18.2.1)<a class="headerlink" href="#equation-eq-nb-031" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}f(y;r,\pi) &amp;= \exp \left \{ \ln \left [ \frac{\Gamma(y+r)  }{\Gamma(y+1) \Gamma(r) }
\pi^r (1-\pi)^y \right ] \right \}\\&amp;= \exp \left \{
y \ln (1-\pi) + r\ln \pi + \ln \frac{\Gamma(y+r)  }{\Gamma(y+1) \Gamma(r) }
\right \}\end{aligned}\end{align} \]</div>
<p>因此，有</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-0">
<span class="eqno">(18.2.2)<a class="headerlink" href="#equation-glm-source-content-0" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\text{自然参数} &amp; \quad \theta = \ln (1-\pi)\\&amp; \quad \pi = 1- e^\theta\\\text{累积分布函数} &amp; \quad b(\theta) = - r\ln \pi = -r \ln (1-e^\theta)\\\text{分散函数} &amp; \quad a(\phi) = 1\end{aligned}\end{align} \]</div>
<p>现在来看下负二项式分布的期望与方差，指数族分布的期望与方差函数可以分别由
累积分布函数 <span class="math notranslate nohighlight">\(b(\theta)\)</span> 的一阶导和二阶导得到。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-1">
<span class="eqno">(18.2.3)<a class="headerlink" href="#equation-glm-source-content-1" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}b'(\theta) &amp;= \frac{\partial b}{ \partial \pi} \frac{\partial \pi}{ \partial \theta}\\&amp;= \left (- \frac{r}{\pi} \right ) \{  -(1-\pi) \}\\&amp;= \frac{r(1-\pi)}{\pi}\\&amp;= \mu\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight" id="equation-glm-source-content-2">
<span class="eqno">(18.2.4)<a class="headerlink" href="#equation-glm-source-content-2" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}b''(\theta) &amp;= \frac{\partial^2 b}{ \partial \pi^2} \left (\frac{\partial \pi}{ \partial \theta} \right )^2
+  \frac{\partial b}{ \partial \pi} \frac{\partial^2 \pi}{ \partial \theta^2}\\&amp;= \left ( \frac{r}{\pi^2}  \right )(1-\pi)^2 + \frac{r}{\pi}(1-\pi)\\&amp;=\frac{r(1-\pi)^2  +r\pi(1-\pi)  }{\pi^2}\\&amp;= \frac{r(1-\pi)}{\pi^2}\\&amp;= \mu + \frac{\mu^2}{r}\\&amp;= \nu(\mu)\end{aligned}\end{align} \]</div>
<p>有了方差函数后，可得到方差为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-3">
<span class="eqno">(18.2.5)<a class="headerlink" href="#equation-glm-source-content-3" title="公式的永久链接"></a></span>\[V(Y) = a(\phi)\nu(\mu) = \mu + \frac{\mu^2}{r}\]</div>
<p>这个形式下的方差函数，参数 <span class="math notranslate nohighlight">\(r\)</span> 在分母的位置，不是很”美观”，
通常情况下会重新参数化一下，令 <span class="math notranslate nohighlight">\(\alpha=1/r\)</span>
，使用参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 重新参数化负二项式模型后，负二项式分布的期望和方差分别为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-4">
<span class="eqno">(18.2.6)<a class="headerlink" href="#equation-glm-source-content-4" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\text{期望} &amp; \quad \mu = \frac{1-\pi}{\alpha \pi}\\  &amp; \quad \pi = \frac{1}{1+\alpha \mu}\\\text{方差} &amp; \quad V(Y) = \mu + \alpha \mu^2\end{aligned}\end{align} \]</div>
<p>负二项式分布的概率分布函数 <a class="reference internal" href="#equation-eq-nb-031">公式(18.2.1)</a> 用期望参数 <span class="math notranslate nohighlight">\(\mu\)</span> 和 参数 <span class="math notranslate nohighlight">\(\alpha\)</span>
重新参数化后为</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-035">
<span class="eqno">(18.2.7)<a class="headerlink" href="#equation-eq-nb-035" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}f(y;\alpha,\mu)  &amp;= \exp \left \{
y \ln (1-\pi) + r\ln \pi + \ln \frac{\Gamma(y+r)  }{\Gamma(y+1) \Gamma(r) }
\right \}\\&amp;= \exp \left \{
y \ln \left (\frac{\alpha \mu}{1+\alpha \mu} \right )- \frac{1}{\alpha} \ln (1+\alpha \mu) + \ln \frac{\Gamma(y+1/\alpha)  }{\Gamma(y+1) \Gamma(1/\alpha) }
\right \}\end{aligned}\end{align} \]</div>
<p><a class="reference internal" href="#equation-eq-nb-035">公式(18.2.7)</a> 是负二项式模型的标准指数族形式，其标准连接函数为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-5">
<span class="eqno">(18.2.8)<a class="headerlink" href="#equation-glm-source-content-5" title="公式的永久链接"></a></span>\[\eta = \theta = \ln \left (\frac{\alpha \mu}{1+\alpha \mu} \right )\]</div>
<p>标准连接函数的响应函数为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-6">
<span class="eqno">(18.2.9)<a class="headerlink" href="#equation-glm-source-content-6" title="公式的永久链接"></a></span>\[\mu = \frac{\exp(\eta)}{\alpha[1-\exp(\eta)] }\]</div>
<p>采用标准连接函数的负二项式模型通常简称为 <code class="docutils literal notranslate"><span class="pre">NB-C</span></code> 模型，</p>
<p>因此有</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-7">
<span class="eqno">(18.2.10)<a class="headerlink" href="#equation-glm-source-content-7" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\text{自然参数} &amp; \quad \theta = \ln \left (\frac{\alpha \mu}{1+\alpha \mu} \right )\\
\text{累积分布函数} &amp; \quad b(\theta) =  \frac{1}{\alpha} \ln (1+\alpha \mu)\\\text{期望} &amp; \quad b'(\theta) =  \mu\\\text{方差函数} &amp; \quad \nu(\mu) = b''(\theta) =  \mu + \alpha \mu^2\\\text{分散函数} &amp; \quad a(\phi) = 1\\\text{方差} &amp; \quad V(Y) =  a(\phi)\nu(\mu) = \mu + \alpha \mu^2\\\text{标准连接函数} &amp; \quad g(\mu) = \ln \left (\frac{\alpha \mu}{1+\alpha \mu} \right )\\\text{标准连接函数一阶导}  &amp; \quad g'(\mu) = \frac{1}{\mu+\alpha \mu^2}\\\text{响应函数}  &amp; \quad \mu = \frac{\exp(\eta)}{\alpha[1-\exp(\eta)] }\end{aligned}\end{align} \]</div>
</section>
<section id="id6">
<h2><span class="section-number">18.3. </span>参数估计<a class="headerlink" href="#id6" title="永久链接至标题"></a></h2>
<p>参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 通常被称为辅助(ancillary)参数或者尺度(scale)参数
，
只有 <span class="math notranslate nohighlight">\(\alpha\)</span> 是一个常数的时，负二项式回归模型才能纳入到 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 的框架下，
这是因为 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 框架的 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 算法只能估计协变量参数 <span class="math notranslate nohighlight">\(\beta\)</span> ，
无法同时估计出额外的参数，需要在应用 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 算法前通过其它的方法确定
<span class="math notranslate nohighlight">\(\alpha\)</span> 的值，然后把 <span class="math notranslate nohighlight">\(\alpha\)</span> 的值代入到GLM中，当做一个常量值。
我们先给出 <code class="docutils literal notranslate"><span class="pre">NB-C</span></code> 模型的 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 算法过程，
然后再讨论如何用最大似然估计同时估计参数 <span class="math notranslate nohighlight">\(\alpha\)</span>
和协变量参数 <span class="math notranslate nohighlight">\(\beta\)</span>
。</p>
<section id="irls">
<h3><span class="section-number">18.3.1. </span>IRLS<a class="headerlink" href="#irls" title="永久链接至标题"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">NB-C</span></code> 模型的概率质量函数为 <a class="reference internal" href="#equation-eq-nb-035">公式(18.2.7)</a>
，其对数似然函数为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-8">
<span class="eqno">(18.3.1)<a class="headerlink" href="#equation-glm-source-content-8" title="公式的永久链接"></a></span>\[\ell(\mu;y,\alpha) = \sum_{i=1}^N  \left \{
y_i \ln \left (\frac{\alpha \mu_i}{1+\alpha \mu_i} \right )
- \frac{1}{\alpha} \ln (1+\alpha \mu_i)
+ \ln \Gamma(y_i+1/\alpha)
- \ln \Gamma(y_i+1) - \ln \Gamma(1/\alpha)
\right \}\]</div>
<p><code class="docutils literal notranslate"><span class="pre">NB-C</span></code> 模型采用的标准连接函数，标准连接函数为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-9">
<span class="eqno">(18.3.2)<a class="headerlink" href="#equation-glm-source-content-9" title="公式的永久链接"></a></span>\[g(\mu) = \ln \left (\frac{\alpha \mu}{1+\alpha \mu} \right )
= - \ln [ 1+ 1/ (\alpha \mu ) ]\]</div>
<p>标准连接函数的导数为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-10">
<span class="eqno">(18.3.3)<a class="headerlink" href="#equation-glm-source-content-10" title="公式的永久链接"></a></span>\[g'(\mu) = \frac{1}{\mu+\alpha \mu^2}\]</div>
<p>依此可以给出 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 算法过程中的权重矩阵 <span class="math notranslate nohighlight">\(W\)</span> 和工作响应矩阵 <span class="math notranslate nohighlight">\(Z\)</span>
，分别为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-11">
<span class="eqno">(18.3.4)<a class="headerlink" href="#equation-glm-source-content-11" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}W_{ii} &amp;=  \frac{ 1}{ a(\phi) \nu(\hat{\mu}_i) ( g' )^2}\\&amp;=
\hat{\mu}_i + \alpha \hat{\mu}_i^2\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight" id="equation-glm-source-content-12">
<span class="eqno">(18.3.5)<a class="headerlink" href="#equation-glm-source-content-12" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}Z_i &amp;=  (y_i- \hat{\mu}_i) g'  + \eta_i\\ &amp;=   \frac{(y_i- \hat{\mu}_i)}{\hat{\mu}_i + \alpha \hat{\mu}_i^2}  + \eta_i\end{aligned}\end{align} \]</div>
<p>偏差统计量为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-13">
<span class="eqno">(18.3.6)<a class="headerlink" href="#equation-glm-source-content-13" title="公式的永久链接"></a></span>\[D = 2\sum_{i=1}^N \left \{
    y_i \ln \left ( \frac{y_i}{ \hat{\mu}_i} \right )
- \left ( y_i + \frac{1}{\alpha} \right ) \ln \left (  \frac{1+\alpha y_i}{1+\alpha \hat{\mu}_i} \right )
\right \}\]</div>
<p><code class="docutils literal notranslate"><span class="pre">NB-C</span></code> 模型IRLS算法过程:</p>
<div class="line-block">
<div class="line"><span class="math notranslate nohighlight">\(\mu=\{y+mean(y)\}/2\)</span></div>
<div class="line"><span class="math notranslate nohighlight">\(\eta=- \ln \{ 1/(\alpha\mu) +1 \}\)</span></div>
<div class="line">WHILE ( abs( <span class="math notranslate nohighlight">\(\Delta Dev\)</span> ) &gt; tolerance) {</div>
<div class="line-block">
<div class="line"><span class="math notranslate nohighlight">\(W=\mu+\alpha \mu^2\)</span></div>
<div class="line"><span class="math notranslate nohighlight">\(Z=\{ \eta +(y-\mu)/W \}\)</span></div>
<div class="line"><span class="math notranslate nohighlight">\(\beta=(X^TWX)^{-1}X^TWZ\)</span></div>
<div class="line"><span class="math notranslate nohighlight">\(\eta = X\beta\)</span></div>
<div class="line"><span class="math notranslate nohighlight">\(\mu=1/\{ \alpha(e^{-\eta} -1 ) \}\)</span></div>
<div class="line">OldDev=Dev</div>
<div class="line">Dev = <span class="math notranslate nohighlight">\(2\sum \{ y\ln(y/\mu) -(y+1/\alpha)\ln[(1+\alpha y)/(1+\alpha \mu)] \}\)</span></div>
<div class="line"><span class="math notranslate nohighlight">\(\Delta Dev\)</span> =Dev - OldDev</div>
</div>
<div class="line">}</div>
<div class="line"><span class="math notranslate nohighlight">\(\chi^2=\sum [ (y-\mu)^2/(\mu+\alpha \mu^2)]\)</span></div>
</div>
<figure class="align-center" id="id20">
<span id="fg-nb-irls"></span><a class="reference internal image-reference" href="../../../_images/irls.png"><img alt="../../../_images/irls.png" src="../../../_images/irls.png" style="width: 772.8px; height: 459.9px;" /></a>
<figcaption>
<p><span class="caption-number">图 18.3.1 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">NB-C</span></code> 模型的 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 算法过程</span><a class="headerlink" href="#id20" title="永久链接至图片"></a></p>
</figcaption>
</figure>
</section>
<section id="id7">
<h3><span class="section-number">18.3.2. </span>参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计<a class="headerlink" href="#id7" title="永久链接至标题"></a></h3>
<div class="math notranslate nohighlight" id="equation-glm-source-content-14">
<span class="eqno">(18.3.7)<a class="headerlink" href="#equation-glm-source-content-14" title="公式的永久链接"></a></span>\[\frac{\partial \ell }{\partial \mu}
=  \sum_{i=1}^N \frac{y_i - \mu_i}{\mu_i (1+\alpha \mu_i )}\]</div>
<div class="math notranslate nohighlight" id="equation-glm-source-content-15">
<span class="eqno">(18.3.8)<a class="headerlink" href="#equation-glm-source-content-15" title="公式的永久链接"></a></span>\[\frac{\partial \ell }{\partial \beta_j}
= \sum_{i=1}^N \frac{x_{ij} (y_i - \mu_i )}{1+\alpha \mu_i }\]</div>
<div class="math notranslate nohighlight" id="equation-glm-source-content-16">
<span class="eqno">(18.3.9)<a class="headerlink" href="#equation-glm-source-content-16" title="公式的永久链接"></a></span>\[\frac{\partial \ell }{\partial \alpha} =  \sum_{i=1}^N
\left \{
\frac{1}{\alpha^2} \left [ \ln(1+\alpha \mu_i) +\frac{\alpha(y_i - \mu_i)}{1+\alpha \mu_i}  \right ]
+ \psi \left ( y_i + \frac{1}{\alpha} \right )
- \psi \left ( \frac{1}{\alpha} \right )
\right \}\]</div>
<div class="math notranslate nohighlight" id="equation-glm-source-content-17">
<span class="eqno">(18.3.10)<a class="headerlink" href="#equation-glm-source-content-17" title="公式的永久链接"></a></span>\[\frac{\partial^2 \ell}{\partial \beta_j \beta_k} = \sum_{i=1}^N
\left [
-x_{ij}x_{ik} \frac{\mu_i(1+\alpha y_i)}{(1+\alpha \mu_i)^2}
\right ]\]</div>
<div class="math notranslate nohighlight" id="equation-glm-source-content-18">
<span class="eqno">(18.3.11)<a class="headerlink" href="#equation-glm-source-content-18" title="公式的永久链接"></a></span>\[\frac{\partial^2 \ell}{\partial \beta_j \partial \alpha } = \mathbb{E} \left [
- \sum_{i=1}^N
\frac{\mu_i(y_i - \mu_i)x_{ij}}{(1+\alpha \mu_i)^2}
\right ]\]</div>
<div class="math notranslate nohighlight" id="equation-glm-source-content-19">
<span class="eqno">(18.3.12)<a class="headerlink" href="#equation-glm-source-content-19" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\frac{\partial^2 \ell}{\partial \alpha^2} = \sum_{i=1}^N
&amp; \left \{
- \frac{1}{\alpha^3} \left [
\frac{\alpha(1+2\alpha \mu)(y_i-\mu_i) - \alpha \mu_i (1+\alpha \mu_i)}{(1+\alpha \mu_i)^2}
+ 2\ln(1+\alpha \mu_i)
\right ] \right.\\&amp; \left. + \psi' \left ( y_i + \frac{1}{\alpha} \right )
- \psi' \left (  \frac{1}{\alpha} \right )
\right \}\end{aligned}\end{align} \]</div>
</section>
</section>
<section id="id8">
<h2><span class="section-number">18.4. </span>负二项式模型扩展<a class="headerlink" href="#id8" title="永久链接至标题"></a></h2>
<section id="id9">
<h3><span class="section-number">18.4.1. </span>对数连接函数<a class="headerlink" href="#id9" title="永久链接至标题"></a></h3>
<p>采用对数连接的负二项式模型简称为 <code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 模型，<span class="math notranslate nohighlight">\(\alpha=0\)</span> 的
<code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 模型就等价于泊松模型。
传统的泊松回归模型经常会面临过度分散的问题，
<code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 模型通常会看做是泊松模型的”改进版”，
是处理泊松过度分散数据最常用的方法，
而标准连接的 <code class="docutils literal notranslate"><span class="pre">NB-C</span></code> 模型很少使用。</p>
<p>把 <code class="docutils literal notranslate"><span class="pre">NB-C</span></code> 模型转换成 <code class="docutils literal notranslate"><span class="pre">NB2</span></code> 模型，只需要更换连接函数和响应函数(反连接函数)即可。</p>
<ul class="simple">
<li><p>连接函数： <span class="math notranslate nohighlight">\(\eta=\ln(\mu)\)</span></p></li>
<li><p>响应函数： <span class="math notranslate nohighlight">\(\mu=exp(\eta)\)</span></p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">NB2</span></code> 模型的概率质量函数的指数族形式为</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-51">
<span class="eqno">(18.4.1)<a class="headerlink" href="#equation-eq-nb-51" title="公式的永久链接"></a></span>\[f(y;\alpha,\mu)
= \exp \left \{
y \ln  ( \mu  )- \frac{1}{\alpha} \ln (1+\alpha \mu) + \ln \frac{\Gamma(y+1/\alpha)  }{\Gamma(y+1) \Gamma(1/\alpha) }
\right \}\]</div>
<p><code class="docutils literal notranslate"><span class="pre">NB2</span></code> 模型的偏差统计量为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-20">
<span class="eqno">(18.4.2)<a class="headerlink" href="#equation-glm-source-content-20" title="公式的永久链接"></a></span>\[D = 2\sum_{i=1}^N \left \{
    y_i \ln \left ( \frac{y_i}{ \hat{\mu}_i} \right )
- \frac{1}{\alpha}  \ln \left (  \frac{1+\alpha y_i}{1+\alpha \hat{\mu}_i} \right )
\right \}\]</div>
<p><code class="docutils literal notranslate"><span class="pre">NB2</span></code> 模型的 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 算法过程和 <code class="docutils literal notranslate"><span class="pre">NB-C</span></code> 模型几乎没有差别，
只是把对应的连接函数及其导数部分替换一下即可。
<code class="docutils literal notranslate"><span class="pre">NB2</span></code> 模型关键组件为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-21">
<span class="eqno">(18.4.3)<a class="headerlink" href="#equation-glm-source-content-21" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\text{连接函数} \quad  &amp;\eta = g(\mu) = \ln (\mu)\\\text{连接函数一阶导} \quad  &amp;g'(\mu) = 1/\mu\\\text{连接函数二阶导} \quad  &amp;g''(\mu) = -1/\mu^2\\\text{方差} \quad  &amp;V(\mu) = a(\phi)\nu(\mu) = \mu+\alpha \mu^2\\\text{方差一阶导} \quad  &amp;V'(\mu) = 1+ 2\alpha \mu\\\text{方差的平方} \quad  &amp;V^2(\mu) = ( \mu+\alpha \mu^2)^2\end{aligned}\end{align} \]</div>
<p><code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 算法过程的权重 <span class="math notranslate nohighlight">\(W\)</span> 和工作响应 <span class="math notranslate nohighlight">\(Z\)</span>
分别为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-22">
<span class="eqno">(18.4.4)<a class="headerlink" href="#equation-glm-source-content-22" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}W &amp;= \text{diag} \left \{ \frac{ 1}{ V(\hat{\mu}) ( g' )^2}
\right \}_{(N\times N)}\\&amp;= \text{diag} \left \{
\frac{\mu}{1+\alpha \mu}
\right \}_{(N\times N)}\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight" id="equation-glm-source-content-23">
<span class="eqno">(18.4.5)<a class="headerlink" href="#equation-glm-source-content-23" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}Z &amp;=   \left \{ (y- \hat{\mu}) g'  + \eta
\right \}_{(N\times 1 )}\\ &amp;=   \left \{ \frac{(y- \hat{\mu})}{\hat{\mu}}  + \eta
\right \}_{(N\times 1 )}\end{aligned}\end{align} \]</div>
<p>在传统的GLM算法中，参数估计算法IRLS使用的是期望信息矩阵 <code class="docutils literal notranslate"><span class="pre">EIM</span></code>
，对于采用标准连接函数的 <code class="docutils literal notranslate"><span class="pre">NB-C</span></code> 模型来说，期望信息矩阵 <code class="docutils literal notranslate"><span class="pre">EIM</span></code>
和观测信息矩阵 <code class="docutils literal notranslate"><span class="pre">OIM</span></code> 是等价的。
然而 <code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 模型是非标准连接函数，此时期望信息矩阵 <code class="docutils literal notranslate"><span class="pre">EIM</span></code> 和
观测信息矩阵 <code class="docutils literal notranslate"><span class="pre">OIM</span></code> 不再相等。
在 <code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 的参数估计过程中，要想利用观测信息矩阵 <code class="docutils literal notranslate"><span class="pre">OIM</span></code>
计算参数的标准误，就需要对IRLS算法做一些改动。</p>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>回顾一下，<code class="docutils literal notranslate"><span class="pre">GLM</span></code> 的参数估计算法，传统的最大似然估计是利用观测信息矩阵 <code class="docutils literal notranslate"><span class="pre">OIM</span></code> 计算参数估计量的标准误，
<code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 算法利用期望信息矩阵 <code class="docutils literal notranslate"><span class="pre">EIM</span></code> 替代了观测信息矩阵 <code class="docutils literal notranslate"><span class="pre">OIM</span></code> ，而利用 <code class="docutils literal notranslate"><span class="pre">EIM</span></code>
计算出的参数估计量标准误是有一定误差的。对于采用标准连接函数的GLM模型，<code class="docutils literal notranslate"><span class="pre">OIM</span></code> 和 <code class="docutils literal notranslate"><span class="pre">EIM</span></code>
是等价的，使用 <code class="docutils literal notranslate"><span class="pre">EIM</span></code> 也没有关系。然而非标准连接的 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 模型，<code class="docutils literal notranslate"><span class="pre">OIM</span></code> 和 <code class="docutils literal notranslate"><span class="pre">EIM</span></code> 是不一样的，
此时要想得到准确的参数估计量标准误，就需要对 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 做一些改动。</p>
</div>
<p><code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 模型和泊松模型连接函数都是对数函数，两个模型不同的是方差，
泊松模型的方差等于期望 <span class="math notranslate nohighlight">\(\mu\)</span>
，而 <code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 模型的方差是 <span class="math notranslate nohighlight">\(\mu+\alpha \mu^2\)</span>
，<code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 模型的方差多出来一项 <span class="math notranslate nohighlight">\(\alpha \mu^2\)</span>
，就是这多出来的一项使得 <code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 模型的理论方差不再是和期望相同，
并且可以通过参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 调节方差和期望的大小关系，
可以拟合泊松过度分散的数据，
因此 <code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 模型是最常用的用于替代泊松模型处理泊松过度分散数据的方案。</p>
</section>
<section id="id10">
<h3><span class="section-number">18.4.2. </span>参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计<a class="headerlink" href="#id10" title="永久链接至标题"></a></h3>
<p>辅助参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 和分散参数 <span class="math notranslate nohighlight">\(\phi\)</span>
是不同的。分散参数 <span class="math notranslate nohighlight">\(\phi\)</span> 不影响协变量参数 <span class="math notranslate nohighlight">\(\beta\)</span>
的估计过程，因此可以在 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 算法之后利用皮尔逊分散统计量估计。
然而，辅助参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 是会影响协变量参数 <span class="math notranslate nohighlight">\(\beta\)</span> 的估计过程的，
所以 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计是不同于 <span class="math notranslate nohighlight">\(\phi\)</span> 的。</p>
<p>负二项式模型中 <span class="math notranslate nohighlight">\(\alpha\)</span> 参数的确定一般有两种方法，一种是在 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 以外，
用某种方法确定 <span class="math notranslate nohighlight">\(\alpha\)</span> 的值，然后把它当成一个常量代入 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 过程。
此时负二项式模型就是一个标准的单参数 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 模型，可以使用 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 进行协变量参数估计。</p>
<p>如果需要模型自行估计 <span class="math notranslate nohighlight">\(\alpha\)</span>
，就需要修改 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 算法的过程，在 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 迭代的过程中插入 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计的过程。
在 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 迭代的每一步中插入一个 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计过程，
<span class="math notranslate nohighlight">\(\alpha\)</span> 和 <span class="math notranslate nohighlight">\(\beta\)</span> 交替估计。</p>
<p>在一个迭代步骤中，先假设 <span class="math notranslate nohighlight">\(\alpha\)</span> 是已知的，执行 <span class="math notranslate nohighlight">\(\beta\)</span> 的估计过程，
然后再利用 <span class="math notranslate nohighlight">\(\beta\)</span> 的估计值，估计 <span class="math notranslate nohighlight">\(\alpha\)</span> 的值。</p>
<p>在 <span class="math notranslate nohighlight">\(\beta\)</span>  已知的情况下，可以利用皮尔逊分散统计量来估计 <span class="math notranslate nohighlight">\(\alpha\)</span>
。理论上，负二项式模型的分散统计量值为 <span class="math notranslate nohighlight">\(1\)</span>
，可以利用这个</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-24">
<span class="eqno">(18.4.6)<a class="headerlink" href="#equation-glm-source-content-24" title="公式的永久链接"></a></span>\[\hat{\phi}=\frac{\chi^2}{N-p}
= \sum \frac{(y_i-\mu_i)^2}{(N-p)(\mu_i - \alpha \mu^2_i)}
= 1\]</div>
</section>
<section id="id11">
<h3><span class="section-number">18.4.3. </span>几何模型<a class="headerlink" href="#id11" title="永久链接至标题"></a></h3>
<p>当 <span class="math notranslate nohighlight">\(\alpha=1\)</span> 是，负二项式分布就变成了几何分布，
几何分布是负二项式分布的一个特例。
分别把 <code class="docutils literal notranslate"><span class="pre">NB-C</span></code> 模型和 <code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 模型
的 <span class="math notranslate nohighlight">\(\alpha\)</span> 设置为 <span class="math notranslate nohighlight">\(1\)</span> 就得到了
标准连接和对数连接的几何分布。</p>
<p>标准连接的 <code class="docutils literal notranslate"><span class="pre">NB-C</span></code> 模型的概率质量函数 <a class="reference internal" href="#equation-eq-nb-035">公式(18.2.7)</a>
转换成几何分布的概率质量函数为</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-55">
<span class="eqno">(18.4.7)<a class="headerlink" href="#equation-eq-nb-55" title="公式的永久链接"></a></span>\[f(y;\mu)
= \exp \left \{
y \ln  \left (\frac{\mu}{1+\mu}  \right  )-  \ln (1+\mu)
\right \}\]</div>
<p>对数连接的 <code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 模型的概率质量函数 <a class="reference internal" href="#equation-eq-nb-55">公式(18.4.7)</a>
转换成几何分布的概率质量函数为</p>
<div class="math notranslate nohighlight" id="equation-eq-nb-56">
<span class="eqno">(18.4.8)<a class="headerlink" href="#equation-eq-nb-56" title="公式的永久链接"></a></span>\[f(y;\mu)
= \exp \left \{
y \ln  ( \mu  )-  \ln (1+\mu)
\right \}\]</div>
<p>相比于负二项式分布，几何分布的概率质量函数没有了 <code class="docutils literal notranslate"><span class="pre">Gamma</span></code>
函数的部分，变得更加简洁一些。
几何分布和指数分布的图形几乎是已知的，
不同的是，指数分布是连续值分布，
而几何分布是离散分布，一般称几何分布和指数分布是离散相关的。</p>
<figure class="align-center" id="id21">
<span id="fg-nb-geometric"></span><a class="reference internal image-reference" href="../../../_images/负二项式分布_alpha_1.0.jpg"><img alt="../../../_images/负二项式分布_alpha_1.0.jpg" src="../../../_images/负二项式分布_alpha_1.0.jpg" style="width: 448.0px; height: 336.0px;" /></a>
<figcaption>
<p><span class="caption-number">图 18.4.1 </span><span class="caption-text">几何分布和指数分布近乎是一致的，</span><a class="headerlink" href="#id21" title="永久链接至图片"></a></p>
</figcaption>
</figure>
<p>几何分布的期望是 <span class="math notranslate nohighlight">\(\mu\)</span>
，方差是 <span class="math notranslate nohighlight">\(\mu+\mu^2\)</span>
，各个关键组件为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-25">
<span class="eqno">(18.4.9)<a class="headerlink" href="#equation-glm-source-content-25" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\text{自然参数} &amp; \quad \theta = \ln \left (\frac{ \mu}{1+ \mu} \right )\\
\text{累积分布函数} &amp; \quad b(\theta) =  \ln (1+\mu)\\\text{期望} &amp; \quad b'(\theta) =  \mu\\\text{方差函数} &amp; \quad \nu(\mu) = b''(\theta) =  \mu +  \mu^2\\\text{分散函数} &amp; \quad a(\phi) = 1\\\text{方差} &amp; \quad V(Y) =  a(\phi)\nu(\mu) = \mu + \mu^2 = \mu(1+\mu)\\\text{标准连接函数} &amp; \quad g(\mu) = \ln \left (\frac{ \mu}{1+ \mu} \right )\\\text{标准连接函数一阶导}  &amp; \quad g'(\mu) = \frac{1}{\mu+ \mu^2}\end{aligned}\end{align} \]</div>
<p>标准连接的对数似然函数为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-26">
<span class="eqno">(18.4.10)<a class="headerlink" href="#equation-glm-source-content-26" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\ell(\mu;y)
&amp;= \sum_{i=1}^N \left \{
y_i \ln  \left (\frac{\mu_i}{1+\mu_i}  \right  )-  \ln (1+\mu_i)
\right \}\\&amp;=\sum_{i=1}^N \left \{
y_i \ln (\mu_i) - (1+y_i) \ln (1+\mu_i)
\right \}\end{aligned}\end{align} \]</div>
<p>标准连接的偏差统计量为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-27">
<span class="eqno">(18.4.11)<a class="headerlink" href="#equation-glm-source-content-27" title="公式的永久链接"></a></span>\[\mathcal{D} =2\sum_{i=1}^N \left \{
y_i \ln \left (\frac{y_i}{\mu_i} \right )
-(1+y_i) \ln \left ( \frac{1+y_i}{1+\mu_i} \right )
\right \}\]</div>
<p>几何模型是一个单参数模型，因此可以直接应用 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code>
算法进行参数估计。</p>
</section>
<section id="id12">
<h3><span class="section-number">18.4.4. </span>广义负二项式模型<a class="headerlink" href="#id12" title="永久链接至标题"></a></h3>
<p>负二项式模型的方差函数为 <span class="math notranslate nohighlight">\(\mu+\alpha \mu^2\)</span>
，其中有一个 <span class="math notranslate nohighlight">\(\mu\)</span> 的二次项，
如果把二次项改成一次就变成了一个线性参数化方程，
我们把方差函数为 <span class="math notranslate nohighlight">\(\mu+ \alpha \mu\)</span> 的模型称为
线性负二项式模型，简称为 <code class="docutils literal notranslate"><span class="pre">NB-1</span></code> 模型。
泊松模型的方差等于期望 <span class="math notranslate nohighlight">\(\mu\)</span>
，而这些扩展模型都是在泊松方差的基础上乘上一个因子，
不同的乘数因子形成了不同的泊松扩展模型。</p>
<ul class="simple">
<li><p>泊松： <span class="math notranslate nohighlight">\(V=\mu\)</span></p></li>
<li><p>NB1： <span class="math notranslate nohighlight">\(V=\mu(1+\alpha )\)</span></p></li>
<li><p>NB2： <span class="math notranslate nohighlight">\(V=\mu(1+\alpha \mu)\)</span></p></li>
<li><p>几何： <span class="math notranslate nohighlight">\(V=\mu(1+\mu)\)</span></p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">NB-1</span></code> 模型，或者说线性负二项式模型，
也可以看做是泊松-伽马混合模型，
只不过在混合模型的定义和推导上和 <code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 模型有些差别。</p>
<p><code class="docutils literal notranslate"><span class="pre">NB-1</span></code> 模型方差函数是
<span class="math notranslate nohighlight">\(\mu+\alpha \mu\)</span>
，<code class="docutils literal notranslate"><span class="pre">NB-2</span></code> 模型方差函数是
<span class="math notranslate nohighlight">\(\mu+\alpha \mu^2\)</span>
，二者的差别在于 <span class="math notranslate nohighlight">\(\mu\)</span> 的幂次不一样，
按照这个规律是不是可以有更高幂次的模型？
更进一步，是不是可以把幂次也参数化？
比如用参数 <span class="math notranslate nohighlight">\(Q\)</span>
参数化方差函数的最高幂次，
则方差函数变为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-28">
<span class="eqno">(18.4.12)<a class="headerlink" href="#equation-glm-source-content-28" title="公式的永久链接"></a></span>\[V = \mu +\alpha \mu^Q\]</div>
<p>其中 <span class="math notranslate nohighlight">\(Q\)</span> 是一个待估计的的未知参数。
把方差函数的幂次参数化，相当于对负二项式模型的方差函数进行了一般化扩展，
因此我们称之为广义负二项式模型(generalized negative binomial)，
一般简称为 <code class="docutils literal notranslate"><span class="pre">NB-P</span></code> 模型。</p>
<p><code class="docutils literal notranslate"><span class="pre">NB-P</span></code> 模型是一个三参数模型，三个参数分别是
期望参数 <span class="math notranslate nohighlight">\(\mu\)</span> ，辅助参数 <span class="math notranslate nohighlight">\(\alpha\)</span>
，以及参数 <span class="math notranslate nohighlight">\(Q\)</span>
，显然已经不再属于 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 框架下的模型，
无法用 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 原版的 <code class="docutils literal notranslate"><span class="pre">IRLS</span></code> 算法进行参数估计。</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html" class="btn btn-neutral float-left" title="17. 过度分散" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html" class="btn btn-neutral float-right" title="19. 零计数问题" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2018, zhangzhenhu(acmtiger@outlook.com) 禁止一切形式的转载！.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
  


    <script src="https://utteranc.es/client.js"
            repo="zhangzhenhu/blog"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>



</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>