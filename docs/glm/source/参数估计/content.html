<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>参数估计 &mdash; 张振虎的博客 张振虎 文档</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
    <link rel="canonical" href="https://zhangzhenhu.github.io/blog/glm/source/参数估计/content.html" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/translations.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2.7.7/unpacked/MathJax.min.js"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"RR": "{\\bf R}", "bold": ["{\\bf #1}", 1]}}})</script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> 张振虎的博客
          </a>
              <div class="version">
                acmtiger@outlook.com
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">目录:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">广义线性模型</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html">1. 概率基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id2">1.1. 概率模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id3">1.1.1. 概率律</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id4">1.1.2. 离散模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id5">1.1.3. 连续模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id6">1.2. 条件概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id7">1.3. 联合概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id8">1.4. 全概率与贝叶斯定理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id9">1.5. 独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id10">1.6. 随机变量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id11">1.6.1. 离散随机变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id12">1.6.2. 连续随机变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id13">1.6.3. 累积分布函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id14">1.6.4. 随机变量的函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id15">1.6.5. 期望与方差</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id16">1.7. 边缘化</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id17">1.8. 常见概率分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id18">1.8.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id19">1.8.2. 二项式分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id20">1.8.3. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id21">1.8.4. 多项式分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id22">1.8.5. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id23">1.8.6. 卡方分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#t">1.8.7. t分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#f">1.8.8. F分布</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html">2. 最大似然估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#ch-liklihood">2.1. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id3">2.2. 伯努利分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id4">2.3. 类别分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#ch-2-gaussian-ml">2.4. 高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id6">2.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html">3. 推断与检验</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id2">3.1. 统计量和充分统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-sample-distribution">3.2. 抽样分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-sample-distribution-normal">3.2.1. 正态分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#t">3.2.2. t分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id5">3.2.3. 卡方分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id6">3.3. 极限理论</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id7">3.3.1. 马尔可夫和切比雪夫不等式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id8">3.3.2. 弱大数定律</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id9">3.3.3. 依概率收敛</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-clt">3.3.4. 中心极限定理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id11">3.3.5. 强大数定理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id12">3.4. 似然估计量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id13">3.4.1. 估计量的偏差与方差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-2-fisher-information">3.4.2. 信息量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-2-mle-estimator">3.4.3. 最大似然估计的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-influence-test-interval">3.5. 置信区间</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#z">3.5.1. 均值参数的 Z 区间估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id18">3.5.2. 均值参数的 T 区间估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id19">3.5.3. 方差参数的区间估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-influence-test-test">3.6. 简单假设检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id22">3.6.1. Z检验</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id23">3.6.2. T检验</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id24">3.6.3. 卡方检验</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html">4. 指数族</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#ch-24-1">4.1. 指数族的定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id3">4.1.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id4">4.1.2. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id5">4.1.3. 泊松分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id6">4.1.4. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id7">4.1.5. 其它常见指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#ch-24-moments">4.2. 指数族的期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id9">4.3. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#kl">4.4. 最大似然估计与KL散度的关系</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html">5. 线性回归模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id2">5.1. 最小二乘</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id3">5.1.1. 最小误差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id4">5.1.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id5">5.2. 线性回归的概率解释</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id6">5.2.1. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id7">5.2.2. 参数估计</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html">6. 广义线性模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id2">6.1. 指数族分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id3">6.1.1. 自然指数族</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id4">6.1.2. 示例：高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id5">6.1.3. 示例：伯努利分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id6">6.2. 广义线性模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id7">6.3. 例子</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html">7. 参数估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#ch-glm-estimate">7.1. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id3">7.2. 泰勒级数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id4">7.3. 梯度下降法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id6">7.4. 牛顿法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id7">7.4.1. 算法推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id8">7.4.2. 标准连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id9">7.4.3. 迭代初始值的设定</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#irls">7.5. 迭代重加权最小二乘(IRLS)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id10">7.5.1. 算法推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id11">7.5.2. 算法过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id12">7.6. 估计量的标准误差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#ch-glm-estimate-phi">7.7. 分散参数的估计</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html">8. 模型评估</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#id2">8.1. 拟合优度</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#id3">8.1.1. 嵌套模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#likelihood-ratio">8.1.2. 对数似然比(Likelihood ratio)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#deviance">8.1.3. 偏差(deviance)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#r-2">8.1.4. 决定系数 <span class="math notranslate nohighlight">\(R^2\)</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#ch-glm-gof-chi">8.1.5. 广义皮尔逊卡方统计量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#residual-analysis">8.2. 残差分析(Residual analysis)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#response-residuals">8.2.1. Response residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#working-residuals">8.2.2. Working residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#partial-residuals">8.2.3. Partial residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#pearson-residuals">8.2.4. Pearson residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#deviance-residuals">8.2.5. Deviance residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#score-residuals">8.2.6. Score residuals</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#model-selection">8.3. 模型选择(model selection)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#aic">8.3.1. AIC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#bic">8.3.2. BIC</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html">9. 模型检验</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id2">9.1. 拉格朗日乘子检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id3">9.1.1. 得分统计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id4">9.1.2. 检验过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#wald">9.2. wald 检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id5">9.2.1. 参数估计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id6">9.2.2. 检验过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id7">9.3. 似然比检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id8">9.3.1. 抽样分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id9">9.3.2. 模型比较</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id10">9.3.3. 偏差统计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#f">9.3.4. F 检验</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id11">9.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html">10. 高斯模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id2">10.1. 传统线性回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id3">10.2. 高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id4">10.3. 高斯回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id5">10.4. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id6">10.4.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#irls">10.4.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id7">10.4.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id10">10.5. 其它连接函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html">11. 逆高斯模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id2">11.1. 逆高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id3">11.2. 逆高斯回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id4">11.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id5">11.3.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#irls">11.3.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id6">11.3.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id7">11.4. 其它连接函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html">12. 二项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id2">12.1. 伯努利分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id3">12.2. 逻辑回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id4">12.2.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id5">12.2.2. 参数估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#odds-logit">12.2.3. odds 与 logit</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id6">12.3. 二项式分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id7">12.4. 二项式回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id8">12.4.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id9">12.4.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id10">12.5. 其它连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id11">12.5.1. 恒等连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#probit">12.5.2. probit 回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#log-log-clog-log">12.5.3. log-log 和 clog-log</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id12">12.6. 分组数据与比例数据</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html">13. 泊松模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#poisson">13.1. 泊松(Poisson)分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id2">13.1.1. 推导过程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id3">13.1.2. 泊松分布的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id5">13.2. 泊松回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id6">13.3. 参数估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id7">13.4. 拟合统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id8">13.5. 频率模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id9">13.6. 泊松模型的局限性</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html">14. 指数模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#exponential">14.1. 指数(exponential)分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id2">14.1.1. 推导过程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id3">14.1.2. 分布的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id6">14.2. 指数回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id7">14.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id8">14.3.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id9">14.3.2. 拟合优度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#irls">14.3.3. IRLS</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html">15. Gamma 模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id1">15.1. Gamma 函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id2">15.2. Gamma 分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id3">15.3. Gamma 回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id4">15.4. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id5">15.4.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#irls">15.4.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id6">15.4.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id7">15.5. 其他连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id8">15.5.1. 对数 Gamma 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#identity-gamma">15.5.2. 恒等(identity) Gamma 模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html">16. 过度分散</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id2">16.1. 什么是过度分散</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id3">16.2. 过度分散的检测</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id4">16.3. 过度分散的影响</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id5">16.4. 标准误差的修正</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html">17. 负二项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id2">17.1. 负二项式分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id3">17.1.1. 从二项式分布推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id4">17.1.2. 泊松-伽马混合分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#alpha">17.1.3. 辅助参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的影响</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id5">17.2. 负二项回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id6">17.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#irls">17.3.1. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id7">17.3.2. 参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id8">17.4. 负二项式模型扩展</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id9">17.4.1. 对数连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id10">17.4.2. 参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id11">17.4.3. 几何模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id12">17.4.4. 广义负二项式模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html">18. 零计数问题</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id2">18.1. 零截断模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id3">18.1.1. 零截断泊松模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id4">18.1.2. 零截断负二项式模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id5">18.2. 零膨胀模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#hurdle">18.2.1. Hurdle 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#zero-inflate">18.2.2. Zero-inflate 模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html">19. 多项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id2">19.1. 类别分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#softmax">19.2. softmax 回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id3">19.2.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id4">19.2.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id5">19.3. 多项式分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id6">19.4. 多项式回归模型</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html">20. 有序离散模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id2">20.1. 有序逻辑回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id3">20.2. 参数估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id4">20.3. 连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#logit">20.3.1. logit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#probit">20.3.2. probit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#clog-log">20.3.3. clog-log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#log-log">20.3.4. log-log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#cauchit">20.3.5. cauchit</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id5">20.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html">附录</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html#id2">标准正态累积分布表</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html#id3">卡方分布临界值表</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/content.html">参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../probability_model/index_html.html">概率图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html">1. 概率基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id2">1.1. 概率分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id3">1.2. 独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#marginalization">1.3. 边缘化(marginalization)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id6">1.4. 贝叶斯定理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id7">1.5. 期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id8">1.6. 常见概率分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id9">1.6.1. 离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id10">1.6.2. 连续变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id11">1.6.3. 计数变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id12">1.7. 大数定律</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id13">1.7.1. 独立同分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id14">1.7.2. 中心极限定理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id15">1.8. 信息论基础</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id16">1.8.1. 信息熵</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#kl">1.8.2. KL散度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id18">1.8.3. 互信息</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html">2. 参数估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-liklihood">2.1. 极大似然估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id3">2.1.1. 二值离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id4">2.1.2. 一般离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-2-gaussian-ml">2.1.3. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id6">2.1.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-bayesian-estimation">2.2. 贝叶斯估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id8">2.2.1. 伯努利变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id9">2.2.2. 类别变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id10">2.3. 最大后验估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id11">2.3.1. 伯努利变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id12">2.3.2. 类别变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id13">2.4. 最大似然估计与贝叶斯估计的对比</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id14">2.5. 统计量和充分统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#fisher-information">2.6. Fisher Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id15">2.7. 估计量的评价</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id16">2.7.1. 估计量的方差与偏差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id17">2.7.2. 大数定律和中心极限定理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-2-mle-estimator">2.7.3. 最大似然估计的特性</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html">3. 指数族</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#ch-24-1">3.1. 指数族的定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id3">3.1.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id4">3.1.2. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id5">3.1.3. 泊松分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id6">3.1.4. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id7">3.1.5. 其它常见指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#ch-24-moments">3.2. 指数族的期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id9">3.3. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#kl">3.4. 最大似然估计与KL散度的关系</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/19.%E5%A4%9A%E7%BB%B4%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83_26.html">4. 多维高斯分布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html">5. 有向图(Directed Graphical Models)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id1">5.1. 有向图</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id2">5.2. 条件独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id3">5.3. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html">6. 无向图(Undirected Graphical Models)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id1">6.1. 无向图的定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id2">6.2. 条件独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id3">6.3. 图的分解</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#vs">6.4. 有向图 vs 无向图</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id4">6.5. 树</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id5">6.6. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html">7. 因子图</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id2">7.1. 因子图的定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id3">7.2. 图模型之间的转换</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id4">7.2.1. 转换为因子图</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id5">7.2.2. 因子图转换为有向图</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id6">7.3. 图模型的评价</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#i-map">7.3.1. I-map</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#d-map">7.3.2. D-map</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#p-map">7.3.3. P-map</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html">8. 模型推断：消元法</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id2">8.1. 什么是模型的推断</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id3">8.2. 消元法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id4">8.2.1. 有向图消元算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#ch-condition-margin">8.2.2. 条件概率和边缘概率</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id6">8.2.3. 无向图的消元法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id7">8.3. 图消除</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id9">8.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html">9. 加和乘积算法(sum-product algorithm)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id1">9.1. 树结构</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id2">9.2. 从消元法到信息传播</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id3">9.3. 树模型的和积算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id4">9.4. 因子图的和积算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id5">9.5. 类树结构图模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#polytrees">9.6. 多重树(polytrees)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id6">9.7. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html">10. 最大后验估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id2">10.1. 最大后验概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id3">10.2. 最大化后验的状态</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id4">10.3. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html">11. 完整观测的参数学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id2">11.1. 有向图的参数学习</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id3">11.2. 无向图的参数学习</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id4">11.2.1. 成对二值变量模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id5">11.2.2. 一般二值变量模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html">12. 不完整观测的学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html#id2">12.1. 隐变量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html#em">12.2. 期望最大化算法(EM)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/14.%E5%9B%BE%E5%BD%A2%E7%BB%93%E6%9E%84%E7%9A%84%E5%AD%A6%E4%B9%A0_lecture_23.html">13. 有向图结构学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/16.%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD_lecture_17.html">14. 变分推断</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html">15. 马尔科夫蒙特卡洛</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#why-sampling">15.1. Why sampling？</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#monte-carlo">15.2. 蒙特卡罗(Monte Carlo)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#markov-chain">15.3. 马尔科夫链(Markov Chain)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id2">15.3.1. 一个例子</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#time-reversibility">15.3.2. 时间可逆性(Time Reversibility)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id3">15.3.3. 总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#markov-chain-monte-carlo">15.4. Markov Chain Monte Carlo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#metropolis-hastings">15.4.1. Metropolis-Hastings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id4">15.4.2. 例子：正态分布的采样</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id5">15.4.3. 多变量采样</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#gibbs">15.4.4. Gibbs 采样</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#mixing-time">15.5. Mixing Time</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#approximate-map-and-partitioning">15.6. Approximate MAP and Partitioning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html">16. 贝叶斯分类器</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id2">16.1. 朴素贝叶斯模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id3">16.1.1. 模型表示</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id4">16.1.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id5">16.2. 高斯判别模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id6">16.2.1. 一元高斯模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id7">16.2.2. 多元高斯模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id8">16.3. 逻辑回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id9">16.4. 生成模型和判别模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id10">16.5. 多分类</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id11">16.6. 其它扩展</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html">17. 回归模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id2">17.1. 机器学习的概率解释</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id3">17.2. 经典线性回归</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id4">17.2.1. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id5">17.3. 线性回归的概率解释</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id6">17.3.1. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id7">17.4. 凸函数最优化问题</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id8">17.5. 岭回归</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html">18. 分类模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id2">18.1. 生成模型与判别模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id3">18.2. 线性回归与线性分类</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id4">18.3. 生成模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id5">18.3.1. 高斯判别模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id6">18.3.2. 朴素贝叶斯模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id7">18.3.3. 指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id8">18.4. 判别模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id9">18.4.1. 逻辑回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id10">18.4.2. 多分类</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id11">18.4.3. 最大熵模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#probit">18.4.4. Probit 回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#noisy-or">18.4.5. Noisy-OR 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id12">18.4.6. 其它指数模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html">19. 广义线性模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id2">19.1. 定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id3">19.1.1. 指数族分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id4">19.1.2. 链接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id5">19.1.3. 例子</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id6">19.2. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id7">19.2.1. 梯度下降法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id8">19.2.2. 牛顿法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#irls">19.2.3. 迭代重加权最小二乘(IRLS)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#goodness-of-fit">19.3. goodness of fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id9">19.4. 连续值响应模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id10">19.4.1. 高斯族</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#gamma">19.4.2. Gamma族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id12">19.5. 二项响应模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id13">19.6. 多项响应模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id14">19.7. 计数响应模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id15">19.7.1. 泊松分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id16">19.8. GLM扩展</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html">20. 混合模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id2">20.1. 一般混合模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id3">20.1.1. 模型的有向图表示</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id4">20.1.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id7">20.2. 高斯混合模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id8">20.2.1. 模型的表示</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id9">20.2.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#k-means">20.3. K-means</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/32.%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90_42.html">21. 因子分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/%E4%BA%8C%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B.html">22. 二变量模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/33.LDA_43.html">23. 主题模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/33.LDA_43.html#plsa">23.1. PLSA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/33.LDA_43.html#lda">23.2. LDA</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html">24. 隐马尔可夫模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id2">24.1. 隐马尔可夫模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id3">24.1.1. 马尔可夫模型和朴素贝叶斯模型的关系</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id4">24.2. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/27.%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA_37.html">25. 条件随机场</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/28.%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%99%A8_38.html">26. 卡尔曼滤波器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/40.%E9%A1%B9%E7%9B%AE%E5%8F%8D%E5%BA%94%E7%90%86%E8%AE%BA_50.html">27. 项目反应理论</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/41.%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA_51.html">28. 贝叶斯知识追踪</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE.html">29. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../audio/index.html">语音技术</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../audio/feature.html">1. 音频特征</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id2">1.1. 认识声音</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id3">1.2. 认识声波</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id4">1.2.1. 物体的振动以及简谐振动</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id7">1.2.2. 什么是声波</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id8">1.2.3. 纯音和复合音</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#spectrum">1.2.4. 频谱 Spectrum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id10">1.2.5. 名词</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id13">1.3. 语音学</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id14">1.3.1. 发声原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id15">1.3.2. 听觉感应</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id16">1.4. 数字信号处理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id17">1.4.1. 模数转换</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#wav">1.4.2. 音频文件–WAV</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id18">1.5. 分帧与加窗</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id19">1.5.1. 预加重处理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id20">1.5.2. 分帧与加窗</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id21">1.6. 声音的感官度量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#sound-pressure-level-spl">1.6.1. 声压与声压级(Sound Pressure Level,SPL)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#intensity-level-il">1.6.2. 声强与声强级(Intensity Level,IL）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id22">1.6.3. 声压与声强的关系</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id23">1.6.4. 响度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id24">1.6.5. 音量计算</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id25">1.6.6. 频率与音高</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id26">1.7. 时域分析</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id27">1.7.1. 短时能量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id28">1.7.2. 短时平均幅度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id29">1.7.3. 短时过零率</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id31">1.8. 频域分析</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#spectrum-spectrogram">1.8.1. 声谱(spectrum)和时频谱(spectrogram)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#short-time-fourier-transform-stft">1.8.2. 短时傅里叶变换 Short-time Fourier transform (STFT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id33">1.8.3. 倒频谱</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id34">1.8.4. 色谱图</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id35">1.9. 小波域特征</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id36">1.9.1. 离散小波域变换</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id37">1.9.2. 小波域过零率</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id38">1.9.3. 小波域质心</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id39">1.9.4. 小波域子带能量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#mfcc">1.10. 语音识别的音频特征–MFCC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id40">1.11. 参考资料</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../edm/index.html">教育领域数据挖掘</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../edm/bkt.html">1. 贝叶斯知识追踪(Bayesian Knowledge Tracing,BKT)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id1">1.1. 简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#hidden-markov-model-hmm">1.2. 隐马尔科夫模型(Hidden Markov Model,HMM)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id5">1.3. 贝叶斯知识追踪(Bayesian Knowledge Tracing,BKT)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#bkt">1.3.1. BKT的参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#item-response-theory-irt">1.4. 项目反映理论(Item Response Theory,IRT)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#bktirt">1.5. BKT结合IRT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id6">1.6. 实验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id7">1.6.1. 数据集</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id8">1.6.2. 实验方法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id9">1.6.3. 实验结果</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id10">1.6.4. 项目代码</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id11">1.7. 未来工作</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id12">1.7.1. 题目难度的计算</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#irt">1.7.2. 多参数IRT模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id13">1.7.3. 参数估计算法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id14">1.8. 参考文献</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../nlp/index.html">自然语言处理</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html">1. 文本去重</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id2">1.1. 背景</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id3">1.2. 技术思路</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id4">1.3. 相似（距离）算法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#euclidean-distance">1.3.1. 欧氏距离（Euclidean Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#minkowski-distance">1.3.2. 闵科夫斯基距离（Minkowski Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#manhattan-distance">1.3.3. 曼哈顿距离（Manhattan Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#chebyshev-distance">1.3.4. 切比雪夫距离（Chebyshev Distance ）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#mahalanobis-distance">1.3.5. 马氏距离(Mahalanobis Distance)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#cosine-similarity">1.3.6. 余弦夹角相似度(Cosine Similarity)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#hamming-distance">1.3.7. 汉明距离（Hamming Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#jaccard">1.3.8. Jaccard 系数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id5">1.3.9. 编辑距离</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id6">1.3.10. 最长公共字串</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id7">1.3.11. 最长公共子序列</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id8">1.4. 文本去重</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#kshingle">1.4.1. KShingle算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#minhash">1.4.2. Minhash算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#simhash">1.4.3. simhash</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#ksentence">1.4.4. KSentence算法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id9">1.5. 话术去重</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../nlp/bert/content.html">2. Attention&amp;Transformer&amp;Bert 简介</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/bert/content.html#transformer">2.1. Transformer 从宏观到微观</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#seq2seq">2.1.1. seq2seq</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#id1">2.1.2. 模型的输入</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/bert/content.html#self-attention">2.2. Self-Attention</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#id2">2.2.1. 什么是注意力？</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#id3">2.2.2. 加权求和</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#id4">2.2.3. 位置编码</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../nlp/bert/content.html#multi-head">2.2.4. 多头注意力（Multi-head）</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/bert/content.html#attention">2.3. Attention 机制</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../nlp/bert/content.html#id5">2.4. 其它参考资料</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../rst_tutorial/latex.html">latex demo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../rst_tutorial/latex.html#latex">latex</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rst_tutorial/latex.html#how-to-write-an-m-x-n-matrix-in-latex">How to write an m x n matrix in LaTeX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-big-parentheses">With big parentheses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-parentheses">With parentheses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-brackets">With brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#latex-matrix-with-no-bracket">LateX matrix with no bracket</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-vertical-bar-brackets">With vertical bar brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-curly-brackets">with curly brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#with-double-vertical-bar-brackets">with double vertical bar brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#small-inline-matrix">small inline matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rst_tutorial/latex.html#examples-matrix-2-x-2-in-latex">Examples matrix 2 x 2 in LaTeX</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../rst_tutorial/graphviz.html">graphviz demo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../rst_tutorial/graphviz.html#id1">布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rst_tutorial/graphviz.html#id2">其它</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/index.html">读书笔记</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/index.html">《统计因果推断推理入门》读书笔记</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html">1. 第三章 干预的效果</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html#id2">1.1. 第3.1节 干预</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html#id3">1.2. 第3.2节 校正公式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html#id8">1.3. 第3.3节 后门准则</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html">《深度学习推荐系统》读书笔记</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id2">重点</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id3">冷启动</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id4">探索与利用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id5">召回层的主要策略</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#embedding">协同过滤 &amp; Embedding 向量</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">张振虎的博客</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>参数估计</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/glm/source/参数估计/content.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="ch-estimate">
<span id="id1"></span><h1>参数估计<a class="headerlink" href="#ch-estimate" title="永久链接至标题"></a></h1>
<p>在上一章节我们介绍了概率论的一些基础知识，我们知道了什么是随机变量，什么是概率分布。
在有些场景下，我们知道一个随机变量 <span class="math notranslate nohighlight">\(X\)</span> 服从什么概率分布
<span class="math notranslate nohighlight">\(p(X;\theta)\)</span> ，但是这个概率分布存在一个未知的参数
<span class="math notranslate nohighlight">\(\theta\)</span> 。
比如高斯分布中的均值 <span class="math notranslate nohighlight">\(\mu\)</span> 或者方差 <span class="math notranslate nohighlight">\(\sigma^2\)</span>
可能是未知的，亦或者两者都未知。
但是如果我们能得到这个随机变量的一些观测数据，我们就可以从这些数据中”学习(learning)”或者说”估计(estimate)”
出模型的未知参数，这些观测数据一般称为”训练数据(training data)”。
本章我们讨论如何利用这个概率分布的观测样本估计出这个未知参数。</p>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>什么是观测样本？</p>
<p>就是从某个概率分布 <span class="math notranslate nohighlight">\(p(X;\theta)\)</span> 中取得的样本值。</p>
</div>
<section id="ch-liklihood">
<span id="id2"></span><h2>极大似然估计<a class="headerlink" href="#ch-liklihood" title="永久链接至标题"></a></h2>
<p>假设有一个随机变量 <span class="math notranslate nohighlight">\(X\)</span> ，其概率分布是 <span class="math notranslate nohighlight">\(p(X;\theta)\)</span>
，其中 <span class="math notranslate nohighlight">\(\theta\)</span> 是这个概率分布的参数，其值是未知的。
我们有一些这个随机变量的观测值，这些观测值集合用符号
<span class="math notranslate nohighlight">\(\mathcal{D}=\{x^{(1)},x^{(2)},\ldots,x^{N}\}\)</span>
表示。这些观测值都是从同一个概率分布 <span class="math notranslate nohighlight">\(p(X;\theta)\)</span> 中得到的样本值，
并且通常我们认为这些样本是独立获取的，即每条样本值不依赖其它样本值，
所以这些样本满足独立同分布(i.i.d)的特性。</p>
<p>我们知道其中任意一条样本 <span class="math notranslate nohighlight">\(x^{(i)}\)</span> 的发生概率是 <span class="math notranslate nohighlight">\(p(x^{(i)};\theta)\)</span> ，
那么所有样本发生的联合概率是 <span class="math notranslate nohighlight">\(p(\mathcal{D};\theta)=p(x^{(1)},\ldots,x^{(N)};\theta)\)</span> ，
又由于所有样本是满足i.i.d的，根据联合概率分布的分解法则有：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-0">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-0" title="公式的永久链接"></a></span>\[p(\mathcal{D};\theta) = p(x^{(1)},\ldots,x^{(N)};\theta)
=\prod_{i=1}^{N} p(x^{(i)};\theta)\]</div>
<p>现在我们要思考如何得到 <span class="math notranslate nohighlight">\(\theta\)</span> 的值，我们假设 <span class="math notranslate nohighlight">\(\theta\)</span> 的可能取值空间为
<span class="math notranslate nohighlight">\(\Theta\)</span> 。
<span class="math notranslate nohighlight">\(\theta\)</span> 的取值有很多种可能，要想确定什么值合适就需要有评价的标准，
通过评价标准对比各个不同取值的”优劣”，然后选出其中最优的那个值。
这个评价的标准就是所有观测样本的联合概率 <span class="math notranslate nohighlight">\(p(\mathcal{D};\theta)\)</span> 。
通常我们认为最有可能发生的是概率最大的那个事件，既然这些观测样本已经发生了(我们已经观测到)，
我们就认为使得这些样本发生概率最大的那个 <span class="math notranslate nohighlight">\(\theta\)</span> 值是最优的。</p>
<p>通常把观测样本发生的联合概率称为似然(likelihood)，一般用符号 <span class="math notranslate nohighlight">\(L(\theta;\mathcal{D})\)</span> 表示，
有时也称为似然函数(likelihood function)。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-1">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-1" title="公式的永久链接"></a></span>\[L(\theta;\mathcal{D}) = p(\mathcal{D};\theta) = \prod_{i=1}^{N} p(x^{(i)};\theta)\]</div>
<p>我们说最优的 <span class="math notranslate nohighlight">\(\theta\)</span> 值是令观测样本发生概率最大的值，
即使得似然函数取得最大值的参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的值是最优的。
因此，参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的估计值 <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> 为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-2">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-2" title="公式的永久链接"></a></span>\[\hat{\theta}_{ML} = \mathop{\arg \max}_{\theta} L(\theta;\mathcal{D})
= \mathop{\arg \max}_{\theta} \prod_{i=1}^{N} p(x^{(i)};\theta)\]</div>
<p>仔细观察后发现，似然函数是每条样本概率 <span class="math notranslate nohighlight">\(p(x^{(i)};\theta)\)</span> 的连乘，
而概率值都是在[0,1]之间的，一系列小于1的数字连乘会趋近于0。
而计算机在处理浮点数时存在精度问题，太小的值是无法表示的。
所以一般我们会为似然函数加上一个对数操作来解决计算机的精度问题，
我们把加了对数的似然函数称为 <em>对数似然函数(log-likelihood function)</em> ，
一般用符号 <span class="math notranslate nohighlight">\(\ell\)</span> 表示。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-3">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-3" title="公式的永久链接"></a></span>\[\ell(\theta;\mathcal{D}) = \log L(\theta;\mathcal{D})\]</div>
<p>通过极大化对数似然函数 <span class="math notranslate nohighlight">\(\ell(\theta;\mathcal{D})\)</span> 得到 <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>
和极大化似然函数 <span class="math notranslate nohighlight">\(L(\theta;\mathcal{D})\)</span> 是等价的，这里不再证明，有兴趣的读者可以参考其他资料。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-4">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-4" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\hat{\theta}_{ML} &amp;= \mathop{\arg \max}_{\theta}  \ell(\theta;\mathcal{D})\\&amp;= \mathop{\arg \max}_{\theta} \log \prod_{i=1}^{N} p(x^{(i)};\theta)\\&amp;= \mathop{\arg \max}_{\theta} \sum_{i=1}^N \log p(x^{(i)};\theta)\end{aligned}\end{align} \]</div>
<p>那么如何进行极大化求解呢？通常有如下三种方法：</p>
<ol class="arabic">
<li><p>解析法(Analytic)，又叫直接求解法。我们知道一个函数在取得极值时其一阶导数是为0的，
那么通过令对数似然函数的一阶导数为0来解得 <span class="math notranslate nohighlight">\(\hat{\theta}_{ML}\)</span> 。
通过令对数似然函数的一阶导数为0，然后解等式方程的方法得到的 <span class="math notranslate nohighlight">\(\hat{\theta}_{ML}\)</span> 称为解析解。</p>
<blockquote>
<div><div class="math notranslate nohighlight" id="equation-glm-source-content-5">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-5" title="公式的永久链接"></a></span>\[\frac{\partial \ell}{\partial \theta} = 0\]</div>
</div></blockquote>
<p>函数的一阶导数为0的点称为“驻点”(stationary point)，可能为（局部）极大或者极小值点，也可能为鞍点(saddle point)，
可以通过极值点的二阶导数判断是极大值点还是极小值点。
并不是所有情况都能得到解析解的，很多时候是无法直接求得的，在后面的章节中我们会详细讨论。</p>
</li>
<li><p>网格搜索法(Grid Search)。如果我们知道 <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> 的值在实数域 <span class="math notranslate nohighlight">\(R\)</span> 的一个子空间中，可以对这个子空间进行搜索
来得到是的似然函数最大的参数值。换句话说，就是尝试这个空间中的每个值，找到令似然函数取得最大的参数值。网格搜索方法是一种很好的方法，它表明可以通过重复逼近和迭代来找到似然函数的最大值。
但是，它在大多数情况下不切实际，并且当参数数量变多时变得更加困难。</p></li>
<li><p>数值法(Numerical)。这是现在最常用的算法。本质上就是先为 <span class="math notranslate nohighlight">\(\theta\)</span> 赋予一个初始值，
然后利用爬山法找到最大值。梯度下降(上升)法(Gradient descent)，牛顿法(Newton-Raphson)，BHHH，DFP等等都属于这类。</p></li>
</ol>
<p>本章我们暂时只讨论极大似然估计的直接求解法，在后续的章节中再讨论数值法。
通过极大化似然函数估计参数的方法称为极大似然估计(maximum likelihood estimation,MLE)，
亦可以叫做最大似然估计。下面看几个具体的例子来直观的理解极大似然估计。</p>
<section id="id3">
<h3>伯努利分布<a class="headerlink" href="#id3" title="永久链接至标题"></a></h3>
<p>我们假设一个离散随机变量 <span class="math notranslate nohighlight">\(X\)</span> 是伯努利分布(Bernoulli distribution)，
即只有两种可能的取值 <span class="math notranslate nohighlight">\(X \in \{0,1\}\)</span>，
我们设其取值为1的概率为 <span class="math notranslate nohighlight">\(p(X=1)=\theta\)</span> ， 其概率分布可以写成:</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-6">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-6" title="公式的永久链接"></a></span>\[p(X;\theta) = \theta^x (1-\theta)^{(1-x)},x \in \{0,1\}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\theta\)</span> 就是我们需要估计出的参数。
假设现在有变量 <span class="math notranslate nohighlight">\(X\)</span> 的N次独立观测样本，用符号
<span class="math notranslate nohighlight">\(\mathcal{D}=\{x^{(1)},\ldots,x^{(N)}\}\)</span> 表示，
样本集的规模为 <span class="math notranslate nohighlight">\(|\mathcal{D}|=N\)</span> 。
我们利用极大似然估计法估计出参数 <span class="math notranslate nohighlight">\(\theta\)</span> 。
首先我们写出观测样本的对数似然函数。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-7">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-7" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\ell(\theta;\mathcal{D}) &amp;= \sum_{i=1}^N \log p(x^{(i)};\theta)\\&amp; = \sum_{i=1}^N \log [ \theta^{x^{(i)}} (1-\theta)^{(1-x^{(i)})} ]\\&amp; = \sum_{i=1}^N \log \theta^{x^{(i)}}  +  \sum_{i=1}^N \log (1-\theta)^{(1-x^{(i)})}\end{aligned}\end{align} \]</div>
<p>我们定义几个统计值，在样本集 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 中，
<span class="math notranslate nohighlight">\(n_0\)</span> 表示随机变量 <span class="math notranslate nohighlight">\(X=0\)</span> 在观测样本中的次数，
<span class="math notranslate nohighlight">\(\hat{p}_{\mathcal{D}}(0)=\frac{n_0}{N}\)</span> 表示随机变量 <span class="math notranslate nohighlight">\(X=0\)</span>
在观测中出现的相对频次(经验分数)；
<span class="math notranslate nohighlight">\(n_1\)</span> 表示 <span class="math notranslate nohighlight">\(X=1\)</span> 在样本中的次数，
<span class="math notranslate nohighlight">\(\hat{p}_{\mathcal{D}}(1)=\frac{n_1}{N}\)</span>
表示 <span class="math notranslate nohighlight">\(X=1\)</span> 在样本中出现的相对频次(经验分数)。
把 <span class="math notranslate nohighlight">\(n_0,n_1\)</span> 代入到对数似然函数中可得：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-8">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-8" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\ell(\theta;\mathcal{D}) &amp;=  \sum_{i=1}^N \log  \theta^{x^{(i)}}  +  \sum_{i=1}^N \log (1-\theta)^{(1-x^{(i)})}\\&amp;= \sum_{i=1}^N x^{(i)} \log \theta +  \sum_{i=1}^N (1-x^{(i)}) \log (1-\theta)\\&amp;= n_1 \log \theta + n_0 \log (1-\theta)\end{aligned}\end{align} \]</div>
<p>我们知道当对数似然函数的导数为0时，函数取得极大值（注意极大值不是最大值，极大值点也可能不存在，也可能存在多个）。
那么我们只需要对对数似然函数求导得到 <span class="math notranslate nohighlight">\(\theta\)</span> 的估计值。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-9">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-9" title="公式的永久链接"></a></span>\[\begin{split}\begin{aligned} 0 &amp;=\frac{\partial \ell}{\partial \theta} \\
 &amp;= \frac{n_1}{\theta}- \frac{n_0}{(1-\theta)} \end{aligned}\end{split}\]</div>
<p>又由于 <span class="math notranslate nohighlight">\(n_0 = N - n_1\)</span> ，带入上式可得：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-10">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-10" title="公式的永久链接"></a></span>\[\frac{n_1}{N-n_1}=\frac{\theta}{1-\theta}\]</div>
<p>最后化简可得 <span class="math notranslate nohighlight">\(\theta\)</span> 的极大似然估计值：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-11">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-11" title="公式的永久链接"></a></span>\[\hat{\theta}_{M L}=\frac{n_1}{N}\]</div>
</section>
<section id="id4">
<h3>类别分布<a class="headerlink" href="#id4" title="永久链接至标题"></a></h3>
<p>我们知道，二值离散变量称为伯努利变量(Bernoulli variable)，其概率分布称为伯努利分布(Bernoulli distribution)，
多次伯努利采样称为二项式分布(Binomial distribution)，伯努利分布是二项式分布特例，即仅进行单次实验的情况。
相对应的，多值离散变量称为类别变量(Categorical variable)，其概率分布称为类别分布(Category distribution)，
多次类别分布采样称为多项式分布(Multinomial distribution)，类别分布是多项式分布的单次实验特例。</p>
<p>我们用M表示变量的取值个数，比如对于伯努利变量M=2，用N表示实验次数(采样次数):</p>
<ol class="arabic simple">
<li><p>当 <span class="math notranslate nohighlight">\(M=2,N=1\)</span> 时，是伯努利分布(Bernoulli distribution)；</p></li>
<li><p>当 <span class="math notranslate nohighlight">\(M=2,N&gt;1\)</span> 时，是二项式分布(Binomial distribution)；</p></li>
<li><p>当 <span class="math notranslate nohighlight">\(M&gt;2,N=1\)</span> 时，是类别分布(Category distribution)；</p></li>
<li><p>当 <span class="math notranslate nohighlight">\(M&gt;2,N&gt;1\)</span> 时，是多项式分布(Multinomial distribution)；</p></li>
</ol>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>注意很多资料中，把类别分布也称为多项式分布，虽然没说错，但是很容易产生混淆，
这里我们明确使用类别分布来表示单次实验。</p>
</div>
<p>现在假设随机变量 <span class="math notranslate nohighlight">\(X\)</span> 是类别变量，其值域空间是 <span class="math notranslate nohighlight">\(\mathcal{X}=\{x_1,\dots,x_M\}\)</span> ，
类别分布的概率分布函数可以写成如下形式：</p>
<div class="math notranslate nohighlight" id="equation-2-100-10">
<span class="eqno">()<a class="headerlink" href="#equation-2-100-10" title="公式的永久链接"></a></span>\[ p(X;\theta) = \prod_{m=1}^{M} \theta_m^{\delta (x,x_m)}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\theta=[\theta_1,\dots,\theta_M]\)</span> 为分布的参数。
为表示方便，我们定义一个指示函数 <span class="math notranslate nohighlight">\(\delta(a,b)\)</span> ，当 <span class="math notranslate nohighlight">\(a=b\)</span> 时，指示函数输出为1，否则输出为0。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-12">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-12" title="公式的永久链接"></a></span>\[\begin{split}\delta (x,x_m) =  \left \{
\begin{aligned}
1 &amp;, \ x = x_{m} ;\\
0 &amp;, \ x \ne x_{m} ;
\end{aligned}
\right .\end{split}\]</div>
<p><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-2-100-10">公式(2.1.21)</a> 的含义是，变量 <span class="math notranslate nohighlight">\(X\)</span> 取值为类别 <span class="math notranslate nohighlight">\(x_m\)</span> 的概率是 <span class="math notranslate nohighlight">\(\theta_m\)</span> ，
即  <span class="math notranslate nohighlight">\(p(X=x_m;\theta)=\theta_m\)</span>
。其中参数向量 <span class="math notranslate nohighlight">\(\theta\)</span> 需要满足约束：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-13">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-13" title="公式的永久链接"></a></span>\[\sum_{m=1}^M \theta_m = 1
\ ,\
\theta_m \in [0,1]\]</div>
<p>现在利用最大似然估计估计出参数向量 <span class="math notranslate nohighlight">\(\theta\)</span> 的值，继续用符号 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 表示观测样本集，
<span class="math notranslate nohighlight">\(|\mathcal{D}|=N\)</span> ，
则似然函数为：</p>
<div class="math notranslate nohighlight" id="equation-20-mutil-likelihood">
<span class="eqno">()<a class="headerlink" href="#equation-20-mutil-likelihood" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}L(\theta;\mathcal{D}) &amp;=  \prod_{i=1}^N p(x^{(i)};\theta)\\&amp;= \prod_{i=1}^N \prod_{m=1}^{M} \theta_m^{\delta (x^{(i)},x_m)}\\&amp;=\prod_{m=1}^{M} \theta_m^{n_m}\end{aligned}\end{align} \]</div>
<p>其中 <span class="math notranslate nohighlight">\(n_m\)</span> 表示 <span class="math notranslate nohighlight">\(x_m\)</span> 在样本中出现的次数，那么有 <span class="math notranslate nohighlight">\(\sum_{m=1}^M n_m=N\)</span> 。
我们为似然函数加上对数操作，以便把连乘符号转换成加法。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-14">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-14" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\ell( \theta;\mathcal{D} ) &amp;= \log L(\theta;\mathcal{D} )\\&amp;=   \sum_{m=1}^M {n_m} \log \theta_m\end{aligned}\end{align} \]</div>
<p>为了找到 <span class="math notranslate nohighlight">\(\theta_m\)</span> 的最大似然解，我们需要最大化对数似然函数
<span class="math notranslate nohighlight">\(\ell(\theta;\mathcal{D} )\)</span> ，
并且限制 <span class="math notranslate nohighlight">\(\theta_m\)</span> 的和必须等于1。这样 <strong>带有约束的优化问题需要借用拉格朗日乘数</strong>
<span class="math notranslate nohighlight">\(\lambda\)</span> 实现，即需要最大化如下方程。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-15">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-15" title="公式的永久链接"></a></span>\[\sum_{m=1}^M {n_m} \log \theta_m + \lambda ( \sum_{m=1}^M \theta_m -1)\]</div>
<p>对上述公式求偏导，并令偏导等于0。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-16">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-16" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}0 &amp;=\frac{\partial }{\partial \theta_m}\\&amp;= \frac{n_m}{\theta_m} + \lambda\\\theta_m &amp;= - \frac{n_m}{\lambda}\end{aligned}\end{align} \]</div>
<p>把 <span class="math notranslate nohighlight">\(\theta_m = - \frac{n_m}{\lambda}\)</span> 代入到约束条件 <span class="math notranslate nohighlight">\(\sum_{m=1}^M \theta_m=1\)</span> 中，
解得 <span class="math notranslate nohighlight">\(\lambda = -N\)</span> ，最终可求得 <span class="math notranslate nohighlight">\(\theta_m\)</span> 的值：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-17">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-17" title="公式的永久链接"></a></span>\[\hat{\theta}_m =  \frac{n_m}{N}\]</div>
<p>我们发现，伯努利分布与类别分布的参数最大似然估计值具有相同的形式，并且最大似然估计值是可以通过样本统计的得到，
这是最大似然估计的一个特性。
样本的统计值被称为统计量(statistic)，
统计量(statistic)是 <strong>样本的一个函数</strong>，其代表着从样本中提取的一些”信息”，比如样本的均值(mean)，样本的总和(sum)等等。
很多时候这些信息可以用于确定这个分布的未知参数，
如果仅需要一个统计量就能确定这个分布的未知参数，而不再需要其它的额外”信息”，那么这个统计量就称为这个分布(或者分布族)
的 <strong>充分统计量(sufficient statistic)</strong> ，在后面的章节中我们会详细讨论充分统计量。</p>
</section>
<section id="ch-2-gaussian-ml">
<span id="id5"></span><h3>高斯分布<a class="headerlink" href="#ch-2-gaussian-ml" title="永久链接至标题"></a></h3>
<p>现在我们假设有一个高斯变量 <span class="math notranslate nohighlight">\(X \sim N(\mu,\sigma^2)\)</span> ，其参数有两个，均值 <span class="math notranslate nohighlight">\(\mu\)</span>
和方差 <span class="math notranslate nohighlight">\(\sigma^2\)</span> 。这个变量的一个观测样本集为 <span class="math notranslate nohighlight">\(\mathcal{D}=\{x^{(1)},x^{(2)},\ldots,x^{N}\}\)</span>
，我们利用极大似然估计出参数 <span class="math notranslate nohighlight">\(\mu,\sigma^2\)</span> ，我们先写出高斯分布的表达式。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-18">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-18" title="公式的永久链接"></a></span>\[p(x;\mu,\sigma^2) = \frac{1}{ (2\pi \sigma^2)^{\frac{1}{2}} } \exp \left \{ - \frac{1}{2\sigma^2} (x-\mu)^2 \right \}\]</div>
<p>这个概率分布表达式表示一条样本的发生概率，所有样本都发生的概率，也就是似然函数为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-19">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-19" title="公式的永久链接"></a></span>\[L(\mu,\sigma^2;\mathcal{D}) = \prod_{i=1}^N p(x^{(i)};\mu,\sigma^2)\]</div>
<p>其对数似然函数，我们选择以自然对数e为底数的对数ln ，则其对数似然函数为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-20">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-20" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned} \ell (\mu,\sigma^2;\mathcal{D};) &amp;= ln \prod_{i=1}^N p(x^{(i)};\mu,\sigma^2)\\&amp;= \sum_{i=1}^N \ln p(x^{(i)};\mu,\sigma^2)\\&amp;= \sum_{i=1}^N \left [ -\frac{1}{2} \ln 2 \pi \sigma^2    - \frac{1}{2\sigma^2} (x^{(i)}-\mu)^2 \right ]\\&amp;= \sum_{i=1}^N \left [ -\frac{1}{2} \ln 2 \pi    -\frac{1}{2} \ln \sigma^2    - \frac{1}{2\sigma^2} (x^{(i)}-\mu)^2 \right ]\\&amp;=  -\frac{N}{2} \ln 2 \pi    -\frac{N}{2} \ln \sigma^2    -  \frac{1}{2\sigma^2} \sum_{i=1}^N (x^{(i)}-\mu)^2\end{aligned}\end{align} \]</div>
<p>然后对参数求偏导数，并令偏导数为0。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-21">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-21" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\begin{cases}
\frac{\partial \ell}{\partial \mu} = \frac{1}{\sigma^2} \sum_{i=1}^N (x^{(i)}-\mu) = 0\\\frac{\partial \ell}{\partial \sigma^2}= -\frac{N}{2\sigma^2} + \frac{1}{2\sigma^4} \sum_{i=1}^N (x^{(i)}-\mu)^2=0
\end{cases}\end{aligned}\end{align} \]</div>
<p>由第一个等式可以解的：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-22">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-22" title="公式的永久链接"></a></span>\[\mu = \frac{1}{N} \sum_{i=1}^N x^{(i)} = \bar{x}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\bar{x}\)</span> 表示样本的平均值，然后代入第二个等式解得：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-23">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-23" title="公式的永久链接"></a></span>\[\sigma^2= \frac{1}{N} \sum_{i=1}^N (x_i-\bar{x})\]</div>
<p>我们发现最终似然估计的参数的值只依赖两个量：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-24">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-24" title="公式的永久链接"></a></span>\[\sum_{i=1}^N x^{(i)},\sum_{i=1}^N (x_i-\bar{x})\]</div>
<p>这两个量被称为高斯分布的充分统计量(sufficient statistics)。</p>
</section>
<section id="id6">
<h3>总结<a class="headerlink" href="#id6" title="永久链接至标题"></a></h3>
<p>通过上面的两个例子，我们来总结下用极大似然方法估计参数的一般模式。</p>
<p>令 <span class="math notranslate nohighlight">\(X\)</span> 表示随机变量，
令 <span class="math notranslate nohighlight">\(p(X;\theta)\)</span> 为随机变量 <span class="math notranslate nohighlight">\(X\)</span> 的概率分布的参数化表示，
其中 <span class="math notranslate nohighlight">\(\theta\)</span> 是概率分布函数中的未知参数向量
（注意 <span class="math notranslate nohighlight">\(\theta\)</span> 表示是多个参数的集合，不一定只有一个未知参数）。
我们把 <span class="math notranslate nohighlight">\(\theta\)</span> 看做是一个 <strong>非随机变量</strong> ，是一系列数值变量，但是其具体取值却是未知的。</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(p(\cdot;\theta)\)</span> 是一个参数为 <span class="math notranslate nohighlight">\(\theta\)</span> 的概率分布的pdf(概率质量函数)或者pmf(概率密度函数)。</p></li>
<li><p><span class="math notranslate nohighlight">\(L(\cdot ; \mathcal{D}) \triangleq p(\mathcal{D} ; \cdot)\)</span> 是随机变量 <span class="math notranslate nohighlight">\(X\)</span> 的观测数据集 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 的似然函数(likelihood function) 。</p></li>
</ul>
<p>我们给出 <span class="math notranslate nohighlight">\(N\)</span> 个观测样本(训练数据集)，<span class="math notranslate nohighlight">\(\mathcal{D}=\{x^{(1)}, \ldots, x^{(N)}\}\)</span> ，上标代表样本编号。
目标是学习出参数 <span class="math notranslate nohighlight">\(\theta\)</span> 。
一个在给定观测时学习未知参数的方法是使用最大似然估计(maximum likelihood estimation,MLE)，也叫极大似然估计。</p>
<dl class="glossary">
<dt id="term-maximum-likelihood-estimation-MLE">最大似然估计(maximum likelihood estimation,MLE)<a class="headerlink" href="#term-maximum-likelihood-estimation-MLE" title="Permalink to this term"></a></dt><dd><p>最直接的理解是：当使得给定观测数据的似然函数取得最大值时，此时似然函数中未知参数的取值是最优的。</p>
<p>似然函数的概率解释是：这些观测值(观测值是可观测到的随机变量的取值)”同时(不是时间上的同时，是联合发生)”发生的概率。
最大似然就是：既然这些样本事件已经发生了，那么我就假设他们的发生的概率是最大的，就认为使得这些样本具有最大发生概率时参数的值是最优取值。
注意，最大似然估计的解不一定存在，也不一定唯一，这取决于似然函数是否有极值点，以及有几个极值点。</p>
</dd>
</dl>
<p>我们假设观察样本都是独立同分布(i.i.d.)于 <span class="math notranslate nohighlight">\(p(X;\theta)\)</span> ，
则这些观测样本 <span class="math notranslate nohighlight">\(\mathcal{D}=\{x^{(1)}, \ldots, x^{(N)}\}\)</span> 的对数似然函数是：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-25">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-25" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\begin{aligned} \ell (\theta;\mathcal{D}) &amp;= \log L(\theta;\mathcal{D})\\&amp;= \log  p(x^{(1)}, \ldots, x^{(N)} ;\theta )\\&amp;= \log  \prod_{i=1}^{N} p(x^{(i)} ; \theta)\\&amp;= \sum_{i=1}^{N} \log p(x^{(i)} ; \theta)  \end{aligned}\end{aligned}\end{align} \]</div>
<p>然后我们通过极大化对数似然函数的方式求解参数的值。当然有些时候我们可以令偏导数为0直接求得解析解，
然而有时候却无法得到解析解，这时就需要用梯度迭代的方法求解。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-26">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-26" title="公式的永久链接"></a></span>\[\hat{\theta}_{ML} = \mathop{\arg \max}_{\theta} \ell (\theta;\mathcal{D})\]</div>
<p>极大似然估计有一个很大的缺陷，例如投掷一个普通的硬币3次，每次都是正面朝上，这时极大似然估计正面朝上的概率时结论会是1，
表示所有未来的投掷结果都是正面向上。这明显是有问题的，当数据集较少时非常容易出现错误的结果，
贝叶斯估计可以一定程度上避免这类问题。</p>
</section>
</section>
<section id="ch-bayesian-estimation">
<span id="id7"></span><h2>贝叶斯估计<a class="headerlink" href="#ch-bayesian-estimation" title="永久链接至标题"></a></h2>
<p>在概率学说中，存在着两个学派：频率学派和贝叶斯学派，
极大似然估计是频率学派的思想，而贝叶斯估计是贝叶斯学派的思想。
这里我们并不过多的讨论两个学派的区别，我们只需要知道极大似然估计估计和贝叶斯估计二者在思想上的差别。</p>
<p><strong>频率学派</strong></p>
<p>在上节讲解似然估计的时候，
我们用一个参数化的概率分布 <span class="math notranslate nohighlight">\(p(X;\theta)\)</span> 表示随机变量 <span class="math notranslate nohighlight">\(X\)</span> 的概率分布。
<span class="math notranslate nohighlight">\(\theta\)</span> 取不同值，会得到不同的 <span class="math notranslate nohighlight">\(p(X;\theta)\)</span> 的函数表达式，
比如： <span class="math notranslate nohighlight">\(p(X;\theta=0.5)\)</span> ，<span class="math notranslate nohighlight">\(p(X;\theta=0.6)\)</span> 。</p>
<p>频率学派中，参数 <span class="math notranslate nohighlight">\(\theta\)</span> 被看做一个数值对象，<strong>其值是固定值，只不过是未知的</strong> ，
目标是找到那个最优的参数值，然后代入 <span class="math notranslate nohighlight">\(p(X;\theta)\)</span> 。
这等价于：在 <span class="math notranslate nohighlight">\(\theta\)</span> 取某个值的条件下，变量 <span class="math notranslate nohighlight">\(X\)</span> 的概率分布，
也就是
把 <span class="math notranslate nohighlight">\(p(X;\theta)\)</span> 看做是 <strong>条件概率分布</strong> <span class="math notranslate nohighlight">\(p(X|\theta)\)</span> 。</p>
<p>最大似然估计的思想中，认为变量 <span class="math notranslate nohighlight">\(X\)</span> 的概率分布是条件概率分布 <span class="math notranslate nohighlight">\(p(X|\theta)\)</span> ，
只要找到参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的值就可以确定 <span class="math notranslate nohighlight">\(p(X|\theta)\)</span> 的表达式，
然后就可以利用条件概率分布 <span class="math notranslate nohighlight">\(p(X|\theta=\hat{\theta})\)</span> 生成新的 <span class="math notranslate nohighlight">\(X\)</span> 的样本值，
整个过程如下：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-27">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-27" title="公式的永久链接"></a></span>\[\mathcal{D} \xrightarrow{\text{MLE}} \hat{\theta}_{ML}
\xrightarrow{\text{代入}} p(X|\theta=\hat{\theta}_{ML})
\xrightarrow{\text{采样}} x_{\text{新样本}}\]</div>
<p><strong>贝叶斯学派</strong></p>
<p>然而贝叶斯学派认为，参数值并不是固定值，而是不确定的，因为我们并没有观察到。
对于没有观察到的事件（得到证据证明其值是什么），其每种值都是有可能的。
在 <span class="math notranslate nohighlight">\(p(X;\theta)\)</span> 中，参数 <span class="math notranslate nohighlight">\(\theta\)</span> 应该也是一个值随机的变量，
因此 <span class="math notranslate nohighlight">\(p(X;\theta)\)</span> 应该是联合概率分布 <span class="math notranslate nohighlight">\(p(X,\theta)\)</span>
，而不是条件概率分布。
根据链式法则，联合概率可以分解成条件概率的乘积：</p>
<div class="math notranslate nohighlight" id="equation-eq-2-10">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-10" title="公式的永久链接"></a></span>\[p(X,\theta) = p(\theta) p(X|\theta)\]</div>
<p>其中，<span class="math notranslate nohighlight">\(p(\theta)\)</span> 是变量 <span class="math notranslate nohighlight">\(\theta\)</span> 的概率分布，
<span class="math notranslate nohighlight">\(p(X|\theta)\)</span> 是已知 <span class="math notranslate nohighlight">\(\theta\)</span> 的条件下 <span class="math notranslate nohighlight">\(X\)</span> 的条件概率分布。
此时，一条 <span class="math notranslate nohighlight">\(X\)</span> 的观测样本的生成过程是：</p>
<ol class="arabic simple">
<li><p>先从概率分布 <span class="math notranslate nohighlight">\(p(\theta)\)</span> 得到 <span class="math notranslate nohighlight">\(\theta\)</span> 的采样值 <span class="math notranslate nohighlight">\(\bar{\theta}\)</span>。</p></li>
<li><p>再把 <span class="math notranslate nohighlight">\(\bar{\theta}\)</span> 代入条件概率分布  <span class="math notranslate nohighlight">\(p(X|\theta=\bar{\theta})\)</span> 。</p></li>
<li><p>最后从条件概率分布 <span class="math notranslate nohighlight">\(p(X|\theta=\bar{\theta})\)</span> 采样得到 <span class="math notranslate nohighlight">\(\bar{x}\)</span> 。</p></li>
</ol>
<p>和频率派(最大似然估计)的最大区别就是，在生成 <span class="math notranslate nohighlight">\(X\)</span> 的样本前，
需要先根据 <span class="math notranslate nohighlight">\(\theta\)</span> 的概率分布 <span class="math notranslate nohighlight">\(p(\theta)\)</span> 得到 <span class="math notranslate nohighlight">\(\theta\)</span> 的样本值。
<span class="math notranslate nohighlight">\(\theta\)</span> <strong>也是一个随机值</strong> 。
事实上，我们并不需要真的去采样参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的值，
可以通过对联合概率分布进行边缘化操作得到变量 <span class="math notranslate nohighlight">\(X\)</span> 边缘概率分布。</p>
<div class="math notranslate nohighlight" id="equation-eq-2-12">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-12" title="公式的永久链接"></a></span>\[p(X) = \int_0^1 p(X,\theta) d\theta = \int_0^1 p(\theta)  p(X|\theta) d \theta\]</div>
<p>通过对 <span class="math notranslate nohighlight">\(\theta\)</span> 进行积分，我们可以消除联合概率公式中的参数 <span class="math notranslate nohighlight">\(\theta\)</span>
，得到 <span class="math notranslate nohighlight">\(X\)</span> 边缘概率分布 <span class="math notranslate nohighlight">\(p(X)\)</span> ，进而用边缘概率分布 <span class="math notranslate nohighlight">\(p(X)\)</span>
对 <span class="math notranslate nohighlight">\(X\)</span> 进行采样。</p>
<p>但无论是先对 <span class="math notranslate nohighlight">\(\theta\)</span> 进行采样，还是得到边缘概率分布 <span class="math notranslate nohighlight">\(p(X)\)</span>
，我们都需要得到参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的概率分布 <span class="math notranslate nohighlight">\(p(\theta)\)</span> 的表达式，
而贝叶斯估计就是利用贝叶斯定理得到 <span class="math notranslate nohighlight">\(p(\theta)\)</span> 。</p>
<p><strong>贝叶斯定理</strong></p>
<p>我们知道变量 <span class="math notranslate nohighlight">\(\theta\)</span> 和变量 <span class="math notranslate nohighlight">\(X\)</span>
组成联合概率 <span class="math notranslate nohighlight">\(p(\theta,X)\)</span>
，并且二者不是相互的独立的，
变量 <span class="math notranslate nohighlight">\(\theta\)</span>
影响着变量 <span class="math notranslate nohighlight">\(X\)</span>
，二者存在”因果关系”，
<span class="math notranslate nohighlight">\(\theta\)</span> 是”因”，<span class="math notranslate nohighlight">\(X\)</span> 是”果”。
联合概率可以通过链式法则分解成一系列条件概率的乘积形式，
链式法则并没有限定变量的顺序(只受到变量间独立性影响)，
所以联合概率 <span class="math notranslate nohighlight">\(p(X,\theta)\)</span>
有两种分解方式：</p>
<div class="math notranslate nohighlight" id="equation-eq-2-13">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-13" title="公式的永久链接"></a></span>\[p(X,\theta) = p(\theta) p(X|\theta) = p(X) p(\theta|X)\]</div>
<p>通过移项可以得到：</p>
<div class="math notranslate nohighlight" id="equation-eq-2-14">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-14" title="公式的永久链接"></a></span>\[ p(\theta|X) = \frac{p(\theta) p(X|\theta)}{p(X)}\]</div>
<p><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-14">公式(2.2.11)</a> 就是贝叶斯定理，贝叶斯定理的核心就是如下的转换:</p>
<div class="math notranslate nohighlight" id="equation-eq-2-15">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-15" title="公式的永久链接"></a></span>\[p(\text{因}|\text{果}) = \frac{p(\text{因})p(\text{果}|\text{因}) }{p(\text{果})}\]</div>
<p>很多场景下，我们可以看到”果”，也就是我们有变量 <span class="math notranslate nohighlight">\(X\)</span>
的观测值，但我们不知道导致这个”果”的”因”是什么，也就是不知道变量 <span class="math notranslate nohighlight">\(\theta\)</span>
是什么。这时我们就可以利用贝叶斯定理推断出”因”，而这就是通常所说的贝叶斯推断(Bayesian inference)，
很多资料中会把”结果”(观测值)称之为证据(evidence)，把”果”变量称为证据变量。</p>
<p><strong>贝叶斯推断</strong></p>
<p>变量 <span class="math notranslate nohighlight">\(\theta\)</span>
是”因”变量，变量 <span class="math notranslate nohighlight">\(X\)</span> 是”果”变量，而其观测值 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>
就是看到的”结果”，
我们把变量 <span class="math notranslate nohighlight">\(X\)</span> 的观测样本 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>
和变量 <span class="math notranslate nohighlight">\(\theta\)</span>
写成贝叶斯定理的形式：</p>
<div class="math notranslate nohighlight" id="equation-eq-2-16">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-16" title="公式的永久链接"></a></span>\[p(\theta|\mathcal{D})
=\frac{p(\mathcal{D}|\theta) p'(\theta)}{p(\mathcal{D})}\]</div>
<ul>
<li><p><span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span> 表示基于”结果” <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>
推断出的”因”变量 <span class="math notranslate nohighlight">\(\theta\)</span> 的概率分布，
通常被称为
<strong>后验概率分布(posterior probability distribution)</strong>
，这里”后验”就表示有了 <strong>证据</strong> 之后，这里的证据就是指”观测结果”，也就是观测样本集。</p></li>
<li><dl class="simple">
<dt><span class="math notranslate nohighlight">\(p'(\theta)\)</span> 表示的是在没有任何证据(观测样本集)时，经验上对 <span class="math notranslate nohighlight">\(\theta\)</span> 的认知，</dt><dd><p>称为 <strong>先验概率分布(prior probability distribution)</strong> 。
先验一般是根据具体的应用场景凭借经验为之设定一个常见的概率分布，
如果你对 <span class="math notranslate nohighlight">\(p(\theta)\)</span> 一无所知那可以设定为均匀分布。
注意这里的 <span class="math notranslate nohighlight">\(p'(\theta)\)</span> 和 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-10">公式(2.2.8)</a> 中的 <span class="math notranslate nohighlight">\(p(\theta)\)</span> 虽然都表示参数变量的边缘概率，
但它们是在贝叶斯估计中不同阶段的表示，所以这里我们加了一个上标”‘“进行区分，
后面我们会说明。</p>
</dd>
</dl>
</li>
<li><p><span class="math notranslate nohighlight">\(p(\mathcal{D}|\theta)\)</span> 就是在有 <span class="math notranslate nohighlight">\(\theta\)</span> 的条件下生成观测样本的的概率，
我们知道观测样本集是符合独立同分布(i.i.d)的，所以展开后具有如下形式：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-28">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-28" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(\mathcal{D}|\theta) &amp;= p(\{x^{(1)},\ldots,x^{(N)}\}|\theta)\\&amp;= \prod_{i=1}^{N} p(x_i|\theta)\end{aligned}\end{align} \]</div>
<p>我们发现这其实就是样本的似然，所以 <span class="math notranslate nohighlight">\(p(\mathcal{D}|\theta)\)</span> 就是样本的似然值。</p>
</li>
<li><p><span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span> 是”果”的观测，直观的讲就是观测样本集的概率分布，通常被称为证据(evidence)。
<span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span> 作为分母，本质上就是归一化因子，是分子所有可能取值的求和，保证输出的 <span class="math notranslate nohighlight">\([0,1]\)</span>
区间内合法概率值，可以通过对分子积分(求和)得到。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-29">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-29" title="公式的永久链接"></a></span>\[p(\mathcal{D}) = \int p(\mathcal{D}|\theta) p'(\theta) d\theta\]</div>
<p><span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span> 作为归一化因子，通过对分子中参数变量积分得到，消除了参数的影响，其不再受到参数的
影响。换句话说，只要样本集 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 确定了，那么 <span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span>
的值就确定了，不再变化，在确定了样本集后，其是一个固定值。</p>
</li>
</ul>
<p>综上，贝叶斯推断可以表述成如下方式，
其中符号 <span class="math notranslate nohighlight">\(\propto\)</span> 表示正比关系。</p>
<div class="math notranslate nohighlight" id="equation-eq-2-17">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-17" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\text{后验概率} &amp;= \frac{\text{似然(likelihood)} \times  \text{先验(prior)}}{\text{证据(evidence)}}\\&amp; \propto \text{似然} \times  \text{先验}\end{aligned}\end{align} \]</div>
<p>我们可以用贝叶斯推断找到参数变量 <span class="math notranslate nohighlight">\(\theta\)</span> 的后验概率分布 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span>
，然后把 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span> 作为参数的”真实”概率分布，
然后代入到 <a class="reference internal" href="#equation-eq-2-17">公式()</a> 中，
这样我们就确定了变量 <span class="math notranslate nohighlight">\(X\)</span> 和变量 <span class="math notranslate nohighlight">\(\theta\)</span>
的联合概率分布，并且依此得到 <span class="math notranslate nohighlight">\(X\)</span> 的边缘概率分布：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-30">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-30" title="公式的永久链接"></a></span>\[p(X) = \int_0^1 p(X,\theta) d\theta = \int_0^1 p(\theta|\mathcal{D}) p(X|\theta) d \theta\]</div>
<p>但是要利用 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-16">公式(2.2.13)</a> 推断出 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span>
还存在两个难点：</p>
<ol class="arabic simple">
<li><p>先验分布 <span class="math notranslate nohighlight">\(p'(\theta)\)</span> 如何确定。</p></li>
<li><p>分母 <span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span> 需要计算积分，并且是对 <span class="math notranslate nohighlight">\(p'(\theta)\)</span> 进行积分，
<span class="math notranslate nohighlight">\(p'(\theta)\)</span> 的形式会影响积分的难度。</p></li>
</ol>
<p>理论上参数的先验分布应该根据我们其认知信息确定，
但实际上多数情况下我们对参数是一无所知的，没有任何信息，
这时，我们就需要一种被称为无信息先验（noninformative prior）的先验分布。
这种先验分布的目的是尽可能的对后验分布产生小的影响（Jeffries, 1946; Box and Tao, 1973; Bernardo and Smith, 1994）。
这有时也被称为“让数据自己说话”。
除无信息先验外，另外一种确定先验分布的方法为共轭先验(conjugate prior)，
共轭先验是一种使用非常广泛的确定先验分布的方法，
本节我们只讨论共轭先验法。</p>
<p><strong>共轭先验</strong></p>
<div class="topic" id="ch-conjugate-prior">
<p class="topic-title">共轭先验(conjugate prior)</p>
<p>在贝叶斯推断中，如果后验分布与先验分布属于同一种概率分布，则此先验分布称为共轭先验。
注意，由于后验分布是由先验与似然相乘得到的，所以共轭指的是先验与似然共轭，
共轭先验与似然相乘后，不改变分布的函数形式，所以得到后验与先验具有相同的形式。</p>
</div>
<p>共轭先验使得后验分布和先验分布拥有相同的形式，
很多时候可以直接给出后验的结果，
而不必计算分母 <span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span>
，这极大的降低了后验分布的计算复杂度。
高斯分布的似然函数的共轭分布仍然是高斯分布，伯努利分布的似然函数的共轭先验是beta分布，
类别分布的似然函数的共轭分布是狄利克雷分布，
稍后我们会举例说明。
共轭先验也是有缺点的，<strong>其一是只有指数族分布才存在共轭先验，在下一章我们会详细讨论指数族。</strong>
<strong>其二是，选取共轭先验更多是为了计算简单，而不是为了更精确的估计参数。</strong></p>
<p>选取了合适的参数先验分布后，就可以利用贝叶斯推断 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-16">公式(2.2.13)</a>
得到参数的后验概率分布 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span>
，后验概率分布就是我们在观测样本集的条件下对参数变量 <span class="math notranslate nohighlight">\(\theta\)</span>
概率分布的估计。
然后就可以用后验概率分布 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span> 替代 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-10">公式(2.2.8)</a>
中参数变量的边缘概率分布。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-31">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-31" title="公式的永久链接"></a></span>\[p(\theta) \triangleq p(\theta|\mathcal{D})\]</div>
<p><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-10">公式(2.2.8)</a> 表示的联合概率也就变成：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-32">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-32" title="公式的永久链接"></a></span>\[p(X,\theta) \triangleq p(\theta|\mathcal{D})  p(X|\theta)\]</div>
<p>此时变量 <span class="math notranslate nohighlight">\(X\)</span> 的边缘概率分布为：</p>
<div class="math notranslate nohighlight" id="equation-eq-2-19">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-19" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(X) &amp;= \int p(X,\theta) d\theta\\&amp;= \int p(\theta|\mathcal{D})  p(X|\theta) d \theta\\&amp;=  p(X|\mathcal{D})\end{aligned}\end{align} \]</div>
<p>有了 <span class="math notranslate nohighlight">\(X\)</span> 的边缘概率分为，就可以预测新样本的概率：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-33">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-33" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(X=x_{new}) &amp;=  p(X=x_{new}|\mathcal{D})\\&amp;= \int p(\theta|\mathcal{D})  p(X=x_{new}|\theta) d \theta\end{aligned}\end{align} \]</div>
<section id="id8">
<h3>伯努利分布<a class="headerlink" href="#id8" title="永久链接至标题"></a></h3>
<p>假设随机变量 <span class="math notranslate nohighlight">\(X\)</span> 服从伯努利分布(Bernoulli distribution)，
其参数化的条件概率分布为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-34">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-34" title="公式的永久链接"></a></span>\[p(X|\theta) = \theta^x (1-\theta)^{(1-x)},x \in \{0,1\}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\theta\)</span> 是需要估计的未知参数，
现在我们认为 <span class="math notranslate nohighlight">\(\theta\)</span> 也是一个随机变量，并且其概率分布为 <span class="math notranslate nohighlight">\(p(\theta)\)</span> ，
观测变量 <span class="math notranslate nohighlight">\(X\)</span> 与参数变量 <span class="math notranslate nohighlight">\(\theta\)</span>  的联合概率分布为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-35">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-35" title="公式的永久链接"></a></span>\[p(X,\theta)=p(\theta)p(X|\theta) =p(\theta)[ \theta^x (1-\theta)^{(1-x)}],x \in \{0,1\}\]</div>
<p><strong>先验分布</strong></p>
<p>变量 <span class="math notranslate nohighlight">\(X\)</span> 是伯努利分布，而伯努利分布的似然函数的共轭先验是 <em>Beta分布</em> ，
一般可记为 <span class="math notranslate nohighlight">\(\theta \sim Beta(\theta|a,b)\)</span> 。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-36">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-36" title="公式的永久链接"></a></span>\[p'(\theta;a,b)=\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{a-1}(1-\theta)^{b-1}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\Gamma(\cdot)\)</span> 称为Gamma函数，并有如下性质：</p>
<div class="math notranslate nohighlight" id="equation-eq-estimate-2">
<span class="eqno">()<a class="headerlink" href="#equation-eq-estimate-2" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\Gamma(x+1)=x\Gamma(x)\\\Gamma(n)=(n-1)! \, \text{n是整数}\end{aligned}\end{align} \]</div>
<p>Beta分布的期望和方差为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-37">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-37" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}E[\theta] = \frac{a}{a+b}\\var[\theta] = \frac{ab}{(a+b)^2(a+b+1)}\end{aligned}\end{align} \]</div>
<p>Beta分布是一个连续值的概率分布( <span class="math notranslate nohighlight">\(\theta \in [0,1]\)</span> 是连续值)，对于一个连续值的概率分布满足积分为1。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-38">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-38" title="公式的永久链接"></a></span>\[\int_{0}^1  \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{a-1}(1-\theta)^{b-1} d\theta = 1\]</div>
<p>这个先验分布中有两个参数a,b，一般情况我们会根据经验直接给定这两个参数的值，也就是其值已知的。
那么其中的Gama函数部分 <span class="math notranslate nohighlight">\(\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\)</span> 是一个常量。
积分符号内部的常量可以提到积分外面去，我们把这个积分等式做个变形，稍后会用到。</p>
<div class="math notranslate nohighlight" id="equation-eq-estimate-3">
<span class="eqno">()<a class="headerlink" href="#equation-eq-estimate-3" title="公式的永久链接"></a></span>\[\int_{0}^1   \theta^{a-1}(1-\theta)^{b-1} d\theta = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}\]</div>
<p><strong>后验分布</strong></p>
<p>有了先验分布后，我们把这个先验分布代入到后验分布中，由于a,b的值是确定的，所以先验分布中的Gamma函数部分
<span class="math notranslate nohighlight">\(\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\)</span> 是一个常数，与参数 <span class="math notranslate nohighlight">\(\theta\)</span> 无关，也与观测样本无关。
此外，我们用 <span class="math notranslate nohighlight">\(n_1\)</span> 表示观测样本中1的次数，用 <span class="math notranslate nohighlight">\(n_0\)</span> 表示观测样本中0出现的次数，
则有 <span class="math notranslate nohighlight">\(n_1+n_0=N\)</span> 。</p>
<div class="math notranslate nohighlight" id="equation-eq-estimate-4">
<span class="eqno">()<a class="headerlink" href="#equation-eq-estimate-4" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned} p(\theta|\mathcal{D})  &amp;=  \frac{p(\mathcal{D}|\theta) p'(\theta)}{p(D)}\\ &amp;=  \frac{L(\theta;\mathcal{D}) p'(\theta)}{p(D)}\\ &amp;= \frac{ \left [ \prod_{i=1}^N \theta^{x^{(i)}} (1-\theta)^{(1-{x^{(i)}})} \right ]  \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}  \theta^{a-1}(1-\theta)^{b-1}}{p(D)}\\ &amp;=  \frac{ \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \left [  \theta^{n_1} (1-\theta)^{n_0} \right ]   \theta^{a-1}(1-\theta)^{b-1}}{p(D)}\\ &amp;=  \frac{\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{n_1+a-1} (1-\theta)^{n_0+b-1}}{p(D)}\end{aligned}\end{align} \]</div>
<p>现在我们来看分母 <span class="math notranslate nohighlight">\(p(D)\)</span> ，我们知道分母其实是分子的归一化，由于 <span class="math notranslate nohighlight">\(\theta\)</span> 是连续值，所以分母其实就是分子的积分。
另外借助 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-estimate-2">公式(2.2.25)</a> 和 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-estimate-3">公式(2.2.28)</a> 可以进行简化。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-39">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-39" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(D) &amp;= \int_0^1 \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{n_1+a-1} (1-\theta)^{n_0+b-1} d\theta\\ &amp;=  \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \int_0^1  \theta^{n_1+a-1} (1-\theta)^{n_0+b-1} d\theta\\ &amp;= \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}  \frac{\Gamma(a+n_1)\Gamma(b+n_0)}{\Gamma(a+b+n_1+n_0)}\end{aligned}\end{align} \]</div>
<p>我们把分母代入到后验分布 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-estimate-4">公式(2.2.29)</a> ，可得：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-40">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-40" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(\theta|\mathcal{D}) &amp;= \frac{\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{n_1+a-1} (1-\theta)^{n_0+b-1}}{p(D)}\\&amp;=  \frac{\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{n_1+a-1} (1-\theta)^{n_0+b-1}}
  {\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}  \frac{\Gamma(a+n_1)\Gamma(b+n_0)}{\Gamma(a+b+n_1+n_0)}}\\
&amp;= \frac{\Gamma(a+b+n_1+n_0)}{\Gamma(a+n_1)\Gamma(b+n_0)} \theta^{n_1+a-1} (1-\theta)^{n_0+b-1}\end{aligned}\end{align} \]</div>
<p>发现没有，后验概率分布 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span> 也是一个Beta分布。
后验与先验具有相同的概率分布形式，这反映出先验关于似然函数共轭的性质。
<span class="math notranslate nohighlight">\(\theta\)</span> 的先验分布是 <span class="math notranslate nohighlight">\(Beta(\theta|a,b)\)</span> ，
后验分布是 <span class="math notranslate nohighlight">\(Beta(\theta|n_1+a,n_0+b)\)</span> ，
而且后验分布就是在先验分布的基础上加上的观测样本的一些统计值。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-41">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-41" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}a_{\text{后验}} &amp;= a_{\text{先验}} + n_1\\b_{\text{后验}} &amp;= b_{\text{先验}} + n_0\end{aligned}\end{align} \]</div>
<p>也就是说对于某些概率分布，如果我们选取共轭先验作为参数的先验分布，那么只需要对观测数据集进行一些统计，
就能直接给出参数的后验概率分布。</p>
<div class="admonition important">
<p class="admonition-title">重要</p>
<p>有了参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的后验概率分布 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span> ，
就相当于得到了参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的”估计值”，和最大似然估计不同的是，
最大似然估计得到的是点估计(参数一个数值估计)。
而贝叶斯估计是把参数看做一个随机变量，得到的是参数的后验概率分布，类似于区间估计。</p>
</div>
<p><strong>预测新样本</strong></p>
<p>有了参数的估计（后验概率分布）后，就相当于确定了变量 <span class="math notranslate nohighlight">\(X\)</span> 和 <span class="math notranslate nohighlight">\(\theta\)</span> 的联合概率分布
<span class="math notranslate nohighlight">\(p(X,\theta) \triangleq p(\theta|\mathcal{D}) p(X|\theta)\)</span> ，
通过对联合概率的边缘化得到变量 <span class="math notranslate nohighlight">\(X\)</span> 的边缘概率分布：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-42">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-42" title="公式的永久链接"></a></span>\[p(X) \triangleq  p(X|\mathcal{D}) = \int_0^1 p(\theta|\mathcal{D}) p(X|\theta) d\theta\]</div>
<p>利用 <span class="math notranslate nohighlight">\(p(X)\)</span> 我们可以预测新样本的概率:</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-43">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-43" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(X|\mathcal{D}) &amp;= \int_0^1 p(X|\theta) p(\theta|\mathcal{D})  d \theta\\&amp;= \int_0^1 \theta^x (1-\theta)^{(1-x)}  \frac{\Gamma(a+b+n_1+n_0)}{\Gamma(a+n_1)\Gamma(b+n_0)} \theta^{n_1+a-1} (1-\theta)^{n_0+b-1} d\theta\\&amp;=\frac{\Gamma(a+b+n_1+n_0)}{\Gamma(a+n_1)\Gamma(b+n_0)}  \int_0^1 \theta^x (1-\theta)^{(1-x)}   \theta^{n_1+a-1} (1-\theta)^{n_0+b-1} d\theta\\&amp;=\frac{\Gamma(a+b+n_1+n_0)}{\Gamma(a+n_1)\Gamma(b+n_0)}  \int_0^1 \theta^{n_1+a-1+x} (1-\theta)^{n_0+b-1+1-x} d\theta\\&amp;= \frac{\Gamma(a+b+n_1+n_0)}{\Gamma(a+n_1)\Gamma(b+n_0)} \frac{\Gamma(a+n_1+x)\Gamma(b+n_0+1-x)}{\Gamma(a+b+n_1+n_0+1)}\\&amp;= \frac{\Gamma(a+b+n_1+n_0)}{\Gamma(a+n_1)\Gamma(b+n_0)} \frac{\Gamma(a+n_1+x)\Gamma(b+n_0+1-x)}{ (a+b+n_1+n_0) \Gamma(a+b+n_1+n_0)}\\&amp;=  \frac{\Gamma(a+n_1+x)\Gamma(b+n_0+1-x)}{ (a+b+n_1+n_0){\Gamma(a+n_1)\Gamma(b+n_0)} }\end{aligned}\end{align} \]</div>
<p><span class="math notranslate nohighlight">\(x_{new}=1\)</span> 的概率为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-44">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-44" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(x_{new}=1|\mathcal{D}) &amp;=\frac{\Gamma(a+n_1+1)\Gamma(b+n_0+1-1)}{ (a+b+n_1+n_0){\Gamma(a+n_1)\Gamma(b+n_0)} }\\&amp;=\frac{\Gamma(a+n_1+1)}{ (a+b+n_1+n_0){\Gamma(a+n_1)} }\\&amp;=\frac{(a+n_1)\Gamma(a+n_1)}{ (a+b+n_1+n_0){\Gamma(a+n_1)} }\\&amp;=\frac{a+n_1}{ a+b+n_1+n_0 }\\&amp;= \frac{a+n_1}{ a+b+N }\end{aligned}\end{align} \]</div>
<p>我们发现用积分法去计算新样本的概率太复杂，实际上这个过程是可以简化的。
我们知道对概率分布求积分相当于其期望，所以我们可以求出参数的后验概率分布的期望值，
然后把期望值作为参数的一个点估计值，代入到变量 <span class="math notranslate nohighlight">\(X\)</span>
的条件概率中，通常称为 <strong>后验期望法(mean of the posterior)</strong> 。</p>
<p>参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的后验概率分布也是beta分布，其期望值可以直接给出：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-45">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-45" title="公式的永久链接"></a></span>\[\bar{\theta}= \mathbb{E}_{p(\theta|\mathcal{D})} [\theta] = \int_0^1 \theta p(\theta|\mathcal{D}) d \theta
= \frac{a+n_1}{a+b+n_1+n_0}\]</div>
<p>把参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的后验期望值作为参数的点估计值：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-46">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-46" title="公式的永久链接"></a></span>\[\hat{\theta}_{Bayes} =\bar{\theta} = \frac{a+n_1}{a+b+n_1+n_0}\]</div>
<p>把这个估计值直接带入到 <span class="math notranslate nohighlight">\(X\)</span> 的条件概率 <span class="math notranslate nohighlight">\(p(X|\theta)\)</span> 分布中，同样可以预测下一个样本的值。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-47">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-47" title="公式的永久链接"></a></span>\[p(x_{new}=1|\hat{\theta}_{Bayes} )
= \hat{\theta}_{Bayes} (1-\hat{\theta}_{Bayes})^{(1-1)}
= \hat{\theta}_{Bayes}
=  \frac{a+n_1}{a+b+n_1+n_0} =  \frac{a+n_1}{a+b+N}\]</div>
<p>我们发现这和上面通过积分法进行预测是等价，实际上
<span class="math notranslate nohighlight">\(\int_0^1 p(x|\theta) p(\theta|\mathcal{D})  d \theta\)</span> 就相当于在求期望。</p>
<p>最后，回顾一下伯努利分布的极大似然估计的结果 <span class="math notranslate nohighlight">\(\hat{\theta}_{ML}=\frac{n_1}{N}\)</span> ，
和贝叶斯估计的结果对比一下，发现贝叶斯估计的结果就是在极大似然估计的基础上加入了先验知识，
<em>加入先验类似于似然函数加上惩罚项，可以起到防止过拟合的效果。</em></p>
</section>
<section id="id9">
<h3>类别分布<a class="headerlink" href="#id9" title="永久链接至标题"></a></h3>
<p>假设随机变量 <span class="math notranslate nohighlight">\(X\)</span> 是一个以 <span class="math notranslate nohighlight">\(\theta\)</span> 为参数变量的类别分布，
其概率分布函数可以写成如下条件概率分布。</p>
<div class="math notranslate nohighlight" id="equation-eq-cat-distribution-2">
<span class="eqno">()<a class="headerlink" href="#equation-eq-cat-distribution-2" title="公式的永久链接"></a></span>\[p(X|\theta) = \prod_{m=1}^{M} \theta_m^{\delta (x,x_m) }\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\delta (x,x_m)\)</span> 是一个指示函数，当 <span class="math notranslate nohighlight">\(x=x_m\)</span> 时，
<span class="math notranslate nohighlight">\(\delta (x,x_m)=1\)</span> ；反之， <span class="math notranslate nohighlight">\(\delta (x,x_m)=0\)</span>
。<span class="math notranslate nohighlight">\(\theta\)</span> 表示参数向量，这里 <span class="math notranslate nohighlight">\(\theta\)</span> 不再是一个标量，而是一个向量。
参数变量 <span class="math notranslate nohighlight">\(\theta\)</span> 的概率分布是 <span class="math notranslate nohighlight">\(p(\theta)\)</span> ，
随机变量 <span class="math notranslate nohighlight">\(X\)</span> 和 <span class="math notranslate nohighlight">\(\theta\)</span> 组成联合概率分布
<span class="math notranslate nohighlight">\(p(X,\theta)\)</span> 。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-48">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-48" title="公式的永久链接"></a></span>\[p(X,\theta) = p(\theta)p(X|\theta)\]</div>
<p>观测变量 <span class="math notranslate nohighlight">\(X\)</span> 的边缘概率分布 <span class="math notranslate nohighlight">\(p(X)\)</span> 需要通过边际化的方法得到：</p>
<div class="math notranslate nohighlight" id="equation-fm-20-0010">
<span class="eqno">()<a class="headerlink" href="#equation-fm-20-0010" title="公式的永久链接"></a></span>\[p(X) = \int p(X,\theta) d \theta =
\int p(\theta) p(X|\theta) d \theta\]</div>
<p><strong>先验分布</strong></p>
<p>类别分布的共轭先验是狄利克雷(Dirichlet)分布，
所以这里我们选取狄利克雷分布作为参数变量 <span class="math notranslate nohighlight">\(\theta\)</span> 的先验分布。</p>
<div class="math notranslate nohighlight" id="equation-eq-prior-dirichlet">
<span class="eqno">()<a class="headerlink" href="#equation-eq-prior-dirichlet" title="公式的永久链接"></a></span>\[\theta \sim Dirichlet(\alpha_1,\dots,\alpha_M)\]</div>
<p>狄利克雷分布的概率函数为：</p>
<div class="math notranslate nohighlight" id="equation-20-prior">
<span class="eqno">()<a class="headerlink" href="#equation-20-prior" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p'(\theta;\alpha) &amp;= \frac{\Gamma(\sum_m \alpha_m)}{\prod_m \Gamma(\alpha_m)} \prod_{m=1}^M \theta_m^{\alpha_m -1 }\\ &amp; \propto \prod_{m=1}^M \theta_m^{\alpha_m - 1}\end{aligned}\end{align} \]</div>
<p>其中 <span class="math notranslate nohighlight">\(\alpha\)</span> 是狄利克雷分布的参数，可以使用经验值，这里看做是已知量。
狄利克雷分布是一个 <em>多元连续变量</em> 的分布，一个概率分布同时输出多个子变量 <span class="math notranslate nohighlight">\(\theta_m(1\le m \le M)\)</span> 的概率值，
并满足约束 <span class="math notranslate nohighlight">\(\sum_m \theta_m = 1\)</span> 。
狄利克雷分布每一个子变量 <span class="math notranslate nohighlight">\(\theta_m\)</span> 的期望值是：</p>
<div class="math notranslate nohighlight" id="equation-eq-dirichlet-expert">
<span class="eqno">()<a class="headerlink" href="#equation-eq-dirichlet-expert" title="公式的永久链接"></a></span>\[\mathbb{E}[\theta_m] = \frac{\alpha_m}{\sum_{m=1}^M \alpha_m}\]</div>
<p>狄利克雷分布是连续值分布，所以满足积分为1的约束。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-49">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-49" title="公式的永久链接"></a></span>\[\int \frac{\Gamma(\sum_m \alpha_m)}{\prod_m \Gamma(\alpha_m)}
\prod_{m=1}^M \theta_m^{\alpha_m -1 } d \theta=
\frac{\Gamma(\sum_m \alpha_m)}{\prod_m \Gamma(\alpha_m)}
\int \prod_{m=1}^M \theta_m^{\alpha_m -1 } d \theta = 1\]</div>
<p>我们把这个积分式稍微变换一下，稍后会使用到。</p>
<div class="math notranslate nohighlight" id="equation-20-integrated-change">
<span class="eqno">()<a class="headerlink" href="#equation-20-integrated-change" title="公式的永久链接"></a></span>\[\int \prod_{m=1}^M \theta_m^{\alpha_m -1 } d \theta = \frac{\prod_m \Gamma(\alpha_m)}{\Gamma(\sum_m \alpha_m)}\]</div>
<p><strong>后验分布</strong></p>
<p>根据贝叶斯公式，可以写出参数变量 <span class="math notranslate nohighlight">\(\theta\)</span> 的后验概率分布：</p>
<div class="math notranslate nohighlight" id="equation-20-posterior-distribution">
<span class="eqno">()<a class="headerlink" href="#equation-20-posterior-distribution" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(\theta|\mathcal{D}) &amp;=
\frac{p'(\theta)p(\mathcal{D}|\theta)}{p(\mathcal{D})}\\&amp;= \frac{ p'(\theta) L(\mathcal{D};\theta)}{p(\mathcal{D})}\\
&amp;= \frac{ \frac{\Gamma(\sum_m \alpha_m)}{\prod_m \Gamma(\alpha_m)}
\prod_{m=1}^M \theta_m^{\alpha_m -1 }  \prod_{m=1}^M \theta_m^{n_m}  }  {p(\mathcal{D})}\\&amp;= \frac{ \frac{\Gamma(\sum_m \alpha_m)}{\prod_m \Gamma(\alpha_m)}
\prod_{m=1}^M \theta_m^{n_m+\alpha_m -1 } }{p(\mathcal{D})}\end{aligned}\end{align} \]</div>
<p>我们再看分母部分 <span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span> ，分母是对分子的归一化，
由于这里 <span class="math notranslate nohighlight">\(\theta\)</span> 是连续值变量，所以分母是对分子的积分。
也可以理解成是对联合概率分布 <span class="math notranslate nohighlight">\(p(\mathcal{D},\theta)\)</span>
进行边际化求得边缘概率 <span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span> 。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-50">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-50" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(\mathcal{D}) &amp;= \int p(\mathcal{D},\theta) d \theta\\&amp;= \int p'(\theta)p(\mathcal{D}|\theta) d \theta\\&amp;= \int \frac{\Gamma(\sum_m \alpha_m)}{\prod_m \Gamma(\alpha_m)}
\prod_{m=1}^M \theta_m^{\alpha_m -1 }  \prod_{m=1}^M \theta_m^{n_m } d \theta\\&amp;= \int \frac{\Gamma(\sum_m \alpha_m)}{\prod_m \Gamma(\alpha_m)}
\prod_{m=1}^M \theta_m^{n_m+\alpha_m -1 } d \theta\\&amp;= \frac{\Gamma(\sum_m \alpha_m)}{\prod_m \Gamma(\alpha_m)}
 \int  \prod_{m=1}^M \theta_m^{n_m+\alpha_m -1 } d \theta\end{aligned}\end{align} \]</div>
<p>参考一下积分变换 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-20-integrated-change">公式(2.2.46)</a> ，其中的积分部分可以改写一下得到 <span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span> 。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-51">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-51" title="公式的永久链接"></a></span>\[p(\mathcal{D})  = \frac{\Gamma(\sum_m \alpha_m)}{\prod_m \Gamma(\alpha_m)}
\frac{\prod_m \Gamma(n_m+ \alpha_m)}{\Gamma(\sum_m n_m + \alpha_m)}\]</div>
<p>我们把这个代入回后验概率分布 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-20-posterior-distribution">公式(2.2.47)</a> 的分母部分。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-52">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-52" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(\theta|\mathcal{D})
&amp;= \frac{ \frac{\Gamma(\sum_m \alpha_m)}{\prod_m \Gamma(\alpha_m)} \prod_{m=1}^M \theta_m^{n_m+\alpha_m -1 } }
{p(\mathcal{D})}\\&amp;= \frac{ \frac{\Gamma(\sum_m \alpha_m)}{\prod_m \Gamma(\alpha_m)} \prod_{m=1}^M \theta_m^{n_m+\alpha_m -1 } }
{  \frac{\Gamma(\sum_m \alpha_m)}{\prod_m \Gamma(\alpha_m)}   \frac{\prod_m \Gamma(n_m+ \alpha_m)}{\Gamma(\sum_m n_m + \alpha_m)}   }\\
&amp;=  \frac{\Gamma(\sum_m n_m + \alpha_m)}{\prod_m \Gamma(n_m+ \alpha_m)} \prod_{m=1}^M \theta_m^{n_m+\alpha_m -1 }\end{aligned}\end{align} \]</div>
<p>我们看到后验概率分布仍然是一个狄利克雷分布，
类别分布的参数进行贝叶斯估计时，参数的共轭先验是狄利克雷分布，得到的参数后验概率分布也是狄利克雷分布。</p>
<div class="math notranslate nohighlight" id="equation-eq-posterior-dirichlet">
<span class="eqno">()<a class="headerlink" href="#equation-eq-posterior-dirichlet" title="公式的永久链接"></a></span>\[\theta|\mathcal{D} \sim Dirichlet(\alpha_1+n_1,\dots,
\alpha_M+n_m)\]</div>
<p><strong>预测新样本</strong></p>
<p>根据观测集 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 得到参数变量 <span class="math notranslate nohighlight">\(\theta\)</span> 的后验概率分布 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span>
，然后假设 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span> 是参数  <span class="math notranslate nohighlight">\(\theta\)</span> 的真实概率分布，
通过对联合概率分布 <span class="math notranslate nohighlight">\(p(X,\theta)\)</span> 边缘化的方式得到类别变量X的边缘概率分布 <span class="math notranslate nohighlight">\(p(X)\)</span>
，最后利用 <span class="math notranslate nohighlight">\(p(X)\)</span> 预测变量 <span class="math notranslate nohighlight">\(X\)</span> 的值。
在推导 <span class="math notranslate nohighlight">\(p(X)\)</span> 的过程中需要利用几个性质：</p>
<ul class="simple">
<li><p>积分变换 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-20-integrated-change">公式(2.2.46)</a>，</p></li>
<li><p>Gamma函数的性质： <span class="math notranslate nohighlight">\(\Gamma(x+1)=x\Gamma(x)\)</span> 。</p></li>
<li><p><span class="math notranslate nohighlight">\(n_m\)</span> 表示类别 <span class="math notranslate nohighlight">\(x_m\)</span> 在观测样本集 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 中出现的次数，<span class="math notranslate nohighlight">\(N=\sum_m n_m\)</span> 。</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-eq-bayies-cat-new">
<span class="eqno">()<a class="headerlink" href="#equation-eq-bayies-cat-new" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(X)
&amp;= \int p(X,\theta) d \theta\\&amp;= \int p(\theta)p(X|\theta) d \theta\\&amp;\triangleq  \int \underbrace{p(\theta|\mathcal{D})}_{\text{后验概率分布}}
\underbrace{p(X | \theta)}_{\text{类别分布}}   d \theta\\&amp;= \int \left [
    \frac{\Gamma(\sum_m n_m + \alpha_m)}{\prod_m \Gamma(n_m+ \alpha_m)} \prod_{m=1}^M \theta_m^{n_m+\alpha_m -1 }
    \right ]
\left [
 \prod_{m=1}^{M} \theta_m^{\delta (x,x_m) }
\right ] d\theta\\&amp; =  \frac{\Gamma(\sum_m n_m + \alpha_m)}{\prod_m \Gamma(n_m+ \alpha_m)}
\int \prod_{m=1}^M \theta_m^{n_m+\alpha_m -1 } \prod_{m=1}^{M} \theta_m^{\delta (x,x_m) }   d \theta\\
&amp;=\frac{\Gamma(\sum_m n_m + \alpha_m)}{\prod_m \Gamma(n_m+ \alpha_m)}
\int  \prod_{m=1}^M \theta_m^{n_m + \alpha_m + \delta (x,x_m)  - 1 }  d \theta\\
&amp;= \frac{\Gamma(\sum_m n_m + \alpha_m)}{\prod_m \Gamma(n_m+ \alpha_m)}
\frac{\prod_m \Gamma(n_m+ \alpha_m+\delta (x,x_m) )}{\Gamma(\sum_m (n_m + \alpha_m+ \delta (x,x_m)))}
 \ \ (\text{利用积分变换公式去掉积分})\end{aligned}\end{align} \]</div>
<p>只有当 <span class="math notranslate nohighlight">\(x=x_m\)</span> 时，指示函数 <span class="math notranslate nohighlight">\(\delta(x,x_m)\)</span> 等于1，否则等于0，因此下面连乘可以分解化简。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-53">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-53" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\prod_m \Gamma(n_m+ \alpha_m+ \delta(x,x_m) )
&amp;=  \underbrace{\Gamma(n_m+ \alpha_m + 1 )}_{\text{把} x = x_m \text{的项分出来}}
    \prod_{\mathbb{m} \in M, \mathbb{m} \neq m } \Gamma(n_\mathbb{m}+ \alpha_\mathbb{m})\\&amp;= (n_m+ \alpha_m)  \Gamma(n_m+ \alpha_m)  \prod_{\mathbb{m} \in M,\mathbb{m} \neq m} \Gamma(n_\mathbb{m}+ \alpha_\mathbb{m})\\&amp;=(n_m+ \alpha_m) \prod_m \Gamma(n_m+ \alpha_m)\end{aligned}\end{align} \]</div>
<p>继续化简 <a class="reference internal" href="#equation-eq-bayies-cat-new">公式()</a> ：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-54">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-54" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(X)
&amp;= \frac{\Gamma(\sum_m n_m + \alpha_m)}{\prod_m \Gamma(n_m+ \alpha_m)}
\frac{(n_m+ \alpha_m) \prod_m \Gamma(n_m+ \alpha_m) }{\Gamma(  \sum_m (n_m + \alpha_m) + \sum_m \delta (x,x_m) ))}\\
&amp;= \frac{(n_m+\alpha_m) \Gamma(\sum_m n_m + \alpha_m)}{\Gamma(\sum_m (n_m + \alpha_m)+ 1 ))}\\&amp;= \frac{(n_m+\alpha_m) \Gamma(\sum_m n_m + \alpha_m)  }{\sum_m (n_m + \alpha_m) \Gamma(\sum_m n_m + \alpha_m)}\\&amp;= \frac{(n_m+\alpha_m)   }{\sum_m (n_m + \alpha_m) }\\
&amp;= \frac{\alpha_m +n_m } {N + \sum_{m=1}^M \alpha_m  }\end{aligned}\end{align} \]</div>
<p>最终我们得到了变量 <span class="math notranslate nohighlight">\(X\)</span> 的边缘概率分布，可以看到最后的公式中没有参数 <span class="math notranslate nohighlight">\(\theta\)</span>
，因为已经通过积分消除掉了参数变量 <span class="math notranslate nohighlight">\(\theta\)</span> 。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-55">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-55" title="公式的永久链接"></a></span>\[p(x_m) = \frac{\alpha_m +n_m } {N + \sum_{m=1}^M \alpha_m  }\]</div>
<p>这种通过积分边缘化的方法，推导过程是复杂的。
我们可以使用变量参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的后验分布的期望值作为参数的估计值，然后把估计值代入到观测变量
<span class="math notranslate nohighlight">\(X\)</span> 的条件概率分布 <span class="math notranslate nohighlight">\(p(X|\theta)\)</span> 中。
参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的后验概率分布 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span>
是一个狄利克雷分布，参考 <a class="reference internal" href="#equation-eq-dirichlet-expert">公式()</a> 和 <a class="reference internal" href="#equation-eq-posterior-dirichlet">公式()</a>
，可以直接写出参数 <span class="math notranslate nohighlight">\(\theta\)</span> 后验分布期望值。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-56">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-56" title="公式的永久链接"></a></span>\[\hat{\theta}_{m}=\mathbb{E}_{p(\theta_{m}|\mathcal{D})}[\theta_m]
=\frac{\alpha_m +n_m } {N + \sum_{m=1}^M \alpha_m  } = p(x_m)\]</div>
<p>贝叶斯估计计算后验概率分布的过程是困难的，需要在整个参数空间求和或者求积分，这在通常情况下是非常困难的(采用共轭先验会简化)，
然后在做预测或者模型比较时又要再次积分(求期望需要积分)。
此外，当数据集规模较小时，贝叶斯估计的结果接近先验分布，当数据集足够大时，贝叶斯估计的结果就会逐渐偏离先验，等价于极大似然估计的结果。
当数据集规模趋近于无穷时，贝叶斯估计的结果和极大似然的结果是一致的。
<strong>在实际应用中，贝叶斯估计先验的选择通常是为了计算方便(共轭先验)而不是为了反映出任何真实的先验知识，</strong>
<strong>然而当先验选择不好的时候，贝叶斯方法有很大可能得到错误的结果。</strong></p>
</section>
</section>
<section id="id10">
<h2>最大后验估计<a class="headerlink" href="#id10" title="永久链接至标题"></a></h2>
<p>贝叶斯估计有个很大的难点就是计算 <span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span>
，计算 <span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span> 需要对参数空间进行积分，
而积分操作的成本很多时候是非常高昂的，甚至都无法计算。
如果我们仅仅是为了预测 <span class="math notranslate nohighlight">\(X\)</span> 的新样本，而不需要对参数变量本身进行过多的探索，
那么我们不需要得到完整的后验分布，而是只得到参数的一个点估计即可，类似于似然估计。</p>
<p>贝叶斯估计是通过计算参数后验概率分布的期望值作为参数的估计值，
而计算期望值就需要完整的计算出概率分布。
然而除了期望值，我们还可以用后验概率分布最大概率的参数值作为参数的估计值，
称之为最大后验估计(Maximum a posteriori estimation,MAP)。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-57">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-57" title="公式的永久链接"></a></span>\[\hat{\theta}_{MAP}  = \mathop{\arg \max}_{\theta} p(\theta|\mathcal{D})\]</div>
<p>回顾一下公式 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-12">公式(2.2.20)</a>
，后验概率的分母 <span class="math notranslate nohighlight">\(p(\mathcal{D})\)</span> 是一个定值，
后验概率是正比于先验乘以似然的。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-58">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-58" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\text{后验概率} &amp;= \frac{\text{似然} \times  \text{先验}}{evidence}\\&amp; \propto \text{似然} \times  \text{先验}\end{aligned}\end{align} \]</div>
<p>在进行最大后验估计时，其实并不需要先计算出后验概率分布 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span> 的具体形式，
因为后验概率是正比于分子的 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D}) \propto L(\theta;\mathcal{D}) p(\theta)\)</span>
，所以极大化求解后验概率分布时，只需要极大化后验分布的分子即可。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-59">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-59" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\hat{\theta}_{MAP}  &amp;= \mathop{\arg \max}_{\theta} p(\theta|\mathcal{D})\\&amp;\triangleq \mathop{\arg \max}_{\theta} \text{似然} \times  \text{先验}\\&amp;= \mathop{\arg \max}_{\theta} L(\theta;\mathcal{D}) p(\theta)\\&amp;\triangleq \mathop{\arg \max}_{\theta} \log   L(\theta;\mathcal{D}) p(\theta)\\&amp;= \mathop{\arg \max}_{\theta} \underbrace{\log L(\theta;\mathcal{D})}_{\text{对数似然}} +
\underbrace{\log p(\theta)}_{\text{对数先验}}\end{aligned}\end{align} \]</div>
<p>发现没有， <strong>最大后验估计就是在极大似然估计的基础上多了一个参数的先验！！！</strong>
所以最大后验估计很多方面是和极大似然估计类似的，但由于多了先验和极大似然估计又有些不同。</p>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>其实最大后验估计加的先验和损失函数加正则项是等价的。对参数引入拉普拉斯先验等价于L1正则化，高斯先验相当于L2正则。
PS:如果你不知道什么是损失函数、正则项，没关系可以暂时无视这句话，以后就会懂的。</p>
</div>
<section id="id11">
<h3>伯努利变量<a class="headerlink" href="#id11" title="永久链接至标题"></a></h3>
<p>我们截取 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-estimate-4">公式(2.2.29)</a> 的分子部分</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-60">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-60" title="公式的永久链接"></a></span>\[p(\theta|\mathcal{D}) \propto
 \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{n_1+a-1} (1-\theta)^{n_0+b-1}\]</div>
<p>最大后验估计的结果为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-61">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-61" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\hat{\theta}_{MAP}  &amp;= \mathop{\arg \max}_{\theta} p(\theta|\mathcal{D})\\&amp;\triangleq \mathop{\arg \max}_{\theta}  \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{n_1+a-1} (1-\theta)^{n_0+b-1}\end{aligned}\end{align} \]</div>
<p>我们通过目标函数加对数，并且令导数为0的方法进行求解。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-62">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-62" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\frac{ \partial}{\partial \theta} \log J(\theta)
 &amp;= \frac{ \partial}{\partial \theta} \log \frac{\Gamma(a+b+n_1+n_0)}{\Gamma(a+n_1)\Gamma(b+n_0)} \theta^{n_1+a-1} (1-\theta)^{n_0+b-1}\\ &amp;= \frac{ \partial}{\partial \theta} \log \frac{\Gamma(a+b+n_1+n_0)}{\Gamma(a+n_1)\Gamma(b+n_0)}
 + \frac{ \partial}{\partial \theta} \log \theta^{n_1+a-1}
 + \frac{ \partial}{\partial \theta} \log (1-\theta)^{n_0+b-1}\\ &amp;= \frac{ \partial}{\partial \theta} (n_1+a-1) \log \theta + \frac{ \partial}{\partial \theta} (n_0+b-1) \log (1-\theta)\\ &amp;= \frac{(n_1+a-1)}{\theta} - \frac{ (n_0+b-1)}{1-\theta}\\ &amp;= 0\end{aligned}\end{align} \]</div>
<p>解得：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-63">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-63" title="公式的永久链接"></a></span>\[\hat{\theta}_{MAP} = \frac{n_1+a-1}{n_1+n_0+a+b-2} = \frac{n_1+a-1}{N+a+b-2}\]</div>
</section>
<section id="id12">
<h3>类别变量<a class="headerlink" href="#id12" title="永久链接至标题"></a></h3>
<p>同理，我们截取 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-20-posterior-distribution">公式(2.2.47)</a> 的分子部分作为极大化的目标函数。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-64">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-64" title="公式的永久链接"></a></span>\[\hat{\theta}_{MAP} = \mathop{\arg \max}_{\theta}
 \frac{\Gamma(\sum_m \alpha_m)}{\prod_m \Gamma(\alpha_m)}
 \prod_{m=1}^M \theta_m^{n_m+\alpha_m -1 }\]</div>
<p>同理加对数，求偏导，然后令偏导数为0，可解得：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-65">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-65" title="公式的永久链接"></a></span>\[\hat{\theta}_{m} = \frac{\alpha_m +n_m - 1}{\sum_m \alpha_m +N - M}\]</div>
<p>与最大似然估计的结果进行对比，
MAP估计结果考虑了训练样本的数量。特别是，当N很小时，MAP值接近先验的结果;当N很大时，MAP值接近经验分布。
从这个意义上讲，MAP估计可以看作是通过惩罚更复杂的模型来控制过度拟合，即那些离先验更远的模型。</p>
</section>
</section>
<section id="id13">
<h2>最大似然估计与贝叶斯估计的对比<a class="headerlink" href="#id13" title="永久链接至标题"></a></h2>
<p>在概率论一直存在着两者学派，一个是频率学派，一个是贝叶斯学派。
这里我们不讨论这两个学派的本质差别，只关注它们在参数估计上的差别。
通常我们用概率分布(probability distribution)去描述一个随机变量，
我们会说一个随机变量会服从于什么概率分布，比如一个随机变量 <span class="math notranslate nohighlight">\(X\)</span>
服从于伯努利分布。而一个概率分布都包含一个或多个参数，只有当参数的值确定时才能唯一确定一个分布。
当一个概率分布的参数值未知时，我们需要找到它来确定这个概率分布，然后利用这个概率分布去做一些有价值的事情。
频率学派和贝叶斯学派在参数的认知上存在着很大差异。</p>
<p>频率学派认为概率分布中的参数值就仅仅是一个数值，所以用参数化的方法定义概率分布 <span class="math notranslate nohighlight">\(p(X;\theta)\)</span>
，并且他们认为参数空间中只有一个值是最优的(或者说是真理)，需要做的就是想办法找到它。
因此在这个基础上提出了最大似然估计法，目标是找出那个最优的参数值。
当然要想估计出参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的值，我们需要有随机变量 <span class="math notranslate nohighlight">\(X\)</span> 的一些观测样本，
我们通过这些样本去估计这个概率分布的未知参数。这些样本都是同一个概率分布  <span class="math notranslate nohighlight">\(p(X;\theta)\)</span> 的样本，所以它们是同分布的，
而且样本与样本之间通常没有什么关系，所以观测样本集都是满足IID(独立同步分布)的。
我们用符号 <span class="math notranslate nohighlight">\(\mathcal{D}=\{x_1,x_2,\cdots,x_N \}\)</span> 表示这个样本集，
其中每一条样本的发生概率是 <span class="math notranslate nohighlight">\(p(x_i;\theta)\)</span> ，那么所有样本都发生的概率是一个联合概率：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-66">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-66" title="公式的永久链接"></a></span>\[p(\mathcal{D};\theta) = p(x_1,x_2,\cdots,x_N ;\theta)
= \prod_{i=1}^N p(x_i;\theta)\]</div>
<p><span class="math notranslate nohighlight">\(p(\mathcal{D};\theta)\)</span> 通常被称为 <em>似然函数(likelihood function)</em> ，习惯上我们用符号
<span class="math notranslate nohighlight">\(L(\theta;\mathcal{D})\)</span> 表示似然函数。
最大似然估计的思想就是：使得这个样本集发生的联合概率(似然函数)最大的那个参数值是最优的。所以最大似然的估计值为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-67">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-67" title="公式的永久链接"></a></span>\[\hat{\theta}_{ML} = \mathop{\arg \max}_{\theta} p(\mathcal{D};\theta)
= \mathop{\arg \max}_{\theta} L(\theta;\mathcal{D})\]</div>
<p>有了参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的估计值，就确定了变量 <span class="math notranslate nohighlight">\(X\)</span> 的概率分布 <span class="math notranslate nohighlight">\(p(X;\hat{\theta}_{ML})\)</span>
，然后就可以预测新的样本。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-68">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-68" title="公式的永久链接"></a></span>\[p(X=x_{new}) = p(X=x_{new};\hat{\theta}_{ML})\]</div>
<p>然而贝叶斯学派的观点却恰恰相反，他们认为未知参数既然是未知，那么这个参数取值为参数空间中任意一个值都是有可能的，
所以参数本身也是一个随机变量，也需要用一个概率分布去描述(贝叶斯派的核心一切未知的变量都是随机变量)，
因此他们把带参数的概率分布定义成一个 <strong>条件概率</strong>
<span class="math notranslate nohighlight">\(p(X|\theta)\)</span> （注意这里和频率派有了本质差别）。
同时，他们利用贝叶斯定理把随机变量 <span class="math notranslate nohighlight">\(X\)</span> 和参数变量 <span class="math notranslate nohighlight">\(\theta\)</span> 两者之间的关系变成”可逆”的。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-69">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-69" title="公式的永久链接"></a></span>\[p(\theta|X) = \frac{p(X|\theta)p(\theta)}{p(X)}\]</div>
<p>通过贝叶斯定理我们把变量 <span class="math notranslate nohighlight">\(X\)</span> 和参数变量 <span class="math notranslate nohighlight">\(\theta\)</span> 的关系定义出来了，
公式中的 <span class="math notranslate nohighlight">\(p(\theta)\)</span> 表示参数变量 <span class="math notranslate nohighlight">\(\theta\)</span> 的边缘概率分布，
是在随机变量 <span class="math notranslate nohighlight">\(X\)</span> 发生之前 <span class="math notranslate nohighlight">\(\theta\)</span> 的概率分布，
所以我们称之为 <span class="math notranslate nohighlight">\(\theta\)</span> 的先验分布(prior distribution)。
但实际上我们并不知道参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的真实概率分布是什么，
所以通常我们会为其假设一个概率分布。
我们假设 <span class="math notranslate nohighlight">\(\theta\)</span> 的先验概率分布为某一个已知的分布，
然后在这个先验分布 <span class="math notranslate nohighlight">\(p(\theta)\)</span> 以及条件概率分布 <span class="math notranslate nohighlight">\(p(X|\theta)\)</span> 情况下，
观测到了变量 <span class="math notranslate nohighlight">\(X\)</span> 的一些样本 <span class="math notranslate nohighlight">\(\mathcal{D}=\{x_1,x_2,\cdots,x_N \}\)</span> ，
这个样本集中的所有样本都是从联合概率 <span class="math notranslate nohighlight">\(p(X,\theta)=p(X|\theta)p(\theta)\)</span>
中采样得到的，
现在我们希望能从这个样本集中反推出 <span class="math notranslate nohighlight">\(\theta\)</span> 的真实概率分布。
也就是在观测样本集的条件下 <span class="math notranslate nohighlight">\(\theta\)</span> 的概率分布，这些样本都是随机变量 <span class="math notranslate nohighlight">\(X\)</span> 的采样，
可以把每个样本点都看成随机变量 <span class="math notranslate nohighlight">\(X\)</span> 的一个副本，
所以有 <span class="math notranslate nohighlight">\(p(\theta|X)\Rightarrow p(\theta|x_1,x_2,\cdots,x_N)= p(\theta|\mathcal{D})\)</span> 。</p>
<div class="math notranslate nohighlight" id="equation-eq-2-20">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-20" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(\theta|\mathcal{D}) &amp;= \frac{p(\mathcal{D}|\theta)p(\theta)}{p(\mathcal{D})}\\&amp;=\frac{p(\theta) \prod_{i=1}^N p(x_i|\theta)}{p(x_1,x_2,\cdots,x_N)}\end{aligned}\end{align} \]</div>
<p>条件概率分布 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span> 称为参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的
<em>后验概率分布(posterior distribution)</em> ，
因为是在观测样本的条件下 <span class="math notranslate nohighlight">\(\theta\)</span> 的概率分布，所以称为后验。
后验概率分布是我们在样本集的基础上对参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的估计分布，
我们把后验概率分布 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span>
作为参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的估计。</p>
<p>有了参数的估计分布后，我们就可以用来预测新的样本。在贝叶斯理论的前提下，随机变量 <span class="math notranslate nohighlight">\(X\)</span> 的样本是由
联合概率 <span class="math notranslate nohighlight">\(p(X,\theta)=p(\theta)p(X|\theta)\)</span> 产生的，其中 <span class="math notranslate nohighlight">\(\theta\)</span>
的概率分布我们用估计的后验概率分布替换，所以新的样本的预测分布为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-70">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-70" title="公式的永久链接"></a></span>\[p(X=x_{new}) = \int p(\theta|D)p(X=x_{new}|\theta) d \theta\]</div>
<p>这个方式其实等价于把 <span class="math notranslate nohighlight">\(\theta\)</span> 的期望值 <span class="math notranslate nohighlight">\(\hat{\theta}_{E}\)</span> 作为估计值，然后把估计值代入条件概率
<span class="math notranslate nohighlight">\(p(X|\theta)\)</span> 进行预测。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-71">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-71" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\hat{\theta}_{E} = \mathbb{E}_{p(\theta|\mathcal{D})}[\theta]
=\int \theta p(\theta|\mathcal{D}) d \theta\\
p(X=x_{new}) = p(X=x_{new}|\theta=\hat{\theta}_{E})\end{aligned}\end{align} \]</div>
<p>后验概率的期望值通常被称为参数的贝叶斯估计(Bayes estimate)：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-72">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-72" title="公式的永久链接"></a></span>\[\hat{\theta}_{Bayes} = \mathbb{E}_{p(\theta|\mathcal{D})}[\theta]\]</div>
<p>然而，并不是所有情况下都能求出后验概率分布的期望值的，
要想求得后验概率分布的期望值，就需要求出后验概率分布 <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span> 的具体形式，
后验概率分布 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-20">公式(2.4.12)</a> 中的分母是对分子的积分，很多时候这个积分的计算复杂度是很高的，以至于无法计算出来。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-73">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-73" title="公式的永久链接"></a></span>\[p(\mathcal{D}) = \int  p(\mathcal{D}|\theta)p(\theta) d\theta\]</div>
<p>因此有时候我们是无法得到后验概率分布的期望的。而且就算我们得到了后验概率分布的具体形式，
要计算后验概率分布的期望有需要对后验概率分布进行积分，这在很多时候也是无法达成的。
所以贝叶斯推断中还有另外一种参数估计方法，<em>最大后验估计(maximum a posterior)</em> ：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-74">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-74" title="公式的永久链接"></a></span>\[\hat{\theta}_{MAP} = \mathop{\arg \max}_{\theta} p(\theta|\mathcal{D})\]</div>
<p>最大后验估计的思想是令后验概率中概率最大的那个值作为参数的估计值，而不是期望值。
我们发现后验概率  <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-20">公式(2.4.12)</a> 是正比于分子部分的。</p>
<div class="math notranslate nohighlight" id="equation-eq-2-21">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-21" title="公式的永久链接"></a></span>\[p(\theta|\mathcal{D}) \propto p(\mathcal{D}|\theta)p(\theta)\]</div>
<p>我们只需要通过极大化分子就能得到 <span class="math notranslate nohighlight">\(\theta\)</span> 的最大后验估计值 <span class="math notranslate nohighlight">\(\hat{\theta}_{MAP}\)</span> ，
所以我们不需要计算积分。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-75">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-75" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\hat{\theta}_{MAP} &amp;= \mathop{\arg \max}_{\theta} p(\theta|\mathcal{D})\\&amp;\triangleq \mathop{\arg \max}_{\theta} p(\mathcal{D}|\theta)p(\theta)\end{aligned}\end{align} \]</div>
<p>我们用 <span class="math notranslate nohighlight">\(\hat{\theta}_{MAP}\)</span> 作为参数的一个具体估计值，然后用于预测新的样本。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-76">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-76" title="公式的永久链接"></a></span>\[p(X=x_{new}) = p(X=x_{new}|\theta=\hat{\theta}_{MAP})\]</div>
<p>此外，我们发现其中的 <span class="math notranslate nohighlight">\(p(\mathcal{D}|\theta)\)</span>
和似然函数 <span class="math notranslate nohighlight">\(L(\theta;\mathcal{D})=p(\mathcal{D}|\theta)\)</span> 是等价的，
<a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-21">公式(2.4.18)</a> 可以表示成：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-77">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-77" title="公式的永久链接"></a></span>\[\text{后验概率(posterior)} \propto \text{似然(likelihood)} \times \text{先验(prior)}\]</div>
<p>最大后验估计相当于一个带惩罚(约束)的最大似然估计。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-78">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-78" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\hat{\theta}_{MAP} &amp;= \mathop{\arg \max}_{\theta} p(\mathcal{D}|\theta)p(\theta)\\&amp;= \mathop{\arg \max}_{\theta} \{ \log p(\mathcal{D}|\theta) + \log p(\theta) \}\end{aligned}\end{align} \]</div>
</section>
<section id="id14">
<h2>统计量和充分统计量<a class="headerlink" href="#id14" title="永久链接至标题"></a></h2>
<p>在本节中，我们讨论充分性的重要概念。
假设我们有一个随机样本集 <span class="math notranslate nohighlight">\(\mathcal{D} = \{x_1,x_2,\dots,x_N\}\)</span> ，样本集中的样本都是从同一个概率分布
<span class="math notranslate nohighlight">\(p(x|\theta)\)</span> 采样得到，其中 <span class="math notranslate nohighlight">\(\theta\)</span> 是这个分布的未知参数，参数空间为 <span class="math notranslate nohighlight">\(\Theta\)</span> 。
我们可以从这个样本集中估计出未知参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的值，常见的参数估计方法有：矩估计(method of moments)，
最大似然估计(maximum likelihood)，贝叶斯估计(Bayes estimation)。
我们先回顾一下极大似然估计，极大似然估计是通过极大化似然函数求得参数的估计值，似然函数其实就是样本的联合概率。
比如我们有一个概率分布 <span class="math notranslate nohighlight">\(p(x|\theta)\)</span> ，其中 <span class="math notranslate nohighlight">\(\theta\)</span> 是这个分布的未知参数，
这个分布的i.i.d观测样本为 <span class="math notranslate nohighlight">\(\mathcal{D}=\{x_1,x_2,\dots,x_N\}\)</span> ，
所有样本都发生的联合概率为 <span class="math notranslate nohighlight">\(p(x_1,x_2,\dots,x_N|\theta)=\prod_{i=1}^N p(x_i|\theta)\)</span> ，
这个联合概率就是似然函数，通过极大化求得参数的估计值 <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> 。
从参数估计章节的例子中我们可以看到，最后参数的估计量可以表示为随机样本的一个函数，这样的函数称为统计量(statistic)。</p>
<dl class="glossary simple">
<dt id="term-0">统计量<a class="headerlink" href="#term-0" title="Permalink to this term"></a></dt><dd><p>正式的，任意观测样本的实值函数 <span class="math notranslate nohighlight">\(T=f(\mathcal{D})\)</span> 都称为一个 <strong>统计量(statistic)</strong> 。
一个统计量就是一个关于样本集的函数（允许是向量形式的函数)，<strong>在这个函数中不能有任何未知参数</strong> 。
比如，样本的均值 <span class="math notranslate nohighlight">\(\bar{x}=\frac{1}{N}\sum_i^N x_i\)</span> ，最大值 <span class="math notranslate nohighlight">\(max(\mathcal{D})\)</span>
， 中位数 <span class="math notranslate nohighlight">\(median(\mathcal{D})\)</span> 以及 <span class="math notranslate nohighlight">\(f(\mathcal{D})=4\)</span> 都是统计量。
但是 <span class="math notranslate nohighlight">\(x_1+\mu\)</span> （ <span class="math notranslate nohighlight">\(\mu\)</span> 是未知参数）就不是统计量。</p>
</dd>
</dl>
<p>在进行参数估计时，我们能利用的只有观测样本集，因此观测样本是我们进行参数估计的唯一信息源。
也就是说，我们能利用的有关参数的所有可用信息都包含在观察样本中。
<strong>因此，我们获得的参数估计量始终是观测值的函数，即参数估计量是统计量。</strong>
从某种意义上讲，该过程可以被认为是“压缩”原始观察数据：最初我们有N个数字，
但是经过这个“压缩”之后，我们只有1个数字 。
这种“压缩”总是使我们失去有关该参数的信息，决不能使我们获得更多的信息。
最好的情况是，该“压缩”结果包含的信息量与N个观测值中包含的信息量相同，
也就是该“压缩”结果包含的信息量已经是关于参数的信息的全部。</p>
<dl class="glossary simple">
<dt id="term-1">充分统计量<a class="headerlink" href="#term-1" title="Permalink to this term"></a></dt><dd><p>假设有一个统计量 <span class="math notranslate nohighlight">\(T(\mathcal{D})\)</span> ，并且 <span class="math notranslate nohighlight">\(t\)</span> 是 <span class="math notranslate nohighlight">\(T\)</span> 的一个特定值，
如果在给定 <span class="math notranslate nohighlight">\(T=t\)</span> 的条件下，我们就能计算出样本的联合概率 <span class="math notranslate nohighlight">\(p(x_1,x_2,\dots,x_N|T=t)\)</span> ，
而不再依赖参数 <span class="math notranslate nohighlight">\(\theta\)</span> ，这个统计量就是 <strong>充分统计量(sufficient statistic)</strong> 。
换种说法，在给定充分统计量 <span class="math notranslate nohighlight">\(T=t\)</span> 条件下，就能确定参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的值，而不再需要额外的信息，
我们可以设想只保留 <span class="math notranslate nohighlight">\(T\)</span> 并丢弃所有 <span class="math notranslate nohighlight">\(x_i\)</span>，而不会丢失任何信息！
从上面的直观分析中，我们可以看到充分统计量“吸收”了样本中包含的有关 <span class="math notranslate nohighlight">\(\theta\)</span> 的所有可用信息。
这个概念是R.A. Fisher在1922年提出的。</p>
</dd>
</dl>
<p>充分性的概念是为了回答以下问题而提出的：
是否存在一个统计量，即函数 <span class="math notranslate nohighlight">\(T(x_1,\dots,x_n)\)</span> ，其中包含样本中有关 <span class="math notranslate nohighlight">\(\theta\)</span> 的所有信息？
如果这样，则可以将原始数据减少或压缩到该统计信息而不会丢失信息。
例如，考虑一系列成功概率未知的独立伯努利试验。
我们可能有一种直觉的感觉，成功次数包含样本中有关 <span class="math notranslate nohighlight">\(\theta\)</span> 的所有信息，
而成功发生的顺序没有提供有关 <span class="math notranslate nohighlight">\(\theta\)</span> 的任何其他信息。
对于高斯分布，(样本)期望和(样本)协方差矩阵就是它的充分统计量，因为如果这两个参数已知，
就可以唯一确定一个高斯分布，而对于高斯分布的其他统计量，例如振幅、高阶矩等在这种时候都是多余的。</p>
<div class="topic">
<p class="topic-title">示例：</p>
<p>令 <span class="math notranslate nohighlight">\(x_1,x_2,\dots,x_N\)</span> 是N次独立伯努利实验的结果，其中 <span class="math notranslate nohighlight">\(p(x_i=1)=\theta\)</span> 。
我们将验证 <span class="math notranslate nohighlight">\(T=\sum_{i=1}^N x_i\)</span> 是 <span class="math notranslate nohighlight">\(\theta\)</span> 的一个充分统计量。</p>
</div>
<div class="topic">
<p class="topic-title">证明：</p>
<p>由于 <span class="math notranslate nohighlight">\(x_i\)</span> 只能取值为0或者1，所以 <span class="math notranslate nohighlight">\(T=t\)</span> 可以看作是在N条样本中 <span class="math notranslate nohighlight">\(x_i=1\)</span> 的次数。
根据贝叶斯定理有：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-79">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-79" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}p(x_1,x_2,\dots,x_N|T=t) &amp;= \frac{p(x_1,\dots,x_N)}{p(T=t)}\\&amp;= \frac{\prod_i \theta^{x_i} (1-\theta)^{(1-x_i)} }{p(T=t)}\\&amp;= \frac{ \theta^t (1-\theta)^{N-t} }{p(T=t)}\end{aligned}\end{align} \]</div>
<p>现在看分母部分，T的含义是在N次实验中1的数量，很明显这是二项式分布，有N次试验，单词成功(为1)的概率为 <span class="math notranslate nohighlight">\(\theta\)</span> ，
一共成功t次(1的数量为t)的概率分布为 <span class="math notranslate nohighlight">\(T=\binom{N}{t}\theta^t (1-\theta)^{N-t}\)</span> ，其中 <span class="math notranslate nohighlight">\(\binom{N}{t}\)</span>
是组合数，从N个结果中任意选出t个的方法数。把分母代入上式：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-80">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-80" title="公式的永久链接"></a></span>\[p(x_1,x_2,\dots,x_N|T=t) = \frac{ \theta^t (1-\theta)^{N-t} }{\binom{N}{t}\theta^t (1-\theta)^{N-t}}
= \frac{1}{\binom{N}{t}}\]</div>
<p>最终发现，样本在给定 <span class="math notranslate nohighlight">\(T=t\)</span> 的条件下的联合概率与参数 <span class="math notranslate nohighlight">\(\theta\)</span> 无关，也就是说在确定了 <span class="math notranslate nohighlight">\(T\)</span> 之后，
就可以直接得到样本的联合概率，而不再依赖参数 <span class="math notranslate nohighlight">\(\theta\)</span> 。</p>
</div>
<p>在很多问题中，参数的最大似然估计量就是一个充分统计量，比如，伯努利实验的参数估计量就是一个充分统计量
<span class="math notranslate nohighlight">\(\hat{\theta}_{ML}=\frac{1}{N}\sum_{i=1}^N x_i=\bar{x}\)</span> 。
同样，贝叶斯参数估计量也是一个充分统计量。最大似然估计量和贝叶斯估计量都是充分统计量的一个函数，
它们”吸收”了观测样本中关于参数的所有有用信息。</p>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>根据统计量的定义：样本的一个函数可以称为统计量，样本的求和 <span class="math notranslate nohighlight">\(\sum_{n=1}^N x_n\)</span> ，
样本的均值 <span class="math notranslate nohighlight">\(\frac{1}{N}\sum_{n=1}^N x_n\)</span> 都可以称为统计量。
所以，似然估计量 <span class="math notranslate nohighlight">\(\hat{\theta}_{ML}=\frac{1}{N}\sum_{i=1}^N x_i\)</span> 可以整体看做一个充分统计量(均值统计)，
也可以看做是充分统计量(求和) <span class="math notranslate nohighlight">\(\sum_{n=1}^N x_n\)</span> 的一个函数。</p>
</div>
</section>
<section id="fisher-information">
<span id="ch-2-fisher-information"></span><h2>Fisher Information<a class="headerlink" href="#fisher-information" title="永久链接至标题"></a></h2>
<p>在参数估计问题中，我们从目标概率分布的观测样本中获取有关参数的信息。
这里有一个很自然的问题是：数据样本可以提供多少关于未知参数信息？
本节我们介绍这种信息量的度量方法。
我们还可以看到，
该信息量度可用于查找估计量方差的界限，
并可用于近似估计从大样本中获得的估计量的抽样分布，
并且如果样本较大，则进一步用于获得近似置信区间。</p>
<p>假设有一个随机变量 <span class="math notranslate nohighlight">\(X\)</span>
，其概率分布函数为 <span class="math notranslate nohighlight">\(p(x;\theta)\)</span>
， <span class="math notranslate nohighlight">\(\theta\)</span> 是模型的未知参数，并且 <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span>
， <span class="math notranslate nohighlight">\(\Theta\)</span> 是参数空间。
对于一个随机变量 <span class="math notranslate nohighlight">\(X \sim p(x;\theta)\)</span>
，当 <span class="math notranslate nohighlight">\(\theta\)</span> 为真实值时，其似然函数应该取得一个极大值，或者说，此时似然函数的导数为0，
这是最大似然估计的基本原理。
我们定义 <span class="math notranslate nohighlight">\(\ell(\theta;\mathcal{D})=log p(\mathcal{D};\theta)\)</span>
为对数似然函数(log-likelihood function)，
<span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 可以看做是一个包含N的随机值的随机变量。
<span class="math notranslate nohighlight">\(p(\mathcal{D};\theta)\)</span> 是所有样本的联合概率分布。</p>
<p>在很多资料中，符号 <span class="math notranslate nohighlight">\(X\)</span> 既表示独立的随即变量，也可以是观测样本集变量，
<span class="math notranslate nohighlight">\(p(x;\theta)\)</span> 既是单个样本的概率分布，又是多个观测样本的联合概率（似然），
容易造成混淆，不利于理解。
为了便于大家理解，我们分两种情况讨论：</p>
<ol class="arabic simple">
<li><p>当仅有一个观测样本时，样本变量的概率分布函数为 <span class="math notranslate nohighlight">\(p(x;\theta)\)</span> ，
对数似然函数为 <span class="math notranslate nohighlight">\(\ell(\theta;x)=\log p(x;\theta)\)</span> 。</p></li>
<li><p>当有 <span class="math notranslate nohighlight">\(N\)</span> 个观测样本时，样本集变量的概率分布函数为 <span class="math notranslate nohighlight">\(p(\mathcal{D};\theta)\)</span> ，
对数似然函数为 <span class="math notranslate nohighlight">\(\ell(\theta;\mathcal{D})=\log p(\mathcal{D};\theta)= \sum_{i=1}^N \log p(x_i;\theta)\)</span> 。</p></li>
</ol>
<p>我们先讨论只有一个观测样本的情形，此时对数似然函数的一阶导数为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-81">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-81" title="公式的永久链接"></a></span>\[\ell(\theta;x) = \frac{\partial }{\partial \theta} \log p(x;\theta)
=\frac{p'(x;\theta)}{p(x;\theta)}\]</div>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>这里利用了对数函数的求导公式:</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-82">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-82" title="公式的永久链接"></a></span>\[\nabla \log f(x) = \frac{1}{f(x)} \nabla f(x)\]</div>
</div>
<p>其中 <span class="math notranslate nohighlight">\(p'(x;\theta)\)</span> 表示函数 <span class="math notranslate nohighlight">\(p(x;\theta)\)</span>
关于 <span class="math notranslate nohighlight">\(\theta\)</span> 的一阶导数，同理，
<span class="math notranslate nohighlight">\(p''(x;\theta)\)</span> 表示二阶导数。
通常模型的 <span class="math notranslate nohighlight">\(\theta\)</span> 是一个向量，这时对数似然函数的一阶导数是一个向量，
二阶导数是一个方阵。</p>
<div class="topic">
<p class="topic-title">Score function</p>
<p>对数似然函数关于参数的一阶导数称为得分函数(Score function)，通常用符号 <span class="math notranslate nohighlight">\(S\)</span> 表示。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-83">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-83" title="公式的永久链接"></a></span>\[S(\theta)= \frac{\partial \ell(\theta)}{\partial \theta}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\theta\)</span> 是模型的参数，当模型存在多个参数时，<span class="math notranslate nohighlight">\(\theta\)</span> 是参数向量，
<span class="math notranslate nohighlight">\(S(\theta)\)</span> 也是一个向量。 <span class="math notranslate nohighlight">\(S(\theta)\)</span> 是一个关于 <strong>观测样本和参数</strong> 的函数。
通常如果似然函数是凹(concave)的，我们可以通过令 <span class="math notranslate nohighlight">\(S(\theta)=0\)</span> 求得参数的解析解。</p>
</div>
<p><span class="math notranslate nohighlight">\(S(\theta)\)</span> 是对数似然函数的一阶导数，一阶导数描述的是函数在这一点的切线的斜率，
导数越大切线斜率越大，所以 <span class="math notranslate nohighlight">\(S(\theta)\)</span> 表示的是对数似然函数在某个 <span class="math notranslate nohighlight">\(\theta\)</span>
值时模型的敏感度(sensitive)。</p>
<p>我们知道观测样本也是一个随机变量，<span class="math notranslate nohighlight">\(S(\theta)\)</span> 是观测样本的一个函数，
所以 <span class="math notranslate nohighlight">\(S(\theta)\)</span> 也可以看做是一个随机变量，
因此我们可以研究 <span class="math notranslate nohighlight">\(S(\theta)\)</span> 的期望与方差。
我们先来看一下 <span class="math notranslate nohighlight">\(S(\theta)\)</span>  的期望，
<span class="math notranslate nohighlight">\(S(\theta)\)</span> 的期望的计算需要利用一些数学技巧。</p>
<p>一个函数的积分和求导是可以互换的，并且概率分布函数的积分一定是等于1的，
所以有如下等式成立。</p>
<div class="math notranslate nohighlight" id="equation-eq-2-33">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-33" title="公式的永久链接"></a></span>\[\int f'(x;\theta) dx= \frac{\partial}{\partial \theta} \int f(x;\theta) dx
=\frac{\partial}{\partial \theta} 1
=0\]</div>
<p>类似地有：</p>
<div class="math notranslate nohighlight" id="equation-eq-2-34">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-34" title="公式的永久链接"></a></span>\[\int f''(x;\theta) dx= \frac{\partial^2}{\partial \theta^2} \int f(x;\theta) dx
=\frac{\partial}{\partial \theta} 1
=0\]</div>
<p><span class="math notranslate nohighlight">\(S(\theta)\)</span> 关于样本变量的期望一定是等于0的，
结合 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-33">公式(2.6.4)</a> 可以推导出 <span class="math notranslate nohighlight">\(S(\theta)\)</span> 的期望为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-84">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-84" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\mathop{\mathbb{E}}_{p(x ; \theta)} \left[ s(\theta) \right] &amp;= \mathop{\mathbb{E}}_{p(x ; \theta)} \left[ \nabla \ell(\theta;x) \right]\\&amp;= \int [\nabla \ell(\theta;x)] \, p(x ; \theta) \, \text{d}x\\&amp;= \int [\nabla \log p(x ; \theta)] \, p(x ; \theta) \, \text{d}x\\&amp;= \int \frac{\nabla p(x ; \theta)}{p(x ; \theta)} p(x ; \theta) \, \text{d}x\\&amp;= \int \nabla p(x ; \theta) \, \text{d}x\\&amp;= \nabla \int p(x; \theta) \, \text{d}x\\&amp;= \nabla 1\\&amp;= 0\end{aligned}\end{align} \]</div>
<p><span class="math notranslate nohighlight">\(S(\theta)\)</span> 的二阶矩(second moment)，也就是其方差(Variance)，被称为 Fisher Information，
中文常翻译成费歇尔信息，
通常用符号 <span class="math notranslate nohighlight">\(I(\theta)\)</span> 表示，
<span class="math notranslate nohighlight">\(I(\theta)\)</span> 是一个方阵，通常称为信息矩阵(information matrix)。</p>
<div class="math notranslate nohighlight" id="equation-eq-2-35">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-35" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}I(\theta) &amp;=\mathop{Var(S(\theta))}_{p(x ; \theta)}\\&amp;=
\mathop{\mathbb{E}}_{p(x ; \theta)} [(S(\theta)- \mathop{\mathbb{E}}_{p(x ; \theta)} [S(\theta)] )^2]\\&amp;= \mathop{\mathbb{E}}_{p(x ; \theta)} [S(\theta)^2]\\&amp;= \mathop{\mathbb{E}}_{p(x ; \theta)} [S(\theta)S(\theta)^T]\end{aligned}\end{align} \]</div>
<p>实际上， <span class="math notranslate nohighlight">\(I(\theta)\)</span> 和对数似然函数的二阶导数的期望值是有关系的，
我们先来看下对数似然函数的二阶导数，
二阶导数可以在一阶导数的基础上再次求导得到。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-85">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-85" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\ell''(\theta;x) &amp;= \frac{\partial}{\partial \theta} \ell'(\theta;x)\\&amp;= \frac{\partial}{\partial \theta} \left [  \frac{p'(x;\theta)}{p(x;\theta)} \right ]\\&amp;= \frac{p''(x;\theta)p(x;\theta)-[p'(x;\theta)]^2}{[p(x;\theta)]^2}\\&amp;= \frac{p''(x;\theta)p(x;\theta)}{[p(x;\theta)]^2} - \left[ \frac{p'(x;\theta)}{p(x;\theta)} \right]^2\\&amp;= \frac{p''(x;\theta)}{p(x;\theta)} - [\ell'(\theta;x)]^2\end{aligned}\end{align} \]</div>
<p>然后我们看下对数似然函数二阶导数的期望值：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-86">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-86" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\mathop{\mathbb{E}}_{p(x ; \theta)} \left[ \ell''(\theta;x) \right] &amp;=
\int \left [  \frac{p''(x;\theta)}{p(x;\theta)} - [\ell'(\theta;x)]^2  \right ]  p(x;\theta) dx\\&amp;= \int p''(x;\theta) dx -\int [\ell'(\theta;x)]^2  p(x;\theta) dx\\&amp;= 0 - \int [S(\theta)]^2  p(x;\theta)  dx\\&amp;=  - \mathop{\mathbb{E}}_{p(x ; \theta)} [ [S(\theta)]^2 ]\\&amp;=  - I(\theta)\end{aligned}\end{align} \]</div>
<p>因此，Fisher Information 就等于对数似然函数二阶导数的期望的负数。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-87">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-87" title="公式的永久链接"></a></span>\[I(\theta) = - \mathop{\mathbb{E}}_{p(x ; \theta)} \left[ \ell''(\theta;x) \right]\]</div>
<p>一个标量值函数(scalar-valued function)的二阶偏导数矩阵(方阵)称为海森矩阵(Hessian matrix)，
通常用符号 <span class="math notranslate nohighlight">\(H\)</span> 表示，
因此 <span class="math notranslate nohighlight">\(I(\theta)\)</span> 经常也被表示成海森矩阵的期望的负数。</p>
<div class="math notranslate nohighlight" id="equation-eq-34-41">
<span class="eqno">()<a class="headerlink" href="#equation-eq-34-41" title="公式的永久链接"></a></span>\[I(\theta) = - \mathop{\mathbb{E}}_{p(x ; \theta)}[H(\theta)]\]</div>
<p>我们看到，无论是通过score function 的方差计算，还是通过Hessian矩阵计算，
<span class="math notranslate nohighlight">\(I(\theta)\)</span> 都是一个期望值，所以经常被称为期望化信息(expected information)。</p>
<p>现在我们来看下观测样本为 <span class="math notranslate nohighlight">\(N\)</span> 个的情形，
我们知道多个独立同分布观测样本的对数似然值就是每个独立样本的求和：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-88">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-88" title="公式的永久链接"></a></span>\[\ell(\theta;\mathcal{D})=\sum_{i=1}^{N}  \ell(\theta;x_i)\]</div>
<p>我们用符号 <span class="math notranslate nohighlight">\(I_{X}(\theta)\)</span> 表示一个观测值的信息矩阵，通常称为 unit Fisher information。
用符号  <span class="math notranslate nohighlight">\(I_{\mathcal{D}}(\theta)\)</span> 表示多个观测值的信息矩阵，则有：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-89">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-89" title="公式的永久链接"></a></span>\[I_{\mathcal{D}}(\theta) = N I_{X}(\theta)\]</div>
<p><span class="math notranslate nohighlight">\(I_{\mathcal{D}}(\theta)\)</span> 是正比于 <span class="math notranslate nohighlight">\(N\)</span> 的，也就是说样本越多，我们的到关于参数的信息量就越大。</p>
</section>
<section id="id15">
<h2>估计量的评价<a class="headerlink" href="#id15" title="永久链接至标题"></a></h2>
<p>一个服从某个概率分布的随机变量 <span class="math notranslate nohighlight">\(X\)</span> ，假设其分布函数为 <span class="math notranslate nohighlight">\(f(x;\theta)\)</span>
，其中 <span class="math notranslate nohighlight">\(\theta\)</span> 是未知参数，我们可以从变量 <span class="math notranslate nohighlight">\(X\)</span>
的观测样本集中估计出参数的值。估计的算法有很多种，我们已经介绍最大似然估计、贝叶斯估计、最大后验估计三种参数估计算法。
那么一个参数估计值 <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> 到底准不准呢？本节我们讨论如何评价一个估计量的好坏。</p>
<section id="id16">
<h3>估计量的方差与偏差<a class="headerlink" href="#id16" title="永久链接至标题"></a></h3>
<p>对于一个长度为N的观测样本集 <span class="math notranslate nohighlight">\(\mathcal{D}=\{x_1,x_2,\dots,x_N\}\)</span> ，
其中每条样本 <span class="math notranslate nohighlight">\(x_n\)</span> 有 <span class="math notranslate nohighlight">\(|\mathcal{X}|\)</span> 种可能取值，样本集 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>
一共有 <span class="math notranslate nohighlight">\(|\mathcal{X}|^N\)</span> 种可能取值。
某个特定样本集的概率为其中所有样本的联合概率 <span class="math notranslate nohighlight">\(p(\mathcal{D})=p(x_1,x_2,\dots,x_N)\)</span> ，
显然，我们可以把 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 也可看做一个随机变量。
<strong>我们知道参数估计量是通过观测样本得到的，所以参数估计量一定是观测样本集的一个统计量(函数)，</strong>
长度固定为N样本集的不同采样将得到不同的参数估计值 <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>
，所以参数估计量也是一个随机变量。
我们用符号 <span class="math notranslate nohighlight">\(\hat{\theta}(\mathcal{D})\)</span>
表示基于样本 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 的参数估计量。</p>
<p>随着样本数量的增加，一个参数估计量应该越来越接近参数的真实值，并且最终能收敛到参数的真实值，
我们把最终能收敛到真实值的估计量称为一致估计。</p>
<div class="topic">
<p class="topic-title">一致性(Consistency)</p>
<p>当样本数量趋近于无穷大时，估计量 <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> 依据某种 <strong>概率</strong> 收敛于参数的真实值 <span class="math notranslate nohighlight">\(\theta_{\text{true}}\)</span>
，那么这个估计量 <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> 就是一致性估计量。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-90">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-90" title="公式的永久链接"></a></span>\[p(\hat{\theta}=\theta_{\text{true}})=1, n \rightarrow \infty\]</div>
</div>
<p>为什么是 <em>依概率</em> 收敛，而不是 <em>确定性</em> 收敛？
因为参数估计量本身是一个随机变量，服从某种概率分布，只能是以某种概率得到某个确定性的值，
所以这里是依概率收敛到真实值。
一致性是对参数估计的基本要求，一个参数估计要是不满足一致性基本无用。</p>
<p>一致性估计量是 <em>依概率</em> 收敛到真实值的，并不是一定收敛到真实值，
所示我们实际上得到的参数估计量和真实值之间还是会存在一定误差的。
我们需要对这个误差进行量化评估，以便能评估一个估计量的好坏。
最直接的方法是计算估计量 <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> 和参数真实值 <span class="math notranslate nohighlight">\(\theta_{\text{true}}\)</span>
之间的均方误差(mean-squared error,MSE)，
由于其中估计量是一个随机变量，所以我们计算MSE的期望。</p>
<div class="math notranslate nohighlight" id="equation-eq-2-39">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-39" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}MSE &amp;= \mathbb{E}_{\mathcal{D}} [(\hat{\theta}(\mathcal{D})- \theta_{\text{true}} )^2]\\&amp;= \mathbb{E}_{\mathcal{D}}[ \hat{\theta}(\mathcal{D})^2-2\hat{\theta}(\mathcal{D})\theta_{\text{true}} + \theta_{\text{true}}^2    ]\\&amp;= \left [ \mathbb{E}_{\mathcal{D}}[\hat{\theta}(\mathcal{D})^2]- \mathbb{E}_{\mathcal{D}}[\hat{\theta}(\mathcal{D})]^2 \right ]
+\left [ \mathbb{E}_{\mathcal{D}}[\hat{\theta}(\mathcal{D})]^2    -2\hat{\theta}(\mathcal{D})\theta_{\text{true}} + \theta_{\text{true}}^2   \right ]\\&amp;= \underbrace{Var_{\mathcal{D}} (\hat{\theta}(\mathcal{D}))}_{\text{方差}}
 +
\underbrace{\left ( \mathbb{E}_{\mathcal{D}}[\hat{\theta}(\mathcal{D})]- \theta_{\text{true}}\right)^2}_{\text{偏差}}\end{aligned}\end{align} \]</div>
<div class="admonition attention">
<p class="admonition-title">注意</p>
<p>这里的方差是参数估计量的方差，不是观测变量 <span class="math notranslate nohighlight">\(X\)</span> 的方差。</p>
</div>
<p>根据上述MSE的等式，一个估计量和真实值之间的MSE是由方差和偏差决定的，
一个好的估计量应该是方差和偏差都尽可能的小。
一个估计量的偏差被定义成估计量的期望和参数真实值误差的平方：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-91">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-91" title="公式的永久链接"></a></span>\[b(\hat{\theta}) = (\mathbb{E}_{\mathcal{D}}[\hat{\theta}(\mathcal{D}) ]
- \theta_{\text{true}})^2\]</div>
<dl class="glossary simple">
<dt id="term-2">无偏估计<a class="headerlink" href="#term-2" title="Permalink to this term"></a></dt><dd><p>当一个估计量满足 <span class="math notranslate nohighlight">\(b(\hat{\theta})=0\)</span> 时，也就是满足 <strong>估计量的期望值等于参数的真实值</strong> ，就称这个估计量为无偏估计。</p>
</dd>
</dl>
<p>无偏估计就是偏差最小的估计量(偏差为0)，而估计量的方差也是存在下界的，这可以通过一个定理给出：</p>
<div class="topic">
<p class="topic-title">Cramer-Rao Lower Bound (CRLB) 定理</p>
<p>Cram´er–Rao Lower Bound (CRLB)定理描述了一个确定性参数(deterministic parameter) <span class="math notranslate nohighlight">\(\theta\)</span>
的估计量的方差的下界</p>
<div class="math notranslate nohighlight" id="equation-eq-2-50">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-50" title="公式的永久链接"></a></span>\[Var(\hat{\theta}) \ge \frac{(\frac{\partial}{\partial \theta} \mathbb{E}[\hat{\theta}] )^2}{I(\theta)}\]</div>
</div>
<p>其中分子是估计量期望对参数真实值的一阶导的平方，
如果一个估计量是无偏估计，那么有 <span class="math notranslate nohighlight">\(\mathbb{E}[\hat{\theta}]=\theta_{\text{true}}\)</span>
，这时分子就等于1。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-92">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-92" title="公式的永久链接"></a></span>\[(\frac{\partial}{\partial \theta} \mathbb{E}[\hat{\theta}] )^2
= ( \frac{\partial}{\partial \theta}  \theta)^2
= 1\]</div>
<p>因此对于无偏估计量，<a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-50">公式(2.7.20)</a> 可以简化为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-93">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-93" title="公式的永久链接"></a></span>\[Var(\hat{\theta}) \ge \frac{1}{I(\theta)}\]</div>
<p><span class="math notranslate nohighlight">\(I(\theta)\)</span> 是费歇尔信息(Fisher-Information)矩阵。
根据CRLB定理，可以看出一个估计量的方差是存在下界的，
并且对于无偏估计量，估计量的方差的最小值是费歇尔信息的倒数。
显然当一个估计量的方差为下界时，这个估计量是最稳定的，
这时我们称之为有效估计。</p>
<div class="topic">
<p class="topic-title">有效估计量(Efficient Estimator)</p>
<p>任意一个估计量，如果其方差为CRLB的下限，那么这个估计量是有效估计量。</p>
</div>
<p>最好的估计量应该是偏差和方差都尽可能的小，偏差最小为无偏估计，
所以我们定义出最小方差无偏估计。</p>
<div class="topic">
<p class="topic-title">最小方差无偏估计</p>
<p>当参数 <span class="math notranslate nohighlight">\(\theta\)</span> 存在多个无偏估计时，其中方差最小的估计量就称为最小方差无偏估计
(Minimum Variance Unbiased Estimator,MVUE)。
显然，MVUE是使得MSE最小的估计量。
然而，最小方差无偏估计量并不总是存在的，
即使存在，我们也可能找不到，没有任何一种方法会始终产生MVUE。
查找MVUE的一种有用方法是为参数找到充分统计量。</p>
</div>
</section>
<section id="id17">
<h3>大数定律和中心极限定理<a class="headerlink" href="#id17" title="永久链接至标题"></a></h3>
<p>要理解后续的内容，依赖两个很重要的定理，大数定律(Law of Large Numbers,LLN)和中心极限定理(Central Limit Theorem,CLT)。
所以这里我们首先回顾一下这两个定理的内容。</p>
<p>假设有一个随机变量 <span class="math notranslate nohighlight">\(X\)</span> ，假设其期望为 <span class="math notranslate nohighlight">\(\mu\)</span>
，方差为 <span class="math notranslate nohighlight">\(\sigma^2\)</span>
。
我们对这个随机变量进行N次独立采样，得到长度为N的观测样本集
<span class="math notranslate nohighlight">\(\mathcal{D}=\{x_1,x_2,\dots,x_N\}\)</span> 。
样本集中的每个样本点都是从同一个随机变量(同样的概率分布)中采样得到，并且是独立进行的，
所以这个样本集是独立同分布的(i.i.d)的。
<strong>样本集</strong> <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>
<strong>可以看成是一个随机变量的N次采样，也可以把其中每个样本点看做是一个独立的随机变量，</strong>
<strong>即</strong>
<span class="math notranslate nohighlight">\(\mathcal{D}\)</span>
<strong>是N的同分布的随机变量集合。</strong>
<strong>此时，我们表示成</strong>
<span class="math notranslate nohighlight">\(\mathcal{D}=\{X_1,X_2,\dots,X_N\}\)</span>
。大数定律和中心极限定理都是描述的 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 的性质。</p>
<section id="id18">
<h4>大数定律<a class="headerlink" href="#id18" title="永久链接至标题"></a></h4>
<p>我们定义样本集 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 的平均值为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-94">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-94" title="公式的永久链接"></a></span>\[Z_N = \frac{X_1+X_2+\cdots+X_N}{N}\]</div>
<p>由于 <span class="math notranslate nohighlight">\(x_1,x_2,\dots,x_N\)</span> 都是随机值，所以它们计算得到的 <span class="math notranslate nohighlight">\(Z_N\)</span> 也是一个随机值，
所以 <span class="math notranslate nohighlight">\(Z_N\)</span> 也是一个随机变量。
既然 <span class="math notranslate nohighlight">\(Z_N\)</span> 也是一个随机变量，
那么我们就研究一起它的期望和方差。
<span class="math notranslate nohighlight">\(Z_N\)</span> 的期望值可以通过下式计算得到：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-95">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-95" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}\mathbb{E}[Z_N] &amp;= \mathbb{E} \left [  \frac{X_1+X_2+\cdots+X_N}{N} \right ]\\&amp;= \frac{\mathbb{E}[X_1+X_2+\cdots+X_N ]  }{N}\\&amp;= \frac{\mathbb{E}[X_1] + \mathbb{E}[X_2]+\cdots+\mathbb{E}[X_N]   }{N}\end{aligned}\end{align} \]</div>
<p>由于 <span class="math notranslate nohighlight">\(x_1,x_2,\dots,x_N\)</span> 是独立同分布的，假设随机变量 <span class="math notranslate nohighlight">\(X_i\)</span> 的期望值为 <span class="math notranslate nohighlight">\(\mu\)</span>
，于是可以得到 <span class="math notranslate nohighlight">\(Z_N\)</span> 的期望值为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-96">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-96" title="公式的永久链接"></a></span>\[\mathbb{E}[Z_N] = \frac{N \mu}{N} = \mu\]</div>
<p>我们发现 <span class="math notranslate nohighlight">\(Z_N\)</span> 的期望值与每个独立变量 <span class="math notranslate nohighlight">\(X_i\)</span> 的期望值相同。
现在我们看下 <span class="math notranslate nohighlight">\(Z_N\)</span> 的方差。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-97">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-97" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}Var[Z_N] &amp;= Var\left[ \frac{X_1+X_2+\cdots+X_N}{N}  \right ]\\&amp;= \frac{Var[X_1+X_2+\cdots+X_N ] }{N^2}\end{aligned}\end{align} \]</div>
<p>此时由于 <span class="math notranslate nohighlight">\(x_1,x_2,\dots,x_N\)</span> 是独立的，所以满足：和的方差等于方差的和，即</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-98">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-98" title="公式的永久链接"></a></span>\[Var[X_1+X_2+\cdots+X_N ]
=Var[X_1] + Var[X_2] + \cdots + Var[X_N]\]</div>
<p>因此 <span class="math notranslate nohighlight">\(Z_N\)</span> 的方差为：</p>
<div class="math notranslate nohighlight" id="equation-eq-2-40">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-40" title="公式的永久链接"></a></span>\[Var[Z_N] = \frac{Var[X_1] + Var[X_2] + \cdots + Var[X_N]}{N^2} = \frac{N \sigma^2}{N^2}
= \frac{ \sigma^2}{N}\]</div>
<p>至此我们发现，对于独立同分布的样本，样本均值变量的期望值就等于独立变量的期望值，样本均值的方差为独立变量的方差的
<span class="math notranslate nohighlight">\(1/N\)</span> 。
<span class="math notranslate nohighlight">\(N\)</span> 越大，样本均值变量的方差 <span class="math notranslate nohighlight">\(Var[Z_N]\)</span> 就越小，方差 <span class="math notranslate nohighlight">\(Var[Z_N]\)</span> 越小，
样本均值变量 <span class="math notranslate nohighlight">\(Z_N\)</span> 就越稳定，也就是越来越收敛于其自身的期望值 <span class="math notranslate nohighlight">\(\mathbb{E}[Z_N]\)</span> 。
极限情况下，当 <span class="math notranslate nohighlight">\(N\)</span> 无穷大时，方差趋近于0 <span class="math notranslate nohighlight">\(Var[Z_N] \rightarrow 0\)</span> ，
<span class="math notranslate nohighlight">\(Z_N\)</span> 就稳定在(收敛于)期望值 <span class="math notranslate nohighlight">\(Z_N \rightarrow  \mathbb{E}[Z_N] =\mu\)</span>
。</p>
<p>现在我们给出大数定律的正式定义：</p>
<div class="topic">
<p class="topic-title">大数定律(Law of Large Numbers,LLN)</p>
<p>一个独立同分布的样本 <span class="math notranslate nohighlight">\(X_1,X_2,\dots,X_N\)</span> ，如果 <span class="math notranslate nohighlight">\(X\)</span> 的期望值是有限值，即
<span class="math notranslate nohighlight">\(|\mathbb{E}[X]| &lt; \infty\)</span> ，那么样本的均值 <span class="math notranslate nohighlight">\(Z_N\)</span>
<em>依概率(in probability)</em> 收敛于变量 <span class="math notranslate nohighlight">\(X\)</span> 期望值。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-99">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-99" title="公式的永久链接"></a></span>\[Z_N = \frac{X_1+X_2+\cdots+X_N}{N} \rightarrow^d \mathbb{E}[X]\]</div>
<p>为什么是 <em>依概率(in probability)</em> ？
时刻牢记 <span class="math notranslate nohighlight">\(Z_N\)</span> （样本均值）是一个随机变量，既然是随机变量就一定服从于某种概率分布。理论上，只有当N无穷大时，
<span class="math notranslate nohighlight">\(Z_N\)</span> 才收敛于 <span class="math notranslate nohighlight">\(\mathbb{E}[X]\)</span> ；反之，当N有限时，仅满足
<span class="math notranslate nohighlight">\(\mathbb{E}[Z_N] = \mathbb{E}[X]\)</span> 。
同时 <span class="math notranslate nohighlight">\(Z_N\)</span> （样本均值）也是样本的一个统计量(statistic)。</p>
</div>
</section>
<section id="id19">
<h4>中心极限定理<a class="headerlink" href="#id19" title="永久链接至标题"></a></h4>
<p>大数定律描述的是样本的均值 <em>“依概率”</em> 渐近收敛于分布的期望(均值)，并没有说明是依据什么概率分布，
而中心极限定理对此做出了解释。
回顾 <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-40">公式(2.7.12)</a>
，我们已经知道样本均值变量的方差为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-100">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-100" title="公式的永久链接"></a></span>\[Var[Z_N] =  \frac{ \sigma^2}{N}\]</div>
<p>这个方差不是一个固定值，而是随着 <span class="math notranslate nohighlight">\(N\)</span> 的增加趋近于0的，没有讨论的意义。
我们重新定义一个新的变量
<span class="math notranslate nohighlight">\(W_N\)</span>
：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-101">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-101" title="公式的永久链接"></a></span>\[W_N =  \sqrt{N}(Z_N-\mathbb{E}[X])\]</div>
<p>依据大数定律，显然随着 <span class="math notranslate nohighlight">\(N\)</span> 的增加 <span class="math notranslate nohighlight">\(W_N\)</span> 是趋近于0的。
并且 <span class="math notranslate nohighlight">\(W_N\)</span> 的方差为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-102">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-102" title="公式的永久链接"></a></span>\[Var[W_N] =  (\sqrt{N})^2 Var[Z_N]
= \sigma^2\]</div>
<div class="topic">
<p class="topic-title">中心极限定理(Central Limit Theorem,CLT)</p>
<p>一个独立同分布的样本 <span class="math notranslate nohighlight">\(X_1,X_2,\dots,X_N\)</span> ，如果 <span class="math notranslate nohighlight">\(X\)</span> 的期望值与方差都是有限值，即
<span class="math notranslate nohighlight">\(|\mathbb{E}[X]| &lt; \infty,\sigma^2=Var[X]&lt;\infty\)</span> ，那么
<span class="math notranslate nohighlight">\(\sqrt{N}(Z_N-\mathbb{E}[X])\)</span>
渐近服从于均值为0，方差为 <span class="math notranslate nohighlight">\(\sigma^2\)</span> 的正态分布。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-103">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-103" title="公式的永久链接"></a></span>\[\sqrt{N}(Z_N-\mathbb{E}[X]) \rightarrow \mathcal{N}(0,\sigma^2)\]</div>
</div>
</section>
</section>
<section id="ch-2-mle-estimator">
<span id="id20"></span><h3>最大似然估计的特性<a class="headerlink" href="#ch-2-mle-estimator" title="永久链接至标题"></a></h3>
<p>现在我们讨论下极大似然估计量的特性，
这里我们直接给出结论，省略证明过程。
极大似然估计量通常是满足中心极限定理以及大数定律的，
通常称为渐近正态性和渐近一致性。</p>
<div class="topic">
<p class="topic-title">渐近正态性(Asymptotic normality)</p>
<p>我们说一个估计量是渐近正态性的，如果满足：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-104">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-104" title="公式的永久链接"></a></span>\[\sqrt{n}(\hat{\theta}) \rightarrow^d \mathcal{N}(\theta_{\text{true}},\frac{1}{I(\theta)})\]</div>
<p>或者</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-105">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-105" title="公式的永久链接"></a></span>\[\sqrt{n}(\hat{\theta}-\theta_{\text{true}}) \rightarrow^d \mathcal{N}(0,\frac{1}{I(\theta)})\]</div>
</div>
<p><strong>渐近正态性对应着中心极限定理，极大似然估计是满足渐近正态性的。</strong>
似然估计量不仅是渐近服从正态分布，而且是以参数真实值为均值的正态分布，
这表明似然估计量依概率(正态分布)收敛于参数的真实值，这符合一致性的定义。
显然极大似然估计是一致性估计。
由于似然估计是一致性估计，似然估计量是渐近收敛于参数真实值的，也就是估计量的偏差渐近为0，
因此可以得出似然估计量是 <strong>渐近无偏估计</strong> 。</p>
<p>我们知道估计量的MSE是由偏差和方差组成的（ <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#equation-eq-2-39">公式(2.7.2)</a> ），无偏性是对估计量的偏差的评价，
而估计量的方差影响着估计值的稳定性，方差越小估计量就越稳定，
MLE估计量的方差就等于费歇尔信息的倒数，
如果 <span class="math notranslate nohighlight">\(\theta\)</span> 是参数向量，估计量的方差为协方差矩阵，
此时费歇尔信息 <span class="math notranslate nohighlight">\(I(\theta)\)</span>
为信息矩阵(Information matrix)。</p>
<div class="math notranslate nohighlight" id="equation-eq-2-60">
<span class="eqno">()<a class="headerlink" href="#equation-eq-2-60" title="公式的永久链接"></a></span>\[\text{Cov}(\hat{\theta}_{ML}) = [I(\theta)]^{-1}\]</div>
<p>这里我们省略证明过程，有兴趣的读者可以参考其他资料。
显然似然估计不仅仅是渐近无偏估计，而且估计量的方差就等于CLRB定理的下界，
因此似然估计量是不仅仅是有效估计量，而是其最小方差无偏估计(Minimum Variance Unbiased Estimator,MVUE)，
<strong>并且我们可以通过</strong> <span class="math notranslate nohighlight">\(I(\theta)\)</span> <strong>量化衡量MLE估计量的方差。</strong></p>
<p>当我们用MLE估计出一个参数的估计值后，我们期望能量化评估出这个参数估计值的好坏，
大家常用的方法是计算观测值的误差：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-106">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-106" title="公式的永久链接"></a></span>\[\text{MSE} = \frac{1}{N} \sum_i^N (y_i-\hat{y}_i)^2\]</div>
<p>这种方法衡量的是整个模型的预测效果，并不能衡量出参数的估计值和参数的最优值之间的误差，
我们已经知道MLE是无偏估计，那么最终MLE估计量的误差就可以用如下公式衡量：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-content-107">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-content-107" title="公式的永久链接"></a></span>\[\text{Standard Errors} = \sqrt{Var(\hat{\theta}_{ML})} = \sqrt{ \text{diag} ([I(\theta)]^{-1})}\]</div>
<p><span class="math notranslate nohighlight">\([I(\theta)]^{-1}\)</span> 是协方差矩阵，其对角线元素是每个参数方差，开根号后得到每个参数的标准差。</p>
<p>最后我们总结下MLE拥有的特性：</p>
<ul class="simple">
<li><p>MLE估计量符合中心极限定理，满足渐近正态性(Asymptotic normality)。</p></li>
<li><p>MLE估计量符合大数定律，是一致性(Consistency)估计。</p></li>
<li><p>由于满足一致性，渐近收敛于参数真实值，渐近偏差为0，因此MLE估计量满足渐近无偏性(Invariance)。</p></li>
<li><p>MLE估计量的方差是信息矩阵的逆，符合CRLB定理的下限，所以是有效估计(Efficient Estimator)，并且是最小方差无偏估计。</p></li>
</ul>
<p><strong>MLE的这些特性都是建立在样本数量无穷大的条件下，当样本数量很小时，是没有这些特性的。</strong>
<strong>此外，贝叶斯估计由于增加了先验信息，不再是无偏估计，而是有偏估计。</strong>
<strong>在样本数量比较小时，极大似然估计与贝叶斯估计互有优劣，但随着样本数量的增加， 极大似然估计和贝叶斯估计是相似的。</strong></p>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2018, zhangzhenhu(acmtiger@outlook.com) 禁止一切形式的转载！.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
  


    <script src="https://utteranc.es/client.js"
            repo="zhangzhenhu/blog"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>



</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>