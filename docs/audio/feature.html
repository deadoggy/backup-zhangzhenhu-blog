<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>1. 音频特征 &mdash; 张振虎的博客 张振虎 文档</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
    <link rel="canonical" href="https://zhangzhenhu.github.io/blog/audio/feature.html" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/translations.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"RR": "{\\bf R}", "bold": ["{\\bf #1}", 1]}}})</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="教育领域数据挖掘" href="../edm/index.html" />
    <link rel="prev" title="语音技术" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> 张振虎的博客
          </a>
              <div class="version">
                acmtiger@outlook.com
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">目录:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../glm/source/index.html">广义线性模型</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html">1. 概率基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id2">1.1. 概率模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id3">1.1.1. 概率律</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id4">1.1.2. 离散模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id5">1.1.3. 连续模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id6">1.2. 条件概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id7">1.3. 联合概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id8">1.4. 全概率与贝叶斯定理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id9">1.5. 独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id10">1.6. 随机变量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id11">1.6.1. 离散随机变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id12">1.6.2. 连续随机变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id13">1.6.3. 累积分布函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id14">1.6.4. 随机变量的函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id15">1.6.5. 期望与方差</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id16">1.7. 边缘化</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id17">1.8. 常见概率分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id18">1.8.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id19">1.8.2. 二项式分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id20">1.8.3. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id21">1.8.4. 多项式分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id22">1.8.5. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id23">1.8.6. 卡方分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#t">1.8.7. t分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#f">1.8.8. F分布</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html">2. 最大似然估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#ch-liklihood">2.1. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id3">2.2. 伯努利分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id4">2.3. 类别分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#ch-2-gaussian-ml">2.4. 高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id6">2.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html">3. 推断与检验</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id2">3.1. 统计量和充分统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-sample-distribution">3.2. 抽样分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-sample-distribution-normal">3.2.1. 正态分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#t">3.2.2. 学生t分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id5">3.2.3. 卡方分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id6">3.3. 极限理论</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id7">3.3.1. 马尔可夫和切比雪夫不等式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id8">3.3.2. 弱大数定律</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id9">3.3.3. 依概率收敛</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-clt">3.3.4. 中心极限定理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id11">3.3.5. 强大数定理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id12">3.4. 似然估计量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id13">3.4.1. 估计量的偏差与方差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-2-fisher-information">3.4.2. 信息量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-2-mle-estimator">3.4.3. 最大似然估计的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-influence-test-interval">3.5. 置信区间</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#z">3.5.1. 均值参数的 Z 区间估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id18">3.5.2. 均值参数的 T 区间估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id19">3.5.3. 方差参数的区间估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-influence-test-test">3.6. 简单假设检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id22">3.6.1. Z检验</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id23">3.6.2. T检验</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id24">3.6.3. 卡方检验</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%97%8F/content.html">4. 指数族</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%97%8F/content.html#ch-24-1">4.1. 指数族的定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id3">4.1.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id4">4.1.2. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id5">4.1.3. 泊松分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id6">4.1.4. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id7">4.1.5. 其它常见指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%97%8F/content.html#ch-24-moments">4.2. 指数族的期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id9">4.3. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%97%8F/content.html#kl">4.4. 最大似然估计与KL散度的关系</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html">5. 线性回归模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id2">5.1. 最小二乘</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id3">5.1.1. 最小误差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id4">5.1.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id5">5.2. 线性回归的概率解释</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id6">5.2.1. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id7">5.2.2. 参数估计</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html">6. 广义线性模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id2">6.1. 指数族分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id3">6.1.1. 自然指数族</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id4">6.1.2. 示例：高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id5">6.1.3. 示例：伯努利分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id6">6.2. 广义线性模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id7">6.3. 例子</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html">7. 参数估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#ch-glm-estimate">7.1. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id3">7.2. 泰勒级数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id4">7.3. 梯度下降法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id6">7.4. 牛顿法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id7">7.4.1. 算法推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id8">7.4.2. 标准连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id9">7.4.3. 迭代初始值的设定</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#irls">7.5. 迭代重加权最小二乘(IRLS)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id10">7.5.1. 算法推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id11">7.5.2. 算法过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id12">7.6. 估计量的标准误差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#ch-glm-estimate-phi">7.7. 分散参数的估计</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html">8. 模型评估</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#id2">8.1. 拟合优度</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#id3">8.1.1. 嵌套模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#likelihood-ratio">8.1.2. 对数似然比(Likelihood ratio)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#deviance">8.1.3. 偏差(deviance)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#r-2">8.1.4. 决定系数 <span class="math notranslate nohighlight">\(R^2\)</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#ch-glm-gof-chi">8.1.5. 广义皮尔逊卡方统计量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#residual-analysis">8.2. 残差分析(Residual analysis)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#response-residuals">8.2.1. Response residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#working-residuals">8.2.2. Working residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#partial-residuals">8.2.3. Partial residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#pearson-residuals">8.2.4. Pearson residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#deviance-residuals">8.2.5. Deviance residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#score-residuals">8.2.6. Score residuals</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#model-selection">8.3. 模型选择(model selection)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#aic">8.3.1. AIC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/content.html#bic">8.3.2. BIC</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html">9. 模型检验</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id2">9.1. 拉格朗日乘子检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id3">9.1.1. 得分统计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id4">9.1.2. 检验过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#wald">9.2. wald 检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id5">9.2.1. 参数估计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id6">9.2.2. 检验过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id7">9.3. 似然比检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id8">9.3.1. 抽样分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id9">9.3.2. 模型比较</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id10">9.3.3. 偏差统计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#f">9.3.4. F 检验</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/influence.html#id11">9.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html">10. 高斯模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id2">10.1. 传统线性回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id3">10.2. 高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id4">10.3. 高斯回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id5">10.4. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id6">10.4.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#irls">10.4.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id7">10.4.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id10">10.5. 其它连接函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html">11. 逆高斯模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id2">11.1. 逆高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id3">11.2. 逆高斯回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id4">11.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id5">11.3.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#irls">11.3.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id6">11.3.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id7">11.4. 其它连接函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html">12. 二项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id2">12.1. 伯努利分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id3">12.2. 逻辑回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id4">12.2.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id5">12.2.2. 参数估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#odds-logit">12.2.3. odds 与 logit</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id6">12.3. 二项式分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id7">12.4. 二项式回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id8">12.4.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id9">12.4.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id10">12.5. 其它连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id11">12.5.1. 恒等连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#probit">12.5.2. probit 回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#log-log-clog-log">12.5.3. log-log 和 clog-log</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id12">12.6. 分组数据与比例数据</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html">13. 泊松模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#poisson">13.1. 泊松(Poisson)分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id2">13.1.1. 推导过程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id3">13.1.2. 泊松分布的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id5">13.2. 泊松回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id6">13.3. 参数估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id7">13.4. 拟合统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id8">13.5. 频率模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id9">13.6. 泊松模型的局限性</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html">14. 指数模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#exponential">14.1. 指数(exponential)分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id2">14.1.1. 推导过程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id3">14.1.2. 分布的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id6">14.2. 指数回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id7">14.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id8">14.3.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id9">14.3.2. 拟合优度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#irls">14.3.3. IRLS</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/gamma%E6%A8%A1%E5%9E%8B/content.html">15. Gamma 模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/gamma%E6%A8%A1%E5%9E%8B/content.html#id1">15.1. Gamma 函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/gamma%E6%A8%A1%E5%9E%8B/content.html#id2">15.2. Gamma 分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/gamma%E6%A8%A1%E5%9E%8B/content.html#id3">15.3. Gamma 回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/gamma%E6%A8%A1%E5%9E%8B/content.html#id4">15.4. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/gamma%E6%A8%A1%E5%9E%8B/content.html#id5">15.4.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/gamma%E6%A8%A1%E5%9E%8B/content.html#irls">15.4.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/gamma%E6%A8%A1%E5%9E%8B/content.html#id6">15.4.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/gamma%E6%A8%A1%E5%9E%8B/content.html#id7">15.5. 其他连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/gamma%E6%A8%A1%E5%9E%8B/content.html#id8">15.5.1. 对数 Gamma 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/gamma%E6%A8%A1%E5%9E%8B/content.html#identity-gamma">15.5.2. 恒等(identity) Gamma 模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html">16. 过度分散</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id2">16.1. 什么是过度分散</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id3">16.2. 过度分散的检测</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id4">16.3. 过度分散的影响</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id5">16.4. 标准误差的修正</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html">17. 负二项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id2">17.1. 负二项式分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id3">17.1.1. 从二项式分布推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id4">17.1.2. 泊松-伽马混合分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#alpha">17.1.3. 辅助参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的影响</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id5">17.2. 负二项回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id6">17.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#irls">17.3.1. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id7">17.3.2. 参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id8">17.4. 负二项式模型扩展</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id9">17.4.1. 对数连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id10">17.4.2. 参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id11">17.4.3. 几何模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id12">17.4.4. 广义负二项式模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html">18. 零计数问题</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id2">18.1. 零截断模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id3">18.1.1. 零截断泊松模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id4">18.1.2. 零截断负二项式模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id5">18.2. 零膨胀模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#hurdle">18.2.1. Hurdle 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#zero-inflate">18.2.2. Zero-inflate 模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html">19. 多项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id2">19.1. 类别分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#softmax">19.2. softmax 回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id3">19.2.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id4">19.2.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id5">19.3. 多项式分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id6">19.4. 多项式回归模型</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html">20. 有序离散模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id2">20.1. 有序逻辑回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id3">20.2. 参数估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id4">20.3. 连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#logit">20.3.1. logit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#probit">20.3.2. probit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#clog-log">20.3.3. clog-log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#log-log">20.3.4. log-log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../glm/source/%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#cauchit">20.3.5. cauchit</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id5">20.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html">附录</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html#id2">标准正态累积分布表</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/source/%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html#id3">卡方分布临界值表</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../glm/source/%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/content.html">参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../probability_model/index_html.html">概率图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html">1. 概率基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id2">1.1. 概率分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id3">1.2. 独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#marginalization">1.3. 边缘化(marginalization)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id6">1.4. 贝叶斯定理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id7">1.5. 期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id8">1.6. 常见概率分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id9">1.6.1. 离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id10">1.6.2. 连续变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id11">1.6.3. 计数变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id12">1.7. 大数定律</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id13">1.7.1. 独立同分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id14">1.7.2. 中心极限定理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id15">1.8. 信息论基础</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id16">1.8.1. 信息熵</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#kl">1.8.2. KL散度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id18">1.8.3. 互信息</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html">2. 参数估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-liklihood">2.1. 极大似然估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id3">2.1.1. 二值离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id4">2.1.2. 一般离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-2-gaussian-ml">2.1.3. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id6">2.1.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-bayesian-estimation">2.2. 贝叶斯估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id8">2.2.1. 伯努利变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id9">2.2.2. 类别变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id10">2.3. 最大后验估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id11">2.3.1. 伯努利变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id12">2.3.2. 类别变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id13">2.4. 最大似然估计与贝叶斯估计的对比</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id14">2.5. 统计量和充分统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#fisher-information">2.6. Fisher Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id15">2.7. 估计量的评价</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id16">2.7.1. 估计量的方差与偏差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id17">2.7.2. 大数定律和中心极限定理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-2-mle-estimator">2.7.3. 最大似然估计的特性</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html">3. 指数族</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#ch-24-1">3.1. 指数族的定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id3">3.1.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id4">3.1.2. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id5">3.1.3. 泊松分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id6">3.1.4. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id7">3.1.5. 其它常见指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#ch-24-moments">3.2. 指数族的期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id9">3.3. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#kl">3.4. 最大似然估计与KL散度的关系</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/19.%E5%A4%9A%E7%BB%B4%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83_26.html">4. 多维高斯分布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html">5. 有向图(Directed Graphical Models)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id1">5.1. 有向图</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id2">5.2. 条件独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id3">5.3. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html">6. 无向图(Undirected Graphical Models)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id1">6.1. 无向图的定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id2">6.2. 条件独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id3">6.3. 图的分解</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#vs">6.4. 有向图 vs 无向图</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id4">6.5. 树</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id5">6.6. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html">7. 因子图</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id2">7.1. 因子图的定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id3">7.2. 图模型之间的转换</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id4">7.2.1. 转换为因子图</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id5">7.2.2. 因子图转换为有向图</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id6">7.3. 图模型的评价</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#i-map">7.3.1. I-map</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#d-map">7.3.2. D-map</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#p-map">7.3.3. P-map</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html">8. 模型推断：消元法</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id2">8.1. 什么是模型的推断</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id3">8.2. 消元法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id4">8.2.1. 有向图消元算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#ch-condition-margin">8.2.2. 条件概率和边缘概率</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id6">8.2.3. 无向图的消元法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id7">8.3. 图消除</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95.html#id9">8.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html">9. 加和乘积算法(sum-product algorithm)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id1">9.1. 树结构</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id2">9.2. 从消元法到信息传播</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id3">9.3. 树模型的和积算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id4">9.4. 因子图的和积算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id5">9.5. 类树结构图模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#polytrees">9.6. 多重树(polytrees)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id6">9.7. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html">10. 最大后验估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id2">10.1. 最大后验概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id3">10.2. 最大化后验的状态</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id4">10.3. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html">11. 完整观测的参数学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id2">11.1. 有向图的参数学习</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id3">11.2. 无向图的参数学习</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id4">11.2.1. 成对二值变量模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id5">11.2.2. 一般二值变量模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html">12. 不完整观测的学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html#id2">12.1. 隐变量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html#em">12.2. 期望最大化算法(EM)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/14.%E5%9B%BE%E5%BD%A2%E7%BB%93%E6%9E%84%E7%9A%84%E5%AD%A6%E4%B9%A0_lecture_23.html">13. 有向图结构学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/16.%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD_lecture_17.html">14. 变分推断</a></li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html">15. 马尔科夫蒙特卡洛</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#why-sampling">15.1. Why sampling？</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#monte-carlo">15.2. 蒙特卡罗(Monte Carlo)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#markov-chain">15.3. 马尔科夫链(Markov Chain)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id2">15.3.1. 一个例子</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#time-reversibility">15.3.2. 时间可逆性(Time Reversibility)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id3">15.3.3. 总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#markov-chain-monte-carlo">15.4. Markov Chain Monte Carlo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#metropolis-hastings">15.4.1. Metropolis-Hastings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id4">15.4.2. 例子：正态分布的采样</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id5">15.4.3. 多变量采样</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#gibbs">15.4.4. Gibbs 采样</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#mixing-time">15.5. Mixing Time</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#approximate-map-and-partitioning">15.6. Approximate MAP and Partitioning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html">16. 贝叶斯分类器</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id2">16.1. 朴素贝叶斯模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id3">16.1.1. 模型表示</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id4">16.1.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id5">16.2. 高斯判别模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id6">16.2.1. 一元高斯模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id7">16.2.2. 多元高斯模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id8">16.3. 逻辑回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id9">16.4. 生成模型和判别模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id10">16.5. 多分类</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8.html#id11">16.6. 其它扩展</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html">17. 回归模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id2">17.1. 机器学习的概率解释</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id3">17.2. 经典线性回归</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id4">17.2.1. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id5">17.3. 线性回归的概率解释</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id6">17.3.1. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id7">17.4. 凸函数最优化问题</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id8">17.5. 岭回归</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html">18. 分类模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id2">18.1. 生成模型与判别模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id3">18.2. 线性回归与线性分类</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id4">18.3. 生成模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id5">18.3.1. 高斯判别模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id6">18.3.2. 朴素贝叶斯模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id7">18.3.3. 指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id8">18.4. 判别模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id9">18.4.1. 逻辑回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id10">18.4.2. 多分类</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id11">18.4.3. 最大熵模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#probit">18.4.4. Probit 回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#noisy-or">18.4.5. Noisy-OR 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id12">18.4.6. 其它指数模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html">19. 广义线性模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id2">19.1. 定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id3">19.1.1. 指数族分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id4">19.1.2. 链接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id5">19.1.3. 例子</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id6">19.2. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id7">19.2.1. 梯度下降法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id8">19.2.2. 牛顿法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#irls">19.2.3. 迭代重加权最小二乘(IRLS)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#goodness-of-fit">19.3. goodness of fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id9">19.4. 连续值响应模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id10">19.4.1. 高斯族</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#gamma">19.4.2. Gamma族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id12">19.5. 二项响应模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id13">19.6. 多项响应模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id14">19.7. 计数响应模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id15">19.7.1. 泊松分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id16">19.8. GLM扩展</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html">20. 混合模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id2">20.1. 一般混合模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id3">20.1.1. 模型的有向图表示</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id4">20.1.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id7">20.2. 高斯混合模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id8">20.2.1. 模型的表示</a></li>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id9">20.2.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#k-means">20.3. K-means</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/32.%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90_42.html">21. 因子分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/%E4%BA%8C%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B.html">22. 二变量模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/33.LDA_43.html">23. 主题模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/33.LDA_43.html#plsa">23.1. PLSA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/33.LDA_43.html#lda">23.2. LDA</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html">24. 隐马尔可夫模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id2">24.1. 隐马尔可夫模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id3">24.1.1. 马尔可夫模型和朴素贝叶斯模型的关系</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id4">24.2. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/27.%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA_37.html">25. 条件随机场</a></li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/28.%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%99%A8_38.html">26. 卡尔曼滤波器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/40.%E9%A1%B9%E7%9B%AE%E5%8F%8D%E5%BA%94%E7%90%86%E8%AE%BA_50.html">27. 项目反应理论</a></li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/41.%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA_51.html">28. 贝叶斯知识追踪</a></li>
<li class="toctree-l2"><a class="reference internal" href="../probability_model/%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE.html">29. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">语音技术</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">1. 音频特征</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">1.1. 认识声音</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">1.2. 认识声波</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id4">1.2.1. 物体的振动以及简谐振动</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id7">1.2.2. 什么是声波</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">1.2.3. 纯音和复合音</a></li>
<li class="toctree-l4"><a class="reference internal" href="#spectrum">1.2.4. 频谱 Spectrum</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id10">1.2.5. 名词</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id13">1.3. 语音学</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id14">1.3.1. 发声原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id15">1.3.2. 听觉感应</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id16">1.4. 数字信号处理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id17">1.4.1. 模数转换</a></li>
<li class="toctree-l4"><a class="reference internal" href="#wav">1.4.2. 音频文件–WAV</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id18">1.5. 分帧与加窗</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id19">1.5.1. 预加重处理</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id20">1.5.2. 分帧与加窗处理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id21">1.6. 声音的感官度量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#sound-pressure-level-spl">1.6.1. 声压与声压级(Sound Pressure Level,SPL)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#intensity-level-il">1.6.2. 声强与声强级(Intensity Level,IL）</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id22">1.6.3. 声压与声强的关系</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id23">1.6.4. 响度</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id24">1.6.5. 音量计算</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id25">1.6.6. 频率与音高</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id26">1.7. 时域分析</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id27">1.7.1. 短时能量</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id28">1.7.2. 短时平均幅度</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id29">1.7.3. 短时过零率</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id31">1.8. 频域分析</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#spectrum-spectrogram">1.8.1. 声谱(spectrum)和时频谱(spectrogram)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#short-time-fourier-transform-stft">1.8.2. 短时傅里叶变换 Short-time Fourier transform (STFT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id33">1.8.3. 倒频谱</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id34">1.8.4. 色谱图</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id35">1.9. 小波域特征</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id36">1.9.1. 离散小波域变换</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id37">1.9.2. 小波域过零率</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id38">1.9.3. 小波域质心</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id39">1.9.4. 小波域子带能量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#mfcc">1.10. 语音识别的音频特征–MFCC</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id40">1.11. 参考资料</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../edm/index.html">教育领域数据挖掘</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../edm/bkt.html">1. 贝叶斯知识追踪(Bayesian Knowledge Tracing,BKT)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../edm/bkt.html#id1">1.1. 简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="../edm/bkt.html#hidden-markov-model-hmm">1.2. 隐马尔科夫模型(Hidden Markov Model,HMM)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../edm/bkt.html#bayesian-knowledge-tracing">1.3. 贝叶斯知识追踪(Bayesian Knowledge Tracing)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../edm/bkt.html#bkt">1.3.1. BKT的参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../edm/bkt.html#item-response-theory-irt">1.4. 项目反映理论(Item Response Theory,IRT)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../edm/bkt.html#bktirt">1.5. BKT结合IRT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../edm/bkt.html#id5">1.6. 实验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../edm/bkt.html#id6">1.6.1. 数据集</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edm/bkt.html#id7">1.6.2. 实验方法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edm/bkt.html#id8">1.6.3. 实验结果</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edm/bkt.html#id9">1.6.4. 项目代码</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../edm/bkt.html#id10">1.7. 未来工作</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../edm/bkt.html#id11">1.7.1. 题目难度的计算</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edm/bkt.html#irt">1.7.2. 多参数IRT模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edm/bkt.html#id12">1.7.3. 参数估计算法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../edm/bkt.html#id13">1.8. 参考文献</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../nlp/index.html">自然语言处理</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html">1. 文本去重</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id2">1.1. 背景</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id3">1.2. 技术思路</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id4">1.3. 相似（距离）算法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#euclidean-distance">1.3.1. 欧氏距离（Euclidean Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#minkowski-distance">1.3.2. 闵科夫斯基距离（Minkowski Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#manhattan-distance">1.3.3. 曼哈顿距离（Manhattan Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#chebyshev-distance">1.3.4. 切比雪夫距离（Chebyshev Distance ）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#mahalanobis-distance">1.3.5. 马氏距离(Mahalanobis Distance)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#cosine-similarity">1.3.6. 余弦夹角相似度(Cosine Similarity)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#hamming-distance">1.3.7. 汉明距离（Hamming Distance）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#jaccard">1.3.8. Jaccard 系数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id5">1.3.9. 编辑距离</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id6">1.3.10. 最长公共字串</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id7">1.3.11. 最长公共子序列</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id8">1.4. 文本去重</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#kshingle">1.4.1. KShingle算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#minhash">1.4.2. Minhash算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#simhash">1.4.3. simhash</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#ksentence">1.4.4. KSentence算法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../nlp/%E6%96%87%E6%9C%AC%E5%8E%BB%E9%87%8D/content.html#id9">1.5. 话术去重</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nlp/bert/content.html">2. Attention&amp;Transformer&amp;Bert 简介</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nlp/bert/content.html#transformer">2.1. Transformer 从宏观到微观</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../nlp/bert/content.html#seq2seq">2.1.1. seq2seq</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/bert/content.html#id1">2.1.2. 模型的输入</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../nlp/bert/content.html#self-attention">2.2. Self-Attention</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../nlp/bert/content.html#id2">2.2.1. 什么是注意力？</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/bert/content.html#id3">2.2.2. 加权求和</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/bert/content.html#id4">2.2.3. 位置编码</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nlp/bert/content.html#multi-head">2.2.4. 多头注意力（Multi-head）</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../nlp/bert/content.html#attention">2.3. Attention 机制</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nlp/bert/content.html#id5">2.4. 其它参考资料</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../rst_tutorial/latex.html">latex demo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../rst_tutorial/latex.html#latex">latex</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../rst_tutorial/latex.html#how-to-write-an-m-x-n-matrix-in-latex">How to write an m x n matrix in LaTeX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../rst_tutorial/latex.html#with-big-parentheses">With big parentheses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../rst_tutorial/latex.html#with-parentheses">With parentheses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../rst_tutorial/latex.html#with-brackets">With brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../rst_tutorial/latex.html#latex-matrix-with-no-bracket">LateX matrix with no bracket</a></li>
<li class="toctree-l4"><a class="reference internal" href="../rst_tutorial/latex.html#with-vertical-bar-brackets">With vertical bar brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../rst_tutorial/latex.html#with-curly-brackets">with curly brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../rst_tutorial/latex.html#with-double-vertical-bar-brackets">with double vertical bar brackets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../rst_tutorial/latex.html#small-inline-matrix">small inline matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../rst_tutorial/latex.html#examples-matrix-2-x-2-in-latex">Examples matrix 2 x 2 in LaTeX</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../rst_tutorial/graphviz.html">graphviz demo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../rst_tutorial/graphviz.html#id1">布局</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rst_tutorial/graphviz.html#id2">其它</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/index.html">读书笔记</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/index.html">《统计因果推断推理入门》读书笔记</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html">1. 第三章 干预的效果</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html#id2">1.1. 第3.1节 干预</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html#id3">1.2. 第3.2节 校正公式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD%E6%8E%A8%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AB%A0.html#id8">1.3. 第3.3节 后门准则</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html">《深度学习推荐系统》读书笔记</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id2">重点</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id3">冷启动</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id4">探索与利用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#id5">召回层的主要策略</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/content.html#embedding">协同过滤 &amp; Embedding 向量</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">张振虎的博客</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">语音技术</a> &raquo;</li>
      <li><span class="section-number">1. </span>音频特征</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/audio/feature.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1><span class="section-number">1. </span>音频特征<a class="headerlink" href="#id1" title="永久链接至标题"></a></h1>
<section id="id2">
<h2><span class="section-number">1.1. </span>认识声音<a class="headerlink" href="#id2" title="永久链接至标题"></a></h2>
<p>中学时，我们学过声音是由物体的 <strong>振动</strong> 产生的。
物体振动时激励着它周围的空气质点振动，由于空气具有可压缩性，
在质点的相互作用下，振动物体四周的空气就交替地产生压缩与膨胀，并且逐渐向外传播，从而形成声波。</p>
<img alt="https://pic2.zhimg.com/80/fba827f8709a8e6d78a2776d5c6d0e05_hd.jpg" src="https://pic2.zhimg.com/80/fba827f8709a8e6d78a2776d5c6d0e05_hd.jpg" />
<figure class="align-default">
<img alt="../_images/1.gif" src="../_images/1.gif" />
</figure>
<p>当空气的这种波动传递到人耳时，人耳感受到的 <strong>气压的变化</strong> ，也就感受到了声音。</p>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>声音的传播其实就是声源(振动物体)的振动，传导到其周围的其他物质（比如空气粒子），形成扩散，直到传到人耳器官，人感受到声音。
这也就是为什么声音无法在真空中传播的原因。</p>
</div>
<p><strong>声波传播方式不是物质的移动，而是能量的传播</strong> 。也就是说 <strong>质点并不随声波向前扩散</strong> ，而仅在其原来的平衡位置附近振动，靠质点之间的相互作用影响到邻近的质点振动，因此，振动得以向四周传播，形成波动。</p>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>质点振动方向平行于传播方向的波，称为纵波。质点振动方向垂直于波传播方向的波，称为横波。</p>
</div>
<p>声波在空气中传播时只能发生压缩与膨胀，空气质点的振动方向与声波的传播方向是一致的，所以空气中的声波是纵波。
声波在液体中传播一般也为纵波，但在固体中传播则既有纵波又有横波。</p>
<dl class="field-list simple">
<dt class="field-odd">声波对气压的影响</dt>
<dd class="field-odd"><p></p></dd>
</dl>
<p>空气中无任何质点波动时，存在大气压，也就是静压强 <span class="math notranslate nohighlight">\(P_{atm}\)</span>，而当物体振动时，
必然导致振动物体附近的空气压强发生变化，产生压强波动 <span class="math notranslate nohighlight">\(P_{var}\)</span>，也就是说声波导致的压强波动是叠加在大气压之上的，即</p>
<div class="math notranslate nohighlight" id="equation-audio-feature-0">
<span class="eqno">(1.1.15)<a class="headerlink" href="#equation-audio-feature-0" title="公式的永久链接"></a></span>\[P_{total}=P_{atm}+P_{var}\]</div>
<p>而 <span class="math notranslate nohighlight">\(P_{atm}=1.01325×105Pa\)</span> 。</p>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>人耳感受到的声音大小其实就是气压大小，气压越大，对人耳产生的压力越大，人感受到的声音越响亮。</p>
</div>
<figure class="align-center" id="id41">
<img alt="../_images/640.png" src="../_images/640.png" />
<figcaption>
<p><span class="caption-number">图 1.1.1 </span><span class="caption-text">图片来源网络</span><a class="headerlink" href="#id41" title="永久链接至图片"></a></p>
</figcaption>
</figure>
<p>通常说来，声波可以在弹性媒介中传播，如空气、液体和固体等，但不能在真空中传播。
弹性介质中粒子的运动产生任何振动行为（如振动的平板，扬声器等）都可以当成一个声源。
振动的粒子的前后运动使介质产生交替的按正弦变化的稠密（C）和稀疏（R）部分，如下图所示。产生的压力波在介质中以速度c进行传播。</p>
<figure class="align-center" id="id42">
<img alt="../_images/2.gif" src="../_images/2.gif" />
<figcaption>
<p><span class="caption-number">图 1.1.2 </span><span class="caption-text">图片来源网络</span><a class="headerlink" href="#id42" title="永久链接至图片"></a></p>
</figcaption>
</figure>
<p>声波的传播速度c（m/s）依赖于弹性介质的物理特性，通常是</p>
<div class="math notranslate nohighlight" id="equation-audio-feature-1">
<span class="eqno">(1.1.16)<a class="headerlink" href="#equation-audio-feature-1" title="公式的永久链接"></a></span>\[c_{\text{固体}}&gt;c_{\text{液体}}&gt;c_{\text{气体}}\]</div>
</section>
<section id="id3">
<h2><span class="section-number">1.2. </span>认识声波<a class="headerlink" href="#id3" title="永久链接至标题"></a></h2>
<p>上文说道，声音是有物体的振动产生的。但物体究竟是如何振动的呢？产生的声波又是什么样的呢？</p>
<section id="id4">
<h3><span class="section-number">1.2.1. </span>物体的振动以及简谐振动<a class="headerlink" href="#id4" title="永久链接至标题"></a></h3>
<div class="topic">
<p class="topic-title">振动</p>
<p>振动（英语：vibration），指一个物体相对于静止参照物或处于平衡状态的物体的往复运动。
一般来说振动的基础是一个系统在两个能量形式间的能量转换，
振动可以是周期性的（如单摆）或随机性的（如轮胎在碎石路上的运动）。</p>
<p>来自：<a class="reference external" href="https://zh.wikipedia.org/wiki/%E6%8C%AF%E5%8A%A8">维基百科:振动</a></p>
</div>
<div class="topic">
<p class="topic-title">简谐振动（Simple harmonic motion)</p>
<p>简谐运动，或称简谐振动、谐振、SHM（Simple Harmonic Motion），即是最基本也是最简单的一种机械振动。
当某物体进行简谐运动时，物体所受的力跟位移成正比，并且力总是指向平衡位置。</p>
<p>来自：<a class="reference external" href="https://zh.wikipedia.org/wiki/%E7%B0%A1%E8%AB%A7%E9%81%8B%E5%8B%95">维基百科:简谐运动</a></p>
</div>
<p>比如下图中的弹簧运动就是简谐振动</p>
<figure class="align-default">
<img alt="https://upload.wikimedia.org/wikipedia/commons/9/9d/Simple_harmonic_oscillator.gif" src="https://upload.wikimedia.org/wikipedia/commons/9/9d/Simple_harmonic_oscillator.gif" />
</figure>
<p>其位移随时间变化的曲线就是正弦曲线。</p>
<figure class="align-default">
<img alt="https://upload.wikimedia.org/wikipedia/commons/b/b9/Harmonische_Schwingung_2.png" src="https://upload.wikimedia.org/wikipedia/commons/b/b9/Harmonische_Schwingung_2.png" />
</figure>
<p>又比如钟摆运动</p>
<figure class="align-default">
<img alt="../_images/955618dd59b057094ba31f2bf1b0b226_hd.jpg" src="../_images/955618dd59b057094ba31f2bf1b0b226_hd.jpg" />
</figure>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>简谐振动只是一种理想状态，现实下运动物体会受到阻尼影响，如果没有持续的动力支撑，会慢慢衰减。</p>
<figure class="align-default">
<a class="reference internal image-reference" href="https://upload.wikimedia.org/wikipedia/commons/2/2b/Damped_spring.gif"><img alt="https://upload.wikimedia.org/wikipedia/commons/2/2b/Damped_spring.gif" src="https://upload.wikimedia.org/wikipedia/commons/2/2b/Damped_spring.gif" style="height: 150px;" /></a>
</figure>
<figure class="align-default">
<a class="reference internal image-reference" href="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Damped_oscillation_graph.svg/496px-Damped_oscillation_graph.svg.png"><img alt="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Damped_oscillation_graph.svg/496px-Damped_oscillation_graph.svg.png" src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Damped_oscillation_graph.svg/496px-Damped_oscillation_graph.svg.png" style="width: 200px; height: 150px;" /></a>
</figure>
</div>
<div class="admonition important">
<p class="admonition-title">重要</p>
<p>简谐振动是周期性的，产生的是正弦曲线。非简谐运动产生的不是正弦曲线。</p>
</div>
<p><strong>正弦曲线的数学表示：</strong></p>
<figure class="align-center">
<img alt="../_images/3.png" src="../_images/3.png" />
</figure>
<div class="math notranslate nohighlight" id="equation-audio-feature-2">
<span class="eqno">(1.2.10)<a class="headerlink" href="#equation-audio-feature-2" title="公式的永久链接"></a></span>\[A(t) = A_0 sin(2\pi ft+\theta) =  A_0 sin(2\pi\frac{t}{T}+\theta)\]</div>
<p>其中，</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(A_0\)</span> ：振幅，振动幅值，也就是曲线的最大值(绝对值)。</p></li>
<li><p>T: 周期，完成一次循环所需要的时间。</p></li>
<li><p>f：频率，每秒钟的循环次数，也等于1/T，T（周期，单位是时间）为完成一个振动循环所需要的时间；</p></li>
<li><p>θ：初相位，0时刻，波形的起始位置（角度），  <span class="math notranslate nohighlight">\([0,2\pi]\)</span> 之间。</p></li>
</ul>
<p>正弦曲线也可以看做是圆周运动在y轴上的 <strong>投影</strong> 。</p>
<figure class="align-default">
<img alt="../_images/81ca9447d6c45c162c2d76df75a6690a_hd.jpg" src="../_images/81ca9447d6c45c162c2d76df75a6690a_hd.jpg" />
</figure>
<p>圆周的半径是振幅A，一次圆周运动的时间是周期T，0时刻起始位置和横轴的夹角是初相位 <span class="math notranslate nohighlight">\(\theta\)</span></p>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>正弦曲线和余弦曲线是一样的，只是相位差了90度。所以下文中除非特别说明，否则我们默认都是正弦曲线。</p>
</div>
</section>
<section id="id7">
<h3><span class="section-number">1.2.2. </span>什么是声波<a class="headerlink" href="#id7" title="永久链接至标题"></a></h3>
<p>声音是由物体振动产生的，物体振动会影响介质（通常是空气）的压力变换，并在介质中传播，这种传播成为 <strong>声波</strong> 。</p>
<p>观测传播介质（空气）中一个点的压力随时间变化，就得到了声波。</p>
<figure class="align-default">
<img alt="http://www.physicsclassroom.com/Class/sound/u11l1c1.gif" src="http://www.physicsclassroom.com/Class/sound/u11l1c1.gif" />
</figure>
<figure class="align-default">
<img alt="http://www.physicsclassroom.com/Class/sound/u11l1c2.gif" src="http://www.physicsclassroom.com/Class/sound/u11l1c2.gif" />
</figure>
<p>我们观测声波传播路径上任意一个点，测量这个点的气压随时间的变化，这样就变成了横轴为时间，纵轴为压力变化的图像.</p>
<p>声波是由物体的振动引起的，所以声波也是一种正弦波。对于声波可以用正弦函数描述。</p>
<figure class="align-default">
<img alt="http://www.physicsclassroom.com/mmedia/waves/edl.gif" src="http://www.physicsclassroom.com/mmedia/waves/edl.gif" />
</figure>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>简谐振动产生的正弦曲线的纵坐标是位移变化。然后声波的曲线其纵轴不是位移，而是压力。</p>
</div>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>当空气中没有声波时，也是存在气压的。气压距离标准值偏差越大，说明振动越剧烈，响度越大，所以振幅越大的波形表示声音越大。</p>
<ul class="simple">
<li><p>纵坐标是压力，单位是Pa，<strong>0值</strong> 实际是标准大气压，上文我们讲过，声波的能量是叠加在大气压之上的。</p></li>
<li><p>波长，一个时间周期（振动周期）内，传播的距离</p></li>
</ul>
</div>
<p>波形越紧密说明单位时间内振动的次数越多，频率越高，音高越高。</p>
<p>人和动物既可作为发声的声源，也可作为接受声音的接受者，但当作为声源和接受者时，二者的频率范围是不相同的，如下表所示。作为声源时频率范围较窄，而作为接受者时频率范围较宽</p>
<figure class="align-default">
<img alt="../_images/v2-bd9dd4c4bcf3275f7b66b77bc03114a6_hd.jpg" src="../_images/v2-bd9dd4c4bcf3275f7b66b77bc03114a6_hd.jpg" />
</figure>
</section>
<section id="id8">
<h3><span class="section-number">1.2.3. </span>纯音和复合音<a class="headerlink" href="#id8" title="永久链接至标题"></a></h3>
<p>相应于振动，声波也分为周期性声波和非周期性声波，最简单的周期声波是单频的声波，也称为纯音。
它是由简谐振动产生的频率固定、并按正弦变化的声波。与单频音相对应的是复合声，复合声（也称为复声）是由一些频率不同的单频音组成，</p>
<p>维基百科的定义</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>纯音(pure tone)在声学中指声压的时间波形为正弦函数的声音。
单一频率的声音，其瞬时值为与时间有关的正弦（余弦）函数表示的一简单声波。
</pre></div>
</div>
<p>理论上声源物体进行简谐振动产生的声音就是纯音。</p>
<p>声波分简单和复杂两种形式。由单一频率的正弦波产生的声音是纯音,如音叉 的声音，纯音是最简单、最单一的振动所产生的声波。
物理学上用频率和振幅两 个特征来说明纯音的性质。
复杂的波形是由若干个不同质的纯音融合而成。不同 频率和振幅的纯音相混合而成的声音称为复合音。</p>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>现实世界中，纯音几乎是不存在的，一般需要人工产生。</p>
</div>
<p>生成纯音的代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">librosa.output</span> <span class="kn">import</span> <span class="n">write_wav</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Audio</span>
<span class="kn">import</span> <span class="nn">soundfile</span> <span class="k">as</span> <span class="nn">sf</span>

<span class="k">def</span> <span class="nf">wave</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span><span class="n">f</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">time</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">fs</span><span class="o">=</span><span class="mi">44000</span><span class="p">,</span><span class="n">theta</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    生成制定参数的正弦波纯音数据</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    A: 幅值</span>
<span class="sd">    f: 声波频率</span>
<span class="sd">    fs: 采样率</span>
<span class="sd">    theta: 相位</span>
<span class="sd">    time: 声波时长，单位秒</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">t</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">time</span><span class="p">,</span><span class="n">time</span><span class="o">*</span><span class="n">fs</span><span class="p">)</span>
    <span class="n">y</span><span class="o">=</span><span class="n">A</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">f</span><span class="o">*</span><span class="n">t</span><span class="o">+</span><span class="n">theta</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span><span class="p">,</span><span class="n">fs</span>


<span class="k">def</span> <span class="nf">make_wav_file</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">A</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    生成wav音频文件</span>
<span class="sd">    :param f: 频率</span>
<span class="sd">    :param A: 幅值</span>
<span class="sd">    :return:</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">fs</span> <span class="o">=</span> <span class="n">wave</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="n">A</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">)</span>
    <span class="c1"># 在 jupyter 中可以如下语句显示音频</span>
    <span class="c1"># Audio(data=y,rate=fs)</span>

    <span class="c1"># 保存到文件中</span>
    <span class="n">wav_name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">Hz_</span><span class="si">%s</span><span class="s1">Pa.wav&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
    <span class="c1"># 注意浏览器播放不支持浮点型的PCM，所以我们保存成 &quot;PCM_16&quot;</span>
    <span class="n">sf</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="n">wav_name</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">samplerate</span><span class="o">=</span><span class="n">fs</span><span class="p">,</span> <span class="n">subtype</span><span class="o">=</span><span class="s2">&quot;PCM_16&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>生成音频文件</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 生成5HZ的纯音</span>
<span class="n">make_wav_file</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">A</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># 生成20HZ的纯音</span>
<span class="n">make_wav_file</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">A</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># 生成50HZ的纯音</span>
<span class="n">make_wav_file</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">A</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># 生成500HZ的纯音</span>
<span class="n">make_wav_file</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span><span class="n">A</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># 生成5000HZ的纯音</span>
<span class="n">make_wav_file</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span><span class="n">A</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># 生成50000HZ的纯音</span>
<span class="n">make_wav_file</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span><span class="n">A</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>
</div>
<p>各种纯音试听</p>
<h5>频率为50Hz的纯音</h5>
<audio controls><source src="../_static/wave/50Hz_1.0Pa.wav" type="audio/wav"></audio>

<h5>频率为500Hz的纯音</h5>
<audio controls><source src="../_static/wave/500Hz_1.0Pa.wav" type="audio/wav"></audio>

<h5>频率为5000Hz的纯音</h5>
<audio controls><source src="../_static/wave/5000Hz_1.0Pa.wav" type="audio/wav"></audio><p><strong>但是现实世界中，纯音几乎是不存在的</strong></p>
<div class="topic">
<p class="topic-title">疑问？</p>
<p>产生正弦波的声音是纯音，那么非正弦波的声音是什么？</p>
</div>
<p>现实当中，每时每刻都有很多个物体发声振动，产生声波。每个声音的频率、幅值、持续时间都是不同的。
我们听到的声音往往是很多的频率的叠加，比如这样。</p>
<img alt="../_images/54f2520de9eac31a8199a3a1d75c9d50_hd.jpg" src="../_images/54f2520de9eac31a8199a3a1d75c9d50_hd.jpg" />
<p>百度百科的描述</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>复合音：由基音和泛音结合在一起形成的声音，叫做复合音。
复合音的产生是根据物体振动时，不仅整体在振动，它的部分同时也在振动，
因此，平时所听到的声音，都不只是一个声音，而是由许多个声音组合而成的，于是便产生了复合音。
试在钢琴上弹一较低的音，用心聆听，不难发现，除了最响的音之外，还有一些非常弱的声音同时在响，
这就是全弦的振动和弦的部分振动所产生的结果。
</pre></div>
</div>
<p>简单来说就是很多 <strong>声音（不一定是纯音）</strong> 混合在一起就变成了复合音。不同声音的声波叠加到一起就形成复合音的声波。</p>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>注意，声波未必是周期性的</p>
</div>
<div class="admonition tip">
<p class="admonition-title">小技巧</p>
<p>人发出的语音声音是复合声音。</p>
</div>
</section>
<section id="spectrum">
<h3><span class="section-number">1.2.4. </span>频谱 Spectrum<a class="headerlink" href="#spectrum" title="永久链接至标题"></a></h3>
<p>上文说道，声波是正弦波，可以用正弦函数表示，并且声波是可以叠加的，我们看下多个正弦曲线是如何叠加的。</p>
<figure class="align-default">
<img alt="../_images/波形叠加.gif" src="../_images/波形叠加.gif" />
</figure>
<figure class="align-default">
<img alt="https://upload.wikimedia.org/wikipedia/commons/7/7e/Fourier_series_sawtooth_wave_circles_animation.gif" src="https://upload.wikimedia.org/wikipedia/commons/7/7e/Fourier_series_sawtooth_wave_circles_animation.gif" />
</figure>
<div class="topic">
<p class="topic-title">TODO</p>
<p>多个纯音叠加到一起的案例</p>
</div>
<p>既然声波可以叠加到一起，那能否把一段复合声音还原（分解）成原来的多个声音成分呢？</p>
<div class="topic">
<p class="topic-title">傅里叶变换</p>
<p>傅立叶是一位法国数学家和物理学家的名字，英语原名是 Jean Baptiste Joseph Fourier(1768-1830),
Fourier 对热传递很感兴趣，于 1807 年在法国科学学会上发表了一篇论文，运用正弦曲线来描述温度分布，
论文里有个在当时具有争议 性的决断:任何连续周期信号可以由一组适当的正弦曲线组合而成。当时审查这个论文的人，
其中有两位是历史上著名的数学家拉格朗日(Joseph Louis Lagrange, 1736-1813)和拉普拉斯 (Pierre Simon de Laplace, 1749-1827)，
当拉普拉斯和其它审查者投票通过并要发表这个论文 时，拉格朗日坚决反对，在近 50 年的时间里，
拉格朗日坚持认为傅立叶的方法无法表示带有棱角的信号，如在方波中出现非连续变化斜率。法国科学学会屈服于拉格朗日的威望，拒 绝了傅立叶的工作，幸运的是，傅立叶还有其它事情可忙，他参加了政治运动，随拿破仑远 征埃及，法国大革命后因会被推上断头台而一直在逃避。直到拉格朗日死后 15 年这个论文 才被发表出来。</p>
<p>谁是对的呢?拉格朗日是对的:正弦曲线无法组合成一个带有棱角的信号。</p>
<p>但是，我们可以用正弦曲线来非常逼近地表示它，逼近到两种表示方法不存在能量差别，基于此，傅立叶是对的。</p>
<dl class="field-list simple">
<dt class="field-odd">傅里叶变换</dt>
<dd class="field-odd"><p>就是把一段信号分解成一系列不同频率、振幅、相位的正弦信号。对时域信号作傅立叶变换，得到的直接结果即为频谱Spectrum。</p>
</dd>
</dl>
</div>
<figure class="align-default">
<img alt="https://upload.wikimedia.org/wikipedia/commons/2/2b/Fourier_series_and_transform.gif" src="https://upload.wikimedia.org/wikipedia/commons/2/2b/Fourier_series_and_transform.gif" />
</figure>
<p>任何 <strong>周期</strong> 函数，都可以看作是不同振幅，不同相位正弦波的叠加。</p>
<img alt="../_images/40cf849e55ed95732a60b52d4019d609_hd.jpg" src="../_images/40cf849e55ed95732a60b52d4019d609_hd.jpg" />
<p>我们知道，一个正弦信号的全部信息由它的频率、幅度以及初相位这三个参数来决定，也即，
知道了一个正弦信号的“三参数”也就知道了这个正弦信号的所有信息。
而一个复杂信号是由频率不同、幅度不同、初相位不同的许多正弦信号叠加而成的。</p>
<div class="topic">
<p class="topic-title">信号频谱</p>
<p>信号的频谱就是表示组成一个复杂信号的所有不同频率正弦信号的“三参数”，
换句话说，频谱表示了组成这个复杂信号的所有不同频率的正弦信号的“三参数”信息。</p>
</div>
<p>也就是说，人们用频谱把组成一个复杂信号的所有不同频率的正弦信号的参数都表示了出来。
反过来，我们可以通过信号频谱知道这个复杂信号包含哪些频率的正弦信号，以及这些正弦信号的幅度和初相位，</p>
<p>某个频率正弦的幅度大小代表了这个频率正弦信号对原信号的贡献程度，所以，知道了信号频谱也就知道了这个信号含有的哪些频率成分，这个信号的特性也就知道了，
这对于信号分析、传输（通信）以及信号处理具有决定性的作用。
通常，频谱的形式有两种，一种是图形（也称频谱图，从频谱图上可以看到不同频率正弦信号的“三参数”），另一种是函数式。</p>
<img alt="../_images/cd3ea5ecbd446054ace4b9859870e4d8_hd.jpg" src="../_images/cd3ea5ecbd446054ace4b9859870e4d8_hd.jpg" />
<p>通过对波形数据的傅里叶变换，把波形中的每个频率拆开来，再在纵轴上展开，越往上频率越高。
频谱是三维的，越亮表示在这个频率上越响(振幅大)，越暗表示越弱。</p>
<p>所以频谱相对于波形图，是包含有更多信息的，唯一的缺点就是无法表示整体音量总和的大小，所以一般和波形配合观看。</p>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>如两个单频信号幅值和频率相同，但相位相反，那么，当对这两个信号进行平均时，那么，它们的幅值将为0。
在汽车排气系统中，有一种主动消音机制，就是先接收声音，然后将声音反相回放回去，从而达到消音的目的，
利用的就是这个原理。</p>
<figure class="align-default">
<img alt="../_images/6a8f58f7a37efe769dba075c2816d994_hd.jpg" src="../_images/6a8f58f7a37efe769dba075c2816d994_hd.jpg" />
</figure>
<p>对于已经抵消了正弦信号，傅里叶变换是无法还原的。原因不需要解释吧！！！</p>
</div>
<div class="admonition tip">
<p class="admonition-title">小技巧</p>
<ul class="simple">
<li><p>更加通俗易懂的理解傅里叶变换的讲解，请阅读： <a class="reference external" href="https://zhuanlan.zhihu.com/p/19763358">傅里叶分析之掐死教程（完整版）</a></p></li>
<li><p>从技术层面介绍傅里叶变换的操作原理，请阅读：  <a class="reference download internal" download="" href="../_downloads/e629cb860f9737f236d7f4c34c24a462/FFT%E7%9A%84%E7%90%86%E8%A7%A3.pdf"><code class="xref download docutils literal notranslate"><span class="pre">FFT的理解</span></code></a></p></li>
</ul>
</div>
<p>对时域信号作傅立叶变换，得到的直接结果即为频谱Spectrum。它是复数，复数的实部和虚部分别保存幅值和相位信息。
同时显示同一频谱的幅值和相位的图形称为波德图(bode)，如下图所示。</p>
<img alt="../_images/cfcbddbfd80c3f2023cb6fd43184f0f3_hd.jpg" src="../_images/cfcbddbfd80c3f2023cb6fd43184f0f3_hd.jpg" />
</section>
<section id="id10">
<h3><span class="section-number">1.2.5. </span>名词<a class="headerlink" href="#id10" title="永久链接至标题"></a></h3>
<section id="id11">
<h4><span class="section-number">1.2.5.1. </span>频率–基频–音高<a class="headerlink" href="#id11" title="永久链接至标题"></a></h4>
<p>单位时间内(每秒)物体振动的次数，称为“频率”，用 f 表示，单位为赫兹。物体振动越快，频率就越高;物体振动越慢，频率就越低。</p>
<p>物体振动一周所 经历的时间，称为“周期”，记作 T，单位为秒。周期与频率之间具有以下关系: T=1/f。</p>
<p>在一个自然的复合音里，有一个振幅最大、频率最低的分音，也就是第一谐波，这个分音(或第一谐波)一般还被称为“基音”，它的振动频率被称为“基频”。
但对于人工合成的声音或者通过滤波处理后的声音(如过滤掉一些低频成分)，其基频并不等于第一谐波的频率。
例如，一个 300 赫兹的纯音与一个 400 赫兹的纯音叠加时，会产生一个复合波，
这个复合波就包括两个分音，其频率分别等于 300 赫兹和 400 赫兹，第一谐波的频率为 300 赫兹，
这个复合波的基频并不等于 300 赫兹，而是等于 100 赫兹。</p>
<p>音高是人耳对物体振动频率的听觉感受,其高低主要决定于声波频率。一般来说，振动频率越高，感受到的音高也越高;振动频率越低，感受到的音高也越低。
对复合波音高的感知，主要决定于基频。一般来说，女同志的音高比男的高，童声的音高比成人高。</p>
</section>
<section id="id12">
<h4><span class="section-number">1.2.5.2. </span>基音–陪音–谐波–分音–泛音<a class="headerlink" href="#id12" title="永久链接至标题"></a></h4>
<p>一个复合音是由多个频率不同的纯音组成的，
通过一定的方法可以把复合音 分解为一定数目的纯音，这些被分解出来的纯音在物理学上被称为“分音”，
在 电声学上被称为“谐波”。其中，那个振幅最大、频率最低的分音，被称为“基 音”，也被称为“第一谐波”;
其他分音的振幅一般都比基音的振幅小，而频率 都是基音的整数倍，这些音被称为“陪音”，在音乐中也被称为“泛音”。</p>
</section>
</section>
</section>
<section id="id13">
<h2><span class="section-number">1.3. </span>语音学<a class="headerlink" href="#id13" title="永久链接至标题"></a></h2>
<section id="id14">
<h3><span class="section-number">1.3.1. </span>发声原理<a class="headerlink" href="#id14" title="永久链接至标题"></a></h3>
</section>
<section id="id15">
<h3><span class="section-number">1.3.2. </span>听觉感应<a class="headerlink" href="#id15" title="永久链接至标题"></a></h3>
</section>
</section>
<section id="id16">
<h2><span class="section-number">1.4. </span>数字信号处理<a class="headerlink" href="#id16" title="永久链接至标题"></a></h2>
<p>对于人类的语音信号而言，实际处理一般经过以下步骤：</p>
<p>人嘴说话——&gt;声电转换——&gt;采样（模数转换）——&gt;量化（将数字信号用适当的数值表示）——&gt;编码（数据压缩）——&gt;
传输（网络或者其他方式）
——&gt;解码（数据还原）——&gt;反采样（数模转换）——&gt;电声转换——&gt;人耳听声。</p>
<section id="id17">
<h3><span class="section-number">1.4.1. </span>模数转换<a class="headerlink" href="#id17" title="永久链接至标题"></a></h3>
<p>麦克风设备感受空气压力变化，并且把压力转换成电信号，这里电信号也就是模拟信号，随时间连续变化的电信号。
然后需要把模拟信号转换成计算机的数字信号。</p>
<p><strong>模拟信号</strong> 到 <strong>数字信号转换</strong> (analog-to-digital conversion,A/D转化，模数转换)的过程分为两步：</p>
<ul class="simple">
<li><p>采样/抽样 sampling</p></li>
<li><p>量化 quantization</p></li>
</ul>
<p>声波是时间上的连续变化，而计算机只能处理离散数据，是无法记录和处理连续值的。
解决方法就是每隔固定时间（很短）从记录当前波形的幅值并记录下，就把连续值进行了离散化，这个过程就是抽样，每秒钟采集的样本点数称为采样率。</p>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>电脑中的声音文件是用数字0和1来表示的。
所以在电脑上录音的本质就是把模拟声音信号转换成数字信号。
反之，在播放时则是把数字信号还原成模拟声音信号输出。</p>
</div>
<figure class="align-default">
<img alt="../_images/2239910-bf5220a5229bc71b.png" src="../_images/2239910-bf5220a5229bc71b.png" />
</figure>
<dl class="field-list simple">
<dt class="field-odd">采样率</dt>
<dd class="field-odd"><p></p></dd>
</dl>
<p>采样率（也称为采样速度或者采样频率）定义了每秒从连续信号中提取并组成离散信号的采样个数，它用赫兹（Hz）来表示。
采样频率的倒数叫作采样周期或采样时间，它是采样之间的时间间隔。
采样定理指采样频率必须大于被采样信号带宽的两倍，另外一种等同的说法是奈奎斯特频率必须大于被采样信号的带宽。</p>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>采样频率必须至少是声波频率的两倍才可以，也就是一个声波周期内需要至少采集到两个点，才能还原这个声波，采集的点数越多还原的越精准。</p>
<p>人的说话频率基本上为300Hz-3400Hz，但是人耳朵听觉频率基本上为20Hz-20000Hz。</p>
<p>采样频率越高声音的还原就越真实越自然。 在当今的主流采集卡上，
采样频率一般共分为22.05KHz、44.1KHz、48KHz三个等级，22.05KHz只能达到FM广播的声音品质，
44.1KHz则是理论上的CD音质界限，48KHz则更加精确一些。</p>
</div>
<div class="topic">
<p class="topic-title">量化</p>
<p>把实数值表示为整数的过程为 <strong>量化(quantization)</strong> 。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">量化位数</dt>
<dd class="field-odd"><p></p></dd>
</dl>
<p>声音采集卡通过采集到声波幅值是实数值，这个实数值是某个区间内[-m,m]之间的连续值，通过采样得到一个个离散的点，
但这些离散点的值是实数值，需要把实数值数转换成整数，整数再转换成二进制进行存储，存储二进制时的位数就是量化位数。
比如用10位(10bit)、16位（16bit）、20位(20bit)、24位(24bit)、32位(32bit)等等进行存储。</p>
<p>实数值转换为离散值的方法就是，把实数区间[-m,m]（无穷个值）映射到一个整型区间[-n,n]（加上0，一共有2n+1个值），
实数区间[-m,m]分割成2n+1个子区间，对应子区间的整数作为映射输出值。</p>
<p>整型数的位数多少影响着保存数据的精度，位数越多能存储整数区间也就越大，能表示的实数精度就越高，录制和回放的声音就越真实。</p>
<p>通常市面上是这样说，16bit/24bit/32bit。数值越高声音越好。位数多少决定了n的大小（空间大小）。</p>
<p>比如：</p>
<ul class="simple">
<li><p>16bit位宽，n值为 <span class="math notranslate nohighlight">\(2^{15}-1=32767\)</span> (为什么是15而不是16？因为有一位是符号位。为什么减1，因为去掉0),32767 代表最大幅值；</p></li>
<li><p>32bit位宽，n值为 <span class="math notranslate nohighlight">\(2^{31}-1=2147483647\)</span> ，2147483647代表最大幅值。</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p><strong>重点来了！！！！</strong> ，32767 和 2147483647 都代表最大幅值，两者对应幅值是一样的。 也就是说不同采样音频数据的幅值不可比较。</p>
<p>位宽越大，精度越高，声音的音质越好。与声音大小（幅值大小）无关！！！！</p>
<p>个人理解：实数值转整数，也是一种采样离散化。采样时时间维度的离散化，量化是振幅的离散化。</p>
</div>
</section>
<section id="wav">
<h3><span class="section-number">1.4.2. </span>音频文件–WAV<a class="headerlink" href="#wav" title="永久链接至标题"></a></h3>
<div class="topic">
<p class="topic-title">PCM</p>
<p>脉冲编码调制（英文：Pulse-code modulation，缩写：PCM）是一种模拟信号的数字化方法。
PCM将信号的强度依照同样的间距分成数段，然后用独特的数字记号（通常是二进制）来量化。</p>
<p>– 维基百科</p>
</div>
<p>PCM就是上一节说的模数转换，其得到的结果就是声波数据的采样数据，是一个整数序列，每个整数表示声波的振幅值。
由于采样率比较大，一般每秒几万个点，所以PCM数据是比较大。实际应用中往往会对其进行压缩，比如MP3等等，就是对PCM的一种压缩后的结果。</p>
<div class="topic">
<p class="topic-title">音频压缩</p>
<p>音频压缩（区别于动态压缩）属于数据压缩的一种，用以减少音频流媒体的传输带宽需求与音频档案的存储大小。按压缩方法可以分为无损压缩和有损压缩。</p>
</div>
<p>得到音频采样的整数数据序列后，就需要存储在一个文件中，最常用的文件格式是WAV。</p>
<div class="topic">
<p class="topic-title">WAV</p>
<p>WAV(Waveform Audio File Format) 是一种文件格式，是微软与IBM公司所开发在个人计算机存储音频流的编码格式。
固定长度的文件头+PCM音量数据流 组成一个wav文件存储在计算机中。</p>
</div>
<p>文件头中记录着pcm音频流的一些信息，比如采样率、量化位数、声道数等等。</p>
<figure class="align-default">
<img alt="https://upload.wikimedia.org/wikipedia/commons/8/8c/Wave_format.png" src="https://upload.wikimedia.org/wikipedia/commons/8/8c/Wave_format.png" />
</figure>
<p>利用python查看一个wav文件的信息：</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">soundfile</span> <span class="k">as</span> <span class="nn">sf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sf</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;wave/比较平缓.wav&quot;</span><span class="p">)</span>
<span class="go">samplerate: 44100 Hz  # PCM采样率</span>
<span class="go">channels: 1  # 声道数</span>
<span class="go">duration: 31.299 s  # 音频时长是31.299秒</span>
<span class="go">format: WAV (Microsoft) [WAV]  # 文件格式</span>
<span class="go">subtype: Signed 16 bit PCM [PCM_16] # 有符号16bit整型数据</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">声道 channel</dt>
<dd class="field-odd"><p>一个音频文件wave是可以同时存储过个pcm音频流的，如果只有一个音频流就称为单声道，两个称为立体声（包含左声道和右声道）。
当然一般情况下，两个音频流应该是两个不同的采集卡同时采集得到的结果。</p>
</dd>
</dl>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="p">,</span><span class="n">sr</span><span class="o">=</span><span class="n">sf</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="s2">&quot;wave/比较平缓.wav&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># 样本数据的长度</span>
<span class="go">(1380288,)</span>
<span class="go">&gt;&gt;&gt;sr # 采样率</span>
<span class="go">44100</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span> <span class="c1"># 前10个样本点</span>
<span class="go">array([ 0,  1,  2,  1,  0,  0, -2, -2, -2, -3], dtype=int16)</span>
</pre></div>
</div>
</section>
</section>
<section id="id18">
<h2><span class="section-number">1.5. </span>分帧与加窗<a class="headerlink" href="#id18" title="永久链接至标题"></a></h2>
<section id="id19">
<h3><span class="section-number">1.5.1. </span>预加重处理<a class="headerlink" href="#id19" title="永久链接至标题"></a></h3>
</section>
<section id="id20">
<h3><span class="section-number">1.5.2. </span>分帧与加窗处理<a class="headerlink" href="#id20" title="永久链接至标题"></a></h3>
<p>我们已经知道采集到音频数据，是时间轴上的数据序列，声波随着之间变化，声波在整个时间轴上是 <strong>非周期性</strong> 的，这导致计算机很难处理。
但在一个很短的时间切片内（10ms-50ms），声波是可以近似看为周期性的。所以我们可以把长序列数据切片，每片称为一帧。</p>
<img alt="../_images/v2-55d8a7b5a55fe081cc778783d34d2b3a_hd.png" src="../_images/v2-55d8a7b5a55fe081cc778783d34d2b3a_hd.png" />
<p>那么一帧有多长呢？帧长要满足两个条件：</p>
<ul class="simple">
<li><p>从宏观上看，它必须足够短来保证帧内信号是平稳的。前面说过，口型的变化是导致信号不平稳的原因，所以在一帧的期间内口型不能有明显变化，即一帧的长度应当小于一个音素的长度。正常语速下，音素的持续时间大约是 50~200 毫秒，所以帧长一般取为小于 50 毫秒。</p></li>
<li><p>从微观上来看，它又必须包括足够多的振动周期，因为傅里叶变换是要分析频率的，只有重复足够多次才能分析频率。语音的基频，男声在 100 赫兹左右，女声在 200 赫兹左右，换算成周期就是 10 毫秒和 5 毫秒。既然一帧要包含多个周期，所以一般取至少 20 毫秒。</p></li>
</ul>
<p>这样，我们就知道了帧长一般取为 20 ~ 50 毫秒，20、25、30、40、50 都是比较常用的数值，
甚至还有人用 32（在程序猿眼里，这是一个比较「整」的数字）。</p>
<p>取出来的一帧信号，在做傅里叶变换之前，要先进行「加窗」的操作，即与一个「窗函数」相乘，
如下图所示：</p>
<img alt="../_images/v2-29273fde835815754c6e7369f463aa10_hd.png" src="../_images/v2-29273fde835815754c6e7369f463aa10_hd.png" />
<p>加窗的目的是让一帧信号的幅度在两端渐变到 0。渐变对傅里叶变换有好处，可以提高变换结果（即频谱）的分辨率，具体的数学就不讲了。
加窗的代价是一帧信号两端的部分被削弱了，没有像中央的部分那样得到重视。弥补的办法是，帧不要背靠背地截取，而是相互重叠一部分。</p>
<p>相邻两帧的起始位置的时间差叫做帧移，常见的取法是取为帧长的一半，或者固定取为 10 毫秒。</p>
<p>每次FFT变换只能对有限长度的时域数据进行变换，因此，需要对时域信号进行信号截断(分帧)。
即使是周期信号，如果截断的时间长度不是周期的整数倍（周期截断），那么，截取后的信号将会存在泄漏。
为了将这个泄漏误差减少到最小程度（注意我说是的减少，而不是消除），我们需要使用加权函数，也叫窗函数。
加窗主要是为了使时域信号似乎更好地满足FFT处理的周期性要求，减少泄漏。</p>
<p>如下图所示，若周期截断，则FFT频谱为单一谱线。若为非周期截断，则频谱出现拖尾，如图中部所示，可以看出泄漏很严重。
为了减少泄漏，给信号施加一个窗函数（如图中上部红色曲线所示），原始截断后的信号与这个窗函数相乘之后得到的信号为上面右侧的信号。
可以看出，此时，信号的起始时刻和结束时刻幅值都为0，也就是说在这个时间长度内，信号为周期信号，但是只有一个周期。
对这个信号做FFT分析，得到的频谱如下部右侧所示。相比较之前未加窗的频谱，可以看出，泄漏已明显改善，但并没有完全消除。
因此，窗函数只能减少泄漏，不能消除泄漏。</p>
<img alt="../_images/v2-6a1af003630e49911ec7399f1b6ee4b9_hd.jpg" src="../_images/v2-6a1af003630e49911ec7399f1b6ee4b9_hd.jpg" />
<p><strong>因此，加窗的目的是为了减少泄漏。但加窗不能消除泄漏，只能减少。</strong></p>
<p>常见窗口函数：</p>
<img alt="../_images/v2-7adfc1d5b6490b693b91d800c167673e_hd.jpg" src="../_images/v2-7adfc1d5b6490b693b91d800c167673e_hd.jpg" />
<p>矩形窗、汉宁窗和平顶窗的时域形状和频域特征如下图所示，可以看出，窗函数不同，时域和频域都是不同的。</p>
<img alt="../_images/v2-0416157f1938981f7e6dda7654e5ec7c_hd.jpg" src="../_images/v2-0416157f1938981f7e6dda7654e5ec7c_hd.jpg" />
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>关于加窗的更详细解释，请参见知乎文章： 什么是窗函数? <a class="reference external" href="https://zhuanlan.zhihu.com/p/24318554">https://zhuanlan.zhihu.com/p/24318554</a></p>
</div>
<p>对一帧信号做傅里叶变换，得到的结果叫频谱，
它就是下图中的蓝线：</p>
<img alt="../_images/v2-05197addda7c2019a388f5b7e9e94f04_hd.png" src="../_images/v2-05197addda7c2019a388f5b7e9e94f04_hd.png" />
<p>图中的横轴是频率，纵轴是幅度。</p>
<p>频谱上就能看出这帧语音在 480 和 580 赫兹附近的能量比较强。
语音的频谱，常常呈现出 <strong>「精细结构」</strong> 和 <strong>「包络」</strong> 两种模式。
<strong>「精细结构」</strong> 就是蓝线上的一个个小峰，它们在横轴上的间距就是基频，它体现了语音的音高——峰越稀疏，基频越高，音高也越高。
<strong>「包络」</strong> 则是连接这些小峰峰顶的平滑曲线（红线），它代表了口型，即发的是哪个音。
包络上的峰叫 <strong>共振峰</strong> ，图中能看出四个，分别在 500、1700、2450、3800 赫兹附近。
有经验的人，根据共振峰的位置，就能看出发的是什么音。
对每一帧信号都做这样的傅里叶变换，就可以知道音高和口型随时间的变化情况，也就能识别出一句话说的是什么了。</p>
<p>对于声音数据的分析，可以分为时域分析和频域分析。时域分析是指</p>
<p>语音信号的时域分析就是分析和提取语音信号的时域参数，也就是直接对波形进行处理。</p>
</section>
</section>
<section id="id21">
<h2><span class="section-number">1.6. </span>声音的感官度量<a class="headerlink" href="#id21" title="永久链接至标题"></a></h2>
<section id="sound-pressure-level-spl">
<h3><span class="section-number">1.6.1. </span>声压与声压级(Sound Pressure Level,SPL)<a class="headerlink" href="#sound-pressure-level-spl" title="永久链接至标题"></a></h3>
<p>声压是定量描述声波的最基本物理量，它是由生扰动产生的逾量压强，是空间位置和时间的函数。
由于声压的测量比较容易实现，而且通过声压的测量也可以间接求得质点振速等其它声学参量，
因此，声压已经成为人们最为普遍采用的定量描述声波性质的物理量。</p>
<p>通常讲声压指的是有效声压，即在一定时间间隔内将瞬时声压对时间求方均根值所得。</p>
<p>设语音长度为T，离散点数为N，则有效声压的计算公式为</p>
<div class="math notranslate nohighlight" id="equation-audio-feature-3">
<span class="eqno">(1.6.28)<a class="headerlink" href="#equation-audio-feature-3" title="公式的永久链接"></a></span>\[p_e = \sqrt{\frac{\sum_{i=1}^N x^2}{N}}\]</div>
<p>式中，x表示语音信号采样点的幅值。</p>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>上式中，x的值原意应该是声波的压力值。上文讲过声波信号数字化处理后，在计算机存储的音频文件中，x值代表的是声波的振幅。
当用振幅x计算上式时，得到的结果并不是真正的有效声压，仅仅是一种近似表示。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">声压级(Sound Pressure Level,SPL)</dt>
<dd class="field-odd"><p></p></dd>
</dl>
<p>声音的有效声压与基准声压之比，取以10为底的对数，再乘以20，即为声压级，通常以符号 <span class="math notranslate nohighlight">\(L_p\)</span> 表示，单位为分贝dB。</p>
<div class="topic">
<p class="topic-title">分贝
分贝是声级测量中最常用的单位，被简写为dB。其中小写的d代表英文decibel即分贝，而大写的B代表Bel即贝尔，
采用小写d和大写B主要说明分贝和贝尔之间的关系为1:10即1分贝等于十分之一贝尔。
需要说明的是，0dB并非代表完全静寂状态，而是代表人耳的听阈点，也就是听力正常的人所能觉察到的最低声压级。</p>
<p>——功率增加一倍代表增益提升3dB（如混音中，一轨声音为100dB，将这轨复制一份一同播放，总音量将为103dB，
而非100+100=200dB），而电压增加一倍代表增益提升6dB。</p>
</div>
<div class="math notranslate nohighlight" id="equation-audio-feature-4">
<span class="eqno">(1.6.29)<a class="headerlink" href="#equation-audio-feature-4" title="公式的永久链接"></a></span>\[L_p = 20 lg \frac{p_e}{p_{ref}}\]</div>
<p>式中， <span class="math notranslate nohighlight">\(p_e\)</span> 为待测声压的有效值； <span class="math notranslate nohighlight">\(p_{ref}\)</span> 为参考声压（一般是标准大气压）。</p>
</section>
<section id="intensity-level-il">
<h3><span class="section-number">1.6.2. </span>声强与声强级(Intensity Level,IL）<a class="headerlink" href="#intensity-level-il" title="永久链接至标题"></a></h3>
<p>在物理学中，声波在单位时间内作用在与传递方向垂直的单位面积上的能量称为声强。声强用I表示，单位为瓦/平米。</p>
<p>日常生活中能听到的声音其强度范围很大，最大和最小之间可大 <span class="math notranslate nohighlight">\(10^{12}\)</span> 倍。</p>
<p>心理物理学的研究表明，人对声音强弱的感觉并不是与声强成正比，而是与其对数成正比的。
当人耳听到两个强度不同的声音时，感觉的大小大致上与两个声强比值的对数成比例。
因此，用对数尺度来表示声音强度的等级，其单位为分贝(dB)。</p>
<div class="math notranslate nohighlight" id="equation-audio-feature-5">
<span class="eqno">(1.6.30)<a class="headerlink" href="#equation-audio-feature-5" title="公式的永久链接"></a></span>\[L_{I} = 10 lg(I/I_0)\]</div>
<p>在声学中用 <span class="math notranslate nohighlight">\(1x10^{-12} W/m^2\)</span> 作为参考声强( <span class="math notranslate nohighlight">\(I_0\)</span> )。</p>
</section>
<section id="id22">
<h3><span class="section-number">1.6.3. </span>声压与声强的关系<a class="headerlink" href="#id22" title="永久链接至标题"></a></h3>
<p>对于球面波和平面波，声压与声强的关系是</p>
<div class="math notranslate nohighlight" id="equation-audio-feature-6">
<span class="eqno">(1.6.31)<a class="headerlink" href="#equation-audio-feature-6" title="公式的永久链接"></a></span>\[I=P^2/ \rho \cdot c\]</div>
<p>式中， <span class="math notranslate nohighlight">\(\rho\)</span> 为空气密度; c 为声速。在标准大气压和 <span class="math notranslate nohighlight">\(20^oC\)</span> 的环境下， <span class="math notranslate nohighlight">\(\rho \cdot c =408\)</span> 。
该数值为国际单位值，也叫瑞利，称为空气对声波的特性阻抗。</p>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>声压反应的是压力，声强反应的是能量，如果忽略 <span class="math notranslate nohighlight">\(\rho \text{和} c\)</span>  ，二者就是平方关系。</p>
</div>
</section>
<section id="id23">
<h3><span class="section-number">1.6.4. </span>响度<a class="headerlink" href="#id23" title="永久链接至标题"></a></h3>
<div class="topic">
<p class="topic-title">响度</p>
<p>响度（loudness又称音响或音量），是与 <strong>声压级</strong> （中文维基百科这里写的是声强，应该是错误的，
英文词条里写的是 sound pressure level，SPL ）相对应的声音大小的感知量。声压级是客观的物理量，响度是主观的心理量。
响度不仅跟声强有关，还跟频率有关。</p>
<p>– 维基百科</p>
</div>
<p>响度描述的时声音的响亮程度，表示人耳对声音的主管感受，其计量单位是宋。 <strong>定义为声压级为40dB的1khz纯音的响度为1宋。</strong>
<strong>人耳对声音的感觉，不仅和声压有关，还和频率有关</strong> 。声压级相同，频率不同的声音，听起来响亮程度也不同。如空压机和电锯，同是100dB声压级的噪声，听起来电锯声要响的多。</p>
<p>按照人耳对声音的感觉特性，依据声压和频率定出人对声音的主观音响感觉量，称为响度级，单位为方，符号是phon。
根据国际协议规定，0dB声强级的1000Hz的纯音的响度级定义为0 phon。其他频率声音的声级与响度级的对应关系，要从等响度曲线才能查出。</p>
<figure class="align-default">
<img alt="https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Lindos1.svg/1024px-Lindos1.svg.png" src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Lindos1.svg/1024px-Lindos1.svg.png" />
</figure>
<div class="topic">
<p class="topic-title">关于响度的认识
虽然人而表现为声压敏感组织，但从人耳接受声波并对声波进行分析的方式来说，振幅因素和响度其实并没有直接的的关系。
例如空压机与电锯，同是100分贝声压级的噪声．听起来电锯声要响得多。很明显，人耳对于不同的信号频率存有不同的敏感度，
所以声波频率和声压或者说振幅是影响人耳对响度感知的两个主要因素。从心理声学角度考虑，人对响度的感觉除了上述两种之外，
还有来自于信号持续时间和对于临界带宽频率的控制的因素。通常，人对于一个声信号响度级的识别以200ms（毫秒，1000ms=1s）为界，
当信号的持续时间低于200ms的时候，持续时间越短，信号的响度越低。临界带宽频率控制这里不讲深，
可以简单理解成，相同声强的两个声音，频率越丰富的，人耳感觉到的响度越大。</p>
<p>从某种意义上说，提高响度的所有途经，均是为了激发更多的毛细胞，从而达到增加临界带宽数量的目的。</p>
</div>
</section>
<section id="id24">
<h3><span class="section-number">1.6.5. </span>音量计算<a class="headerlink" href="#id24" title="永久链接至标题"></a></h3>
<p>人耳感受声音强度的感知量是 <strong>响度</strong> ，响度受到声压和频率同时影响的。
但在实际的应用中，音频数据的频率是很难获得的，所以通常都是直接使用 <strong>声压级</strong> 来表示音量的大小。</p>
<p>但是计算声压级时是需要用有 <strong>效声压</strong> 除以 <strong>基准声压</strong> 的，基准声压表示的标准大气压。</p>
<p>我们仅有的是音频采样数据（振幅值），数据只是数据，只有经过音响设备播放出来才能产生实际声音（声压）。</p>
<p><strong>有效声压：</strong> ， 我们用音频采样的振幅值替代。</p>
<p><strong>基准声压：</strong> ， 基准声压就类似一个对比的基准线，把音频采样的振幅值归一化到[-1,1]之间即可，归一化的方法就是振幅除以采样位宽的最大值。</p>
<div class="math notranslate nohighlight" id="equation-audio-feature-7">
<span class="eqno">(1.6.32)<a class="headerlink" href="#equation-audio-feature-7" title="公式的永久链接"></a></span>\[volume=80 + 20lg \frac{\sum_{i=1}^N abs(x_i)}{N}\]</div>
<p>为什么没用平方，平方容易受到一些极大值点的影响，不够平稳。</p>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>利用音频采样计算的音量值，并不是实际的感知量响度，也不是物理量声压级，不能表示真实的声音大小，仅仅是一种相对值表示，其值本身没啥意义。</p>
</div>
</section>
<section id="id25">
<h3><span class="section-number">1.6.6. </span>频率与音高<a class="headerlink" href="#id25" title="永久链接至标题"></a></h3>
<p>物体在1秒内振动的次数叫频率。其单位是赫兹，简称赫，符号为Hz。物体振动得越快，频率越大。
频率是物理量，其对应的感知量是音高，即用人的主观感觉来评价所听到的是高调还是低调。
音调跟发声体振动的频率关系是：频率越大，音调越高；频率越小，音调越低。</p>
<p>美(Mel)，是心理声学测量音高的单位。1000美是1000Hz纯音40dB SL时的音高。
音调高的声波具有高美值，音调低的声波美值就低，但 <strong>不是线性关系</strong> 。例如，将1000Hz纯音的频率翻番至2000Hz，
其40dB的声音音高从1000Mel变成1500Mel，而不是2000Mel，如果要达到2000Mel，需要频率3000Hz。</p>
<div class="topic">
<p class="topic-title">总结</p>
<p>声音感知量和物理量之间不是线性关系。</p>
</div>
</section>
</section>
<section id="id26">
<h2><span class="section-number">1.7. </span>时域分析<a class="headerlink" href="#id26" title="永久链接至标题"></a></h2>
<p>语音信号的时域分析是指对语音波形执行直接的操作，而将频域信号处理定义为对语音信号的傅里叶表示执行操作。</p>
<p>短时的意思是对语音波形的一帧（短时间片段）进行操作。</p>
<section id="id27">
<h3><span class="section-number">1.7.1. </span>短时能量<a class="headerlink" href="#id27" title="永久链接至标题"></a></h3>
<dl class="field-list simple">
<dt class="field-odd">定义</dt>
<dd class="field-odd"><p>当前声音片段的能量大小。能量越大响度越大。</p>
</dd>
</dl>
<div class="math notranslate nohighlight" id="equation-audio-feature-8">
<span class="eqno">(1.7.3)<a class="headerlink" href="#equation-audio-feature-8" title="公式的永久链接"></a></span>\[E=\sum_{m=1}^N (x[m])^2\]</div>
</section>
<section id="id28">
<h3><span class="section-number">1.7.2. </span>短时平均幅度<a class="headerlink" href="#id28" title="永久链接至标题"></a></h3>
<dl class="field-list simple">
<dt class="field-odd">定义</dt>
<dd class="field-odd"><p>当前声音片段的平均幅度。</p>
</dd>
</dl>
<div class="math notranslate nohighlight" id="equation-audio-feature-9">
<span class="eqno">(1.7.4)<a class="headerlink" href="#equation-audio-feature-9" title="公式的永久链接"></a></span>\[M = \frac{1}{N} \sum_{m=1}^N |x[m]|\]</div>
</section>
<section id="id29">
<h3><span class="section-number">1.7.3. </span>短时过零率<a class="headerlink" href="#id29" title="永久链接至标题"></a></h3>
<dl class="field-list simple">
<dt class="field-odd">定义</dt>
<dd class="field-odd"><p></p></dd>
</dl>
<p>过零率体现的是信号过零点的次数，体现的是频率特性。因为需要过零点，所以信号处理之前需要中心化处理</p>
<dl class="field-list simple">
<dt class="field-odd">公式</dt>
<dd class="field-odd"><p></p></dd>
</dl>
<div class="math notranslate nohighlight" id="equation-audio-feature-10">
<span class="eqno">(1.7.5)<a class="headerlink" href="#equation-audio-feature-10" title="公式的永久链接"></a></span>\[ \begin{align}\begin{aligned}Z = \sum_{m=1}^N |sgn(x[m])-sgn(x[m-1])|\\\begin{split}sgn(x[m])=\left\{
\begin{aligned}
1 ,\  &amp; x[m] \ge 0 \\
-1,\   &amp; x[m] \lt 0 \\
\end{aligned}
\right.\end{split}\end{aligned}\end{align} \]</div>
<section id="id30">
<h4><span class="section-number">1.7.3.1. </span>短时自相关函数<a class="headerlink" href="#id30" title="永久链接至标题"></a></h4>
<p>省略</p>
</section>
</section>
</section>
<section id="id31">
<h2><span class="section-number">1.8. </span>频域分析<a class="headerlink" href="#id31" title="永久链接至标题"></a></h2>
<p>某些比较宽泛的语音特征（例如，能量、基音、浊音的出现、塞音的成阻、擦音，等等）可以直接从波形上来解释，但是，
在语音识别（以及人的听觉处理）等很多计算机应用中，要求对组成声音的频率做出不同的表示，并以此作为这些应用的基础。</p>
<p>傅里叶分析指出，每一个复杂波都可以表示为很多频率不同的正弦波的总和。</p>
<p>对一个时域信号进行傅里叶变换，就可以得到的信号的声谱（spectrum），信号的频谱由两部分构成：幅度谱和相位谱。</p>
<p>频域（frequency domain）是指在对函数或信号进行分析时，分析其和频率有关部分，而不是和时间有关的部分[1]，和时域一词相对。</p>
<p>一般是通过傅里叶变换把一段时序信号变成频域数据。</p>
<p>根据原信号的不同类型，我们可以把傅立叶变换分为四种类别:</p>
<ul class="simple">
<li><p>非周期性连续信号 – 傅立叶变换(Fourier Transform)</p></li>
<li><p>周期性连续信号 – 傅立叶级数(Fourier Series)</p></li>
<li><p>非周期性离散信号 – 离散时域傅立叶变换(Discrete Time Fourier Transform)</p></li>
<li><p>周期性离散信号 – 离散傅立叶变换(Discrete Fourier Transform)</p></li>
</ul>
<figure class="align-default">
<img alt="../_images/type_of_transform.png" src="../_images/type_of_transform.png" />
</figure>
<p>相关名词解释:</p>
<dl class="field-list simple">
<dt class="field-odd">FT（Fourier Transformation）</dt>
<dd class="field-odd"><p>傅里叶变换。就是我们理论上学的概念，但是对于连续的信号无法在计算机上使用。其时域信号和频域信号都是连续的。</p>
</dd>
<dt class="field-even">DTFT（Discrete-time Fourier Transform）</dt>
<dd class="field-even"><p>离散时间傅里叶变换。这里的“离散时间”指的是时域上式离散的，也就是计算机进行了采样。不过傅里叶变换后的结果依然是连续的。</p>
</dd>
<dt class="field-odd">DFT（Discrete Fourier Transform）</dt>
<dd class="field-odd"><p>离散傅里叶变换。在DTFT之后，将傅里叶变换的结果也进行离散化，就是DFT。</p>
</dd>
</dl>
<p>也就是说：FT时域连续、频域连续；DTFT时域离散、频域连续；DFT时域离散、频域离散。</p>
<dl class="field-list simple">
<dt class="field-odd">FFT（Fast Fourier Transformation）</dt>
<dd class="field-odd"><p>快速傅里叶变换。就是DFT的快速算法，一般工程应用时用的都是这种算法。</p>
</dd>
<dt class="field-even">FS（Fourier Series）</dt>
<dd class="field-even"><p>傅里叶级数。是针对时域连续周期信号提出的，结果是离散的频域结果。</p>
</dd>
<dt class="field-odd">DFS（Discrete Fourier Series）</dt>
<dd class="field-odd"><p>离散傅里叶级数。是针对时域离散周期信号提出的，DFS与DFT的本质是一样的。</p>
</dd>
</dl>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<ul class="simple">
<li><p>DFT 只能处理周期信号</p></li>
<li><p>快速傅里叶变换（FFT），它是一种用来计算DFT（离散傅里叶变换）和IDFT（离散傅里叶反变换）的一种快速算法。</p></li>
<li><p>随机信号是无法做傅里叶变换的。</p></li>
</ul>
</div>
<p>在用计算机处理音频信号时，我们使用的是 DFT（Discrete Fourier Transform）离散傅里叶变换，具体算法是 FFT（Fast Fourier Transformation）。
比如scipy和numpy都有提供相应的功能函数。</p>
<section id="spectrum-spectrogram">
<h3><span class="section-number">1.8.1. </span>声谱(spectrum)和时频谱(spectrogram)<a class="headerlink" href="#spectrum-spectrogram" title="永久链接至标题"></a></h3>
<p>声谱表示某一时刻（一帧语音信号）经过FFT得到的频率成分，其横轴是频率，纵轴是振幅（或者能量）。
而时频谱(spectrogram)表示这些不同的频率成分是如何使波形随着时间的改变而改变的，也就是把每帧的声谱(spectrum)拼接（按照时间轴）起来，
其横轴是时间，纵轴是频率，颜色深浅表示振幅（能量）</p>
<figure class="align-default">
<img alt="../_images/1160281-20181221224530922-479480973.png" src="../_images/1160281-20181221224530922-479480973.png" />
</figure>
<figure class="align-default">
<img alt="../_images/1160281-20181221224541923-1780314401.png" src="../_images/1160281-20181221224541923-1780314401.png" />
</figure>
<figure class="align-default">
<img alt="../_images/1160281-20181221224554397-162344585.png" src="../_images/1160281-20181221224554397-162344585.png" />
</figure>
<p>一段声音的声波和频谱示例</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">specshow</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">sr</span><span class="p">):</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">librosa</span><span class="o">.</span><span class="n">stft</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
    <span class="n">librosa</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">specshow</span><span class="p">(</span><span class="n">librosa</span><span class="o">.</span><span class="n">amplitude_to_db</span><span class="p">(</span><span class="n">D</span><span class="p">,</span><span class="n">ref</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">),</span><span class="n">y_axis</span><span class="o">=</span><span class="s1">&#39;hz&#39;</span><span class="p">,</span> <span class="n">x_axis</span><span class="o">=</span><span class="s1">&#39;time&#39;</span><span class="p">)</span>
    <span class="n">plot_wave</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span><span class="n">time</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">sr</span><span class="p">)</span>
    <span class="c1">#plt.figure(figsize=(30,10))</span>

<span class="n">y</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;wave/比较平缓.wav&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">Audio</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">rate</span><span class="o">=</span><span class="n">fs</span><span class="p">))</span>
<span class="n">specshow</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">sr</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="../_images/声波示例.png" src="../_images/声波示例.png" />
</figure>
<figure class="align-default">
<img alt="../_images/频谱示例.png" src="../_images/频谱示例.png" />
</figure>
<p>对时域信号进行傅立叶变换(FFT)时，
可以用多种不同的函数来表示计算结果，如频谱、自谱、功率谱密度等等，并且这些函数还有不同的格式，如Peak，RMS和Peak-Peak。
到底用哪个函数来表示更贴切，它们有什么区别呢？在讨论这些谱函数之前，让我们明确一下Peak，RMS和Peak-Peak的定义。</p>
<p>基频</p>
<p>共振峰</p>
<p>包络</p>
</section>
<section id="short-time-fourier-transform-stft">
<h3><span class="section-number">1.8.2. </span>短时傅里叶变换 Short-time Fourier transform (STFT)<a class="headerlink" href="#short-time-fourier-transform-stft" title="永久链接至标题"></a></h3>
<p>把音频的每一帧利用快速傅里叶变换FFT转化成频域数据。</p>
<p>时域信号-&gt;分帧-&gt;每一帧单独处理-&gt;加窗-&gt;FFT-&gt;频域结果（复数）-&gt;所有帧结果拼接成时间序列</p>
<img alt="../_images/20170301204438041.jpeg" src="../_images/20170301204438041.jpeg" />
<p>短时傅里叶变换Short-time Fourier transform (STFT)的代码过程</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">stft</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">n_fft</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">win_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="s1">&#39;hann&#39;</span><span class="p">,</span>
         <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">complex64</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;reflect&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Short-time Fourier transform (STFT)</span>

<span class="sd">    Returns a complex-valued 复数 matrix D such that</span>
<span class="sd">        幅度谱：`np.abs(D[f, t])` is the magnitude of frequency bin `f`</span>
<span class="sd">        at frame `t`</span>

<span class="sd">        相位谱：`np.angle(D[f, t])` is the phase of frequency bin `f`</span>
<span class="sd">        at frame `t`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y : np.ndarray [shape=(n,)], real-valued</span>
<span class="sd">        the input signal (audio time series)</span>

<span class="sd">    n_fft : int &gt; 0 [scalar]</span>
<span class="sd">        FFT window size</span>

<span class="sd">    hop_length : int &gt; 0 [scalar]</span>
<span class="sd">        帧（窗口）的重叠部分长度。默认是 `win_length / 4`</span>
<span class="sd">        number audio of frames between STFT columns.</span>
<span class="sd">        If unspecified, defaults `win_length / 4`.</span>

<span class="sd">    win_length  : int &lt;= n_fft [scalar]</span>
<span class="sd">        Each frame of audio is windowed by `window()`.</span>
<span class="sd">        The window will be of length `win_length` and then padded</span>
<span class="sd">        with zeros to match `n_fft`.</span>
<span class="sd">        时序数据分帧的帧长度，同时也是窗口函数的长度。</span>
<span class="sd">        If unspecified, defaults to ``win_length = n_fft``.</span>

<span class="sd">    window : string, tuple, number, function, or np.ndarray [shape=(n_fft,)]</span>
<span class="sd">        - a window specification (string, tuple, or number);</span>
<span class="sd">          see `scipy.signal.get_window`</span>
<span class="sd">        - a window function, such as `scipy.signal.hanning`</span>
<span class="sd">        - a vector or array of length `n_fft`</span>
<span class="sd">        窗口函数</span>
<span class="sd">        .. see also:: `filters.get_window`</span>

<span class="sd">    center      : boolean</span>
<span class="sd">        - If `True`, the signal `y` is padded so that frame</span>
<span class="sd">          `D[:, t]` is centered at `y[t * hop_length]`.</span>
<span class="sd">        - If `False`, then `D[:, t]` begins at `y[t * hop_length]`</span>

<span class="sd">    dtype       : numeric type</span>
<span class="sd">        Complex numeric type for `D`.  Default is 64-bit complex.</span>

<span class="sd">    pad_mode : string</span>
<span class="sd">        If `center=True`, the padding mode to use at the edges of the signal.</span>
<span class="sd">        By default, STFT uses reflection padding.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    D : np.ndarray [shape=(1 + n_fft/2, t), dtype=dtype]</span>
<span class="sd">        STFT matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># By default, use the entire frame</span>
    <span class="k">if</span> <span class="n">win_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">win_length</span> <span class="o">=</span> <span class="n">n_fft</span>

    <span class="c1"># Set the default hop, if it&#39;s not already specified</span>
    <span class="k">if</span> <span class="n">hop_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">hop_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">win_length</span> <span class="o">//</span> <span class="mi">4</span><span class="p">)</span>

    <span class="c1"># 获取窗口函数。其实是一个矩阵，用这个矩阵和原始帧数据相乘。</span>
    <span class="n">fft_window</span> <span class="o">=</span> <span class="n">get_window</span><span class="p">(</span><span class="n">window</span><span class="p">,</span> <span class="n">win_length</span><span class="p">,</span> <span class="n">fftbins</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Pad the window out to n_fft size</span>
    <span class="c1"># 窗口函数两端补0 令其长度等于n_fft</span>
    <span class="n">fft_window</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">pad_center</span><span class="p">(</span><span class="n">fft_window</span><span class="p">,</span> <span class="n">n_fft</span><span class="p">)</span>

    <span class="c1"># Reshape so that the window can be broadcast</span>
    <span class="c1"># reshape时 -1 代表这个维度保持原来的值不变</span>
    <span class="n">fft_window</span> <span class="o">=</span> <span class="n">fft_window</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Check audio is valid</span>
    <span class="n">util</span><span class="o">.</span><span class="n">valid_audio</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="c1"># Pad the time series so that frames are centered</span>
    <span class="k">if</span> <span class="n">center</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_fft</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="n">pad_mode</span><span class="p">)</span>

    <span class="c1"># Window the time series.</span>
    <span class="c1"># 对输入的时序数据进行分帧(窗)，每一帧的长度是n_fft</span>
    <span class="n">y_frames</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">frame_length</span><span class="o">=</span><span class="n">n_fft</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="n">hop_length</span><span class="p">)</span>

    <span class="c1"># Pre-allocate the STFT matrix</span>
    <span class="c1"># 提前申请好 用来保存STFT结果的矩阵 shape=(1 + n_fft // 2,帧的数量)</span>
    <span class="c1">#</span>
    <span class="n">stft_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">n_fft</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">y_frames</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                           <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                           <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)</span>

    <span class="c1"># how many columns can we fit within MAX_MEM_BLOCK?</span>
    <span class="n">n_columns</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">MAX_MEM_BLOCK</span> <span class="o">/</span> <span class="p">(</span><span class="n">stft_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span>
                                          <span class="n">stft_matrix</span><span class="o">.</span><span class="n">itemsize</span><span class="p">))</span>
    <span class="c1"># fft_window.shape = (n_fft,1)</span>
    <span class="c1"># 这个循环是批量算的，不是一帧一帧算，而是一次循环算n_columns帧</span>
    <span class="k">for</span> <span class="n">bl_s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">stft_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_columns</span><span class="p">):</span>
        <span class="n">bl_t</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">bl_s</span> <span class="o">+</span> <span class="n">n_columns</span><span class="p">,</span> <span class="n">stft_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># RFFT(实数FFT) and Conjugate here to match phase(相位) from DPWE code</span>
        <span class="c1"># fft用的是scipy.fftpack</span>
        <span class="n">stft_matrix</span><span class="p">[:,</span> <span class="n">bl_s</span><span class="p">:</span><span class="n">bl_t</span><span class="p">]</span> <span class="o">=</span> <span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">(</span><span class="n">fft_window</span> <span class="o">*</span>
                                            <span class="n">y_frames</span><span class="p">[:,</span> <span class="n">bl_s</span><span class="p">:</span><span class="n">bl_t</span><span class="p">],</span>
                                            <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[:</span><span class="n">stft_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

    <span class="k">return</span> <span class="n">stft_matrix</span>
</pre></div>
</div>
<p>对时序信号通过FFT处理后，得到的是复数矩阵D(shape=(频率区间，帧数量))，其中每个值是一个复数，形如 <span class="math notranslate nohighlight">\(D[f,t]=a+bj\)</span>  。
实数部分a代表当前频率f分支正弦信号的幅值，虚数部分b代表余弦信号的幅值。</p>
<p>通过对D进行运算可以分别得到幅度谱、相位谱、能量谱、功率谱。</p>
<dl class="field-list simple">
<dt class="field-odd">幅度谱</dt>
<dd class="field-odd"><p><cite>np.abs(D[f, t])</cite> is the magnitude of frequency bin <cite>f</cite>
at frame <cite>t</cite></p>
</dd>
<dt class="field-even">相位谱</dt>
<dd class="field-even"><p><cite>np.angle(D[f, t])</cite> is the phase of frequency bin <cite>f</cite>
at frame <cite>t</cite></p>
</dd>
<dt class="field-odd">能量谱</dt>
<dd class="field-odd"><p><cite>np.abs(D[f, t])**2</cite> is the power spectrum  of frequency bin <cite>f</cite>
at frame <cite>t</cite></p>
</dd>
<dt class="field-even">功率谱</dt>
<dd class="field-even"><p>xxxxx</p>
</dd>
</dl>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>复数的绝对值</p>
<p>复数的绝对值定义为：若 <span class="math notranslate nohighlight">\(z=a+bi\)</span> ，则 <span class="math notranslate nohighlight">\(|z|=\sqrt{a^2+b^2}\)</span> 。
其意义是复数的绝对值就是复数向量的模长，语音信号FFT的结果进行绝对值（求模）运算得到的时幅值。</p>
</div>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>如何得到D对应的频率值?</p>
<p>scipy.fftpack.fftfreq 和 numpy.fft.fftfreq 了解下。</p>
</div>
<p>要理解能量谱和功率谱，首先要弄明白能量有限信号和功率有限信号（参看之前的文章能量信号和功率信号的分别）。</p>
<p>能量谱也叫能量谱密度，能量谱密度描述了信号或时间序列的能量如何随频率分布。能量谱是原信号傅立叶变换的平方。</p>
<p>更多讨论可以参看： <a class="reference external" href="https://zhuanlan.zhihu.com/p/34989414">信号频域分析方法的理解（频谱、能量谱、功率谱、倒频谱、小波分析）</a></p>
</section>
<section id="id33">
<h3><span class="section-number">1.8.3. </span>倒频谱<a class="headerlink" href="#id33" title="永久链接至标题"></a></h3>
<p>倒频谱（Cepstrum）也叫倒谱、二次谱和对数功率谱等。倒频谱的工程型定义是：
<strong>信号功率谱对数值进行傅立叶逆变换的结果。（信号→求功率谱→求对数→求傅里叶逆变换）</strong></p>
<p>为什么翻译作倒频谱呢？我个人的理解是，频谱（功率谱）反应的频率特征点横坐标是频率f（Hz），在倒频谱中对应的特征点的横坐标是时间t（s），而f与t互为倒数。从这里也可以看出，虽然倒频谱也叫“频谱”，其横坐标却并不是频率，而是时间。</p>
<p>那么倒频谱有什么好处呢？</p>
<p>“该分析方法方便提取、分析原频谱图上肉眼难以识别的周期性信号，能将原来频谱图上成族的边频带谱线简化为单根谱线，受传感器的测点位置及传输途径的影响小。”
这都是啥意思？一条条解释：</p>
<p>1.方便提取、分析原频谱图上肉眼难以识别的周期性信号</p>
<p>我们知道，频谱分析就是为了提取原始信号中的周期性信号的，怎么频谱中的信号还会有周期性？这就又涉及到两个概念：调制和边频带。</p>
<p>调制分为幅值调制和频率调制。下面以齿轮的幅值调制为例进行说明：齿轮的振动信号主要包括两部分，分别是齿轮啮合振动信号（高频）和齿轮轴的转频振动信号（低频），时域和频域曲线分别如下图所示：</p>
<p>高频信号和低频信号时域波形</p>
<p>高频信号和低频信号的频域波形</p>
<p>调制就是高低频率信号的混合。幅值调制从数学上看，相当于两个信号在时域上相乘；而在频域上，相当于两个信号的卷积。调制后的信号在时域和频域上分别变为：</p>
<p>调制后的时域信号</p>
<p>调制后的频域信号</p>
<p>我们发现，调制后的信号中，除原来的啮合频率分量外，增加了一对分量，它们是以高频信号特征频率为中心，对称分布于两侧，所以称为边频带。</p>
<p>实际实验中齿轮啮合振动信号（高频）和齿轮轴的转频振动信号（低频）的特征频率可能是有多组的，其调制后的频域信号近似于一组频率间隔较大的脉冲函数和一组频率间隔较小的脉冲函数的卷积，从而在频谱上形成若干组围绕啮合频率及其倍频成分两侧的边频族，如下图：</p>
<p>边频带的形成</p>
<p>说了一大堆，终于回归到上边提到的问题：倒频谱“方便提取、分析原频谱图上肉眼难以识别的周期性信号”。这里指的周期性信号，就是重复出现的边频带。</p>
<p>倒频谱能较好地检测出功率谱上的周期成分，通常在功率谱上无法对边频的总体水平作出定量估计，而倒频谱对边频成分具有“概括”能力，能较明显地显示出功率谱上的周期成分，将原来谱上成族的边频带谱线简化为单根谱线，便于观察，而齿轮发生故障时的振动频谱具有的边频带一般都具有等间隔（故障频率）的结构，利用倒频谱这个优点，可以检测出功率谱中难以辨识的周期性信号。
2.受传感器的测点位置及传输途径的影响小</p>
<p>这是倒频谱的第二个好处。对于布置在不同位置的传感器，由于传递路径不同，其功率谱也不相同。但在倒频谱上，由于信号源的振动效应和传递途径的效应分离开来，代表齿轮振动特征的倒频率分量几乎完全相同，只是低倒频率段存在由于传递函数差异而产生的影响。在进行倒频谱分析时，可以不必考虑信号测取时的衰减和标定系数所带来的影响。这一优点对于故障识别极为有用。</p>
<p>关于倒频谱，文章 齿轮故障诊断常用信号分析处理方法 给出了具体了例子，方便理解。</p>
<p>自谱AutoPower
能量谱ESD
互谱CrossPower
频响函数FRF
相干函数</p>
<p><a class="reference external" href="https://zhuanlan.zhihu.com/p/22513006">https://zhuanlan.zhihu.com/p/22513006</a></p>
</section>
<section id="id34">
<h3><span class="section-number">1.8.4. </span>色谱图<a class="headerlink" href="#id34" title="永久链接至标题"></a></h3>
<p>librosa.feature.chroma_stft</p>
<p>色度特征是色度向量（Chroma Vector）和色度图谱（Chromagram）的统称。色度向量是一个含有12个元素的向量，
这些元素分别代表一段时间（如1帧）内12个音级中的能量，不同八度的同一音级能量累加，色度图谱则是色度向量的序列。</p>
</section>
</section>
<section id="id35">
<h2><span class="section-number">1.9. </span>小波域特征<a class="headerlink" href="#id35" title="永久链接至标题"></a></h2>
<section id="id36">
<h3><span class="section-number">1.9.1. </span>离散小波域变换<a class="headerlink" href="#id36" title="永久链接至标题"></a></h3>
</section>
<section id="id37">
<h3><span class="section-number">1.9.2. </span>小波域过零率<a class="headerlink" href="#id37" title="永久链接至标题"></a></h3>
</section>
<section id="id38">
<h3><span class="section-number">1.9.3. </span>小波域质心<a class="headerlink" href="#id38" title="永久链接至标题"></a></h3>
</section>
<section id="id39">
<h3><span class="section-number">1.9.4. </span>小波域子带能量<a class="headerlink" href="#id39" title="永久链接至标题"></a></h3>
</section>
</section>
<section id="mfcc">
<h2><span class="section-number">1.10. </span>语音识别的音频特征–MFCC<a class="headerlink" href="#mfcc" title="永久链接至标题"></a></h2>
<p>前文讲过用逆傅里叶变换抽取倒谱时，每一个帧有12个倒谱系数。下面我们再加上第13个特征：帧的能量。</p>
<p>能量与发音的识别是相关的，因此，它是探测发音的一个有用线索（元音和咝音比塞[se]音具有更多的能量）。
一个帧的 <strong>能量(energy)</strong> 是该帧在某一时段内的样本幂的总和，因此，从时间样本 <span class="math notranslate nohighlight">\(t_1\)</span> 到时间样本 <span class="math notranslate nohighlight">\(t_2\)</span> 的窗口内(一帧),
信号的能量是</p>
<div class="math notranslate nohighlight" id="equation-audio-feature-11">
<span class="eqno">(1.10.1)<a class="headerlink" href="#equation-audio-feature-11" title="公式的永久链接"></a></span>\[Energy = \sum_{t=t_1}^{t_2} x[t]^2\]</div>
<p>语音信号的另外一个重要的事实是：从一帧到下一帧，语音信号是不恒定的。共振峰在转换时的斜坡的变化，塞音从成阻到爆破的变化，
这些都可能给语音的探测提供有用的线索。由于这样的原因，我们还可以加上倒谱特征中与时间变化有联系的一些特征。</p>
<p>我们使用对13个特征（12个倒谱系数+1个能量系数）的每一个特征都加上 <strong>Delta特征（Delta feature）</strong> ，
以及加上 <strong>双Delta特征(double Delta feature)</strong> 的办法来做到这一点。</p>
<p>Delta特征表示的每一个倒谱/能量特征帧与帧之间的变化，双Delta特征表示的每一个Delta特征帧与帧之间的变化。</p>
<p>一种简单的计算法方法是帧与帧之间的差。</p>
<div class="math notranslate nohighlight" id="equation-audio-feature-12">
<span class="eqno">(1.10.2)<a class="headerlink" href="#equation-audio-feature-12" title="公式的永久链接"></a></span>\[d(t)=\frac{c(t+1)-c(t-1)}{2}\]</div>
<p>除了这种简单的估计方法之外，更为普遍的做法是使用各个帧的更加广泛的上下文信息，对于帧与帧之间的倾斜程度进行更加精细的计算。</p>
<p>在我们给12个倒谱特征加了能量特征并进一步加了Delta特征和双Delta特征之后，最后得到39各MFCC特征:</p>
<ul class="simple">
<li><p>12个倒谱系数</p></li>
<li><p>12个Delta倒谱系数</p></li>
<li><p>12个双Delta倒谱系数</p></li>
<li><p>1个能量系数</p></li>
<li><p>1个Delta能量系数</p></li>
<li><p>1个双Delta能量系数</p></li>
</ul>
<p>每一帧，总共39个特征。</p>
</section>
<section id="id40">
<h2><span class="section-number">1.11. </span>参考资料<a class="headerlink" href="#id40" title="永久链接至标题"></a></h2>
<p>什么是频响函数FRF？ <a class="reference external" href="https://zhuanlan.zhihu.com/p/22513076">https://zhuanlan.zhihu.com/p/22513076</a>
什么是泄漏？ <a class="reference external" href="https://zhuanlan.zhihu.com/p/22523642">https://zhuanlan.zhihu.com/p/22523642</a></p>
<p>各种谱函数的区别是什么，何时用何种函数？  <a class="reference external" href="https://zhuanlan.zhihu.com/p/22513006">https://zhuanlan.zhihu.com/p/22513006</a></p>
<p>傅立叶分析和小波分析之间的关系？ <a class="reference external" href="https://www.zhihu.com/question/22864189">https://www.zhihu.com/question/22864189</a></p>
<p>如何通俗地解释什么是离散傅里叶变换？<a class="reference external" href="https://www.zhihu.com/question/21314374">https://www.zhihu.com/question/21314374</a></p>
<p>频谱分析-FFT之后的那些事情  <a class="reference external" href="https://my.oschina.net/2nmjeSMen3/blog/781661">https://my.oschina.net/2nmjeSMen3/blog/781661</a></p>
<p>Chapter 4. Frequency and the Fast Fourier Transform <a class="reference external" href="https://www.oreilly.com/library/view/elegant-scipy/9781491922927/ch04.html">https://www.oreilly.com/library/view/elegant-scipy/9781491922927/ch04.html</a></p>
<p><a class="reference external" href="http://snowball.millersville.edu/~adecaria/ESCI386P/esci386-lesson17-Fourier-Transforms.pdf">http://snowball.millersville.edu/~adecaria/ESCI386P/esci386-lesson17-Fourier-Transforms.pdf</a></p>
<p>Scientific Programming,
Analysis and Visualization with
Python
Lesson 17 - Fourier Transforms
<a class="reference external" href="https://jakevdp.github.io/blog/2013/08/28/understanding-the-fft/">https://jakevdp.github.io/blog/2013/08/28/understanding-the-fft/</a></p>
<p>librosa 音频处理库 <a class="reference external" href="https://www.jianshu.com/p/bf6cb803f25e">https://www.jianshu.com/p/bf6cb803f25e</a></p>
<p>音频特征提取——常用音频特征  <a class="reference external" href="https://www.cnblogs.com/xingshansi/p/6815217.html">https://www.cnblogs.com/xingshansi/p/6815217.html</a></p>
<p>不同元音辅音在声音频谱的表现是什么样子？  <a class="reference external" href="https://www.zhihu.com/question/27126800">https://www.zhihu.com/question/27126800</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="语音技术" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="../edm/index.html" class="btn btn-neutral float-right" title="教育领域数据挖掘" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2018, zhangzhenhu(acmtiger@outlook.com) 禁止一切形式的转载！.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
  


    <script src="https://utteranc.es/client.js"
            repo="zhangzhenhu/blog"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>



</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>