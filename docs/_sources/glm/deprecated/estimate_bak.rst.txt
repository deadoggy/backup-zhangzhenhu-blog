
########################################################
GLM的参数估计
########################################################


本节我们介绍两种GLM模型的参数估计算法，
我们将统一的以指数族的形式展现算法过程，这样适用于指数族中的所有具体分布，
我们的目标是让大家对GLM的基础理论有个全面的了解，同时我们会着重强调算法成立的假设及其一些限制。


传统上，对于单参数的指数族分布可以运用梯度下降法和牛顿法进行参数估计，
梯度下降法的优点是算法实现简单，缺点是收敛速度不如牛顿法。
梯度下降法和牛顿法在形式上是非常相似的，二者都是沿着目标函数的负梯度方向寻找最优解，
不同的是传统梯度下降法利用一阶导数，而牛顿法利用二阶导数，牛顿法相对于梯度下降法收敛速度会更快，
但是由于二阶导数的引入也使得牛顿法的计算复杂度增加很对，甚至很多时候无法计算。
在用牛顿法对指数族模型进行参数估计时，不同的分布拥有不同的梯度表达式，所以每种分布都需实现一个适合自己的牛顿法。
这里我们同时会介绍牛顿法的一个变种算法，迭代重加权最小平方法(iteratively reweighted least squares,IRLS)。
GLM框架下的模型都可以以统计的形式运用IRLS算法进行参数估计，这是GLM非常有吸引力的一点。
IRLS 算法的另一个特点是不需要对估计参数 :math:`\hat{\beta}` 进行初始化设置。

.. _ch_glm_estimate:

最大似然估计
######################################
最大似然估计是应用十分广泛的一种参数估计方法，
其核心思想是通过极大化最大似然函数找到参数的最优解，
GLM中参数估计就是使用的最大似然方法。
注意在GLM中，最大似然方法不能同时估计线性协变量参数 :math:`\beta` 和分散参数
:math:`\phi` ，
在GLM中的最大似然估计通常是假设分散参数 :math:`\phi` 已知的情况下，
估计协变量参数 :math:`\beta` 。

假设响应变量 :math:`Y` 是GLM中的指数族分布，
协变量 :math:`X` 和响应变量 :math:`Y` 的一个样本集为 :math:`\mathcal{D}=\{(x_1,y_1),(x_2,y_2),\dots,(x_N,y_N)\}`
，样本之间是相互独立的，本书中的最大似然估计都是建立在样本独立的假设之上。
所有样本的联合概率为

.. math::
    :label: eq_34_21

    f(y;\theta,\phi)=\prod_{i=1}^N f(y_i;\theta,\phi)

:math:`\theta` 是指数族分布的自然参数，:math:`\phi`
是分散参数。
样本的联合概率又被称为样本集的似然函数，

.. math::
    :label: eq_34_22


    L(\theta,\phi;y)=\prod_{i=1}^N f(\theta,\phi;y_i)


:eq:`eq_34_21` 和 :eq:`eq_34_22` 的区别在于，
前者是一个概率密度(质量)函数，是在给定 :math:`\theta,\phi` 的条件下关变量 :math:`Y` 的函数；
后者是一个似然函数，其表达是在给定观测样本 :math:`y` 的条件下关于未知参数 :math:`\theta,\phi` 的函数。

因为似然函数是一个连乘形式，所以通常我们会对其进行一个对数转换(log-transform)进而得到一个连加的形式，
连加的形式更方便进行计算。
连乘变成连加有两个好处，(1)更容易求导和极大化操作；(2)似然函数是概率连乘，而概率都是小于1的，大量小于1的数字连乘产生更小的数字，
甚至趋近于0，而计算机的浮点数精度是通常无法处理这么小的数字的，所以加对数更方便计算机进行数值处理。


加了对数的似然函数被称为对数似然函数，通常用符号 :math:`\ell`
表示，对数似然函数是最大似然估计(ML)的核心，
GLM模型的对数似然估计函数为：


.. math::


    \ell(\theta,\phi;y)= \sum_{i=1}^N \left \{   \frac{y_i \theta_i - b(\theta_i)}{a(\phi)}   + c(y_i,\phi)   \right \}


:math:`\theta_i` 是自然参数，
:math:`b(\theta_i)` 是累积函数，它描述的是分布的矩(moment)；
:math:`\phi` 是分散参数(dispersion parameter)，它是比例或辅助参数；
:math:`c(\cdot)` 是归一化项。
归一化项不是 :math:`\theta` 的函数，而是简单地缩放基础密度函数的范围使得整个函数的积分（或求和）为1。
在上一节我们讨论过，指数族分布的期望与方差可以通过 :math:`b(\theta)` 的导数求得。


.. math::

     \mu &= \mathbb{E}[Y] = b'(\theta)

     Var(Y) &= b''(\theta) a(\phi)

并且我们知道，均值参数 :math:`\mu` 和自然参数 :math:`\theta` 是存在一个可逆的函数关系的，也就是说
:math:`\mu` 可以看做是关于 :math:`\theta` 的一个函数，反之，:math:`\theta` 也可看做是一个关于
:math:`\mu` 的函数。
基于这个事实，我们可以把 :math:`b''(\theta)` 看做是一个关于 :math:`\mu` 的函数，记作
:math:`\nu(\mu)` 。


.. math::

     b''(\theta) \triangleq \nu(\mu)

因此，方差 :math:`Var(Y)` 就可以被看成是函数 :math:`\nu(\mu)`
和分散函数 :math:`a(\phi)` 的乘积，通常我们把 :math:`\nu(\mu)=b''(\theta)` 称为方差函数(variance function)，
**注意：虽然叫方差函数，但方差函数的值不是方差本身。**
有时 :math:`b''(\theta)` 会是一个常数量(constant)，比如高斯分布，此时分布的方差为：

.. math::

    Var(Y)=constant \times a(\phi)

这时，分布的方差就不会受到均值的影响了。
另外方差函数 :math:`\nu(\mu)` 可以通过简单方式求得。

.. math::

    \nu(\mu) = b''(\theta) =(b'(\theta))'= (\mu(\theta))' = \frac{\partial \mu}{\partial \theta}


显然，当 :math:`\mu` 与 :math:`\theta` 之间的映射函数是线性函数时，一阶偏导 :math:`\frac{\partial \mu}{\partial \theta}`
就是一个常数值。另外，我们知道反函数的导数就等于原函数导数的倒数，所以有：

.. math::

    \frac{\partial \theta}{\partial \mu} = \frac{1}{\nu(\mu)}



在GLM框架下，输入变量 :math:`X` 和其系数 :math:`\beta`
组成一个线性预测器 :math:`\eta=\beta^Tx` 。
:math:`\eta` 和分布的均值(期望)通过连接函数(已知的)连接在一起 。

.. math::


    \eta &=\beta^Tx = g(\mu)

    \mu &= g^{-1}(\eta)


其中 :math:`\beta` 和 :math:`x` 都是一个向量，:math:`\beta^Tx = \sum_j \beta_j x_j` ，
因此有：

.. math::

    \frac{\partial \eta_i}{\partial \beta_j} = x_{ij}



线性预测器 :math:`\eta` 的值空间并没有特别的限定，
其值空间是整个实数域 :math:`\eta \in R` 。
而 :math:`\mu` 的取值范围是特定分布相关的，
不同指数族分布，:math:`\mu` 的取值范围是不同的，比如高斯分布 :math:`\mu \in R`
，二项分布 :math:`\mu \in [0,1]` 。
**因此，连接函数的一个目的就是将线性预测器的值映射到响应变量期望参数的范围。**


现在让我们回到最大似然估计，最大似然估计的思想是使得似然函数取得最大值的参数值为模型的最优解。
根据微分理论，函数取得极值的点其一阶偏导数为0，然而导数为0的点不一定是最大值的点，也可能是驻点、最小值点，
所以最大似然估计要求似然函数最好是凹函数。
注意，参数 :math:`\beta` 是一个向量，所以求得是偏导数，
利用求导的链式法则对GLM模型的对数似然函数进行求导。


.. math::
    :label: eq_34_jac


    \frac{ \partial \ell}{\beta_j} &= \sum_{i=1}^N \left ( \frac{\partial \ell_i}{\partial \theta_i} \right )
    \left ( \frac{\partial \theta_i}{\partial \mu_i} \right )
    \left ( \frac{\partial \mu_i}{\partial \eta_i} \right )
    \left ( \frac{\partial \eta_i}{\partial \beta_j} \right )

    &= \sum_{i=1}^N \left \{ \frac{y_i-b'(\beta_i)}{a(\phi)}   \right \}
    \left \{ \frac{1}{\nu(\mu_i)} \right \} \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{ij}

    &= \sum_{i=1}^N \frac{y_i-\mu_i}{a(\phi) \nu(\mu_i) } \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{ij}



其中 :math:`i` 是观测样本的编号，:math:`j` 是参数向量的下标。
:math:`x_{ij}` 表示第 :math:`i` 条观测样本的第 :math:`j` 列特征值，
:math:`y_i` 是响应变量的观测值，:math:`a(\phi)` 通常认为是已知的。
:math:`\mu_i` 是 :math:`y_i` 的期望，也是模型的预测值，
方差函数 :math:`\nu(\mu_i)` 是关于 :math:`\mu_i` 的函数，因此也可以算出。
:math:`\frac{\partial \mu}{\partial \eta}` 是响应函数(或者说是激活函数)关于 :math:`\eta_i` 的导数，
在确定了连接函数的形式后也是可以算出的。


:eq:`eq_34_jac` 是GLM标准形式下对数似然函数的一阶偏导数，GLM框架下的任意模型都可以按照此公式计算偏导数，
只需要按照特定的分布和连接函数替换相应组件即可。


对数似然函数的一阶导数又叫做 ``Fisher score`` ，或者得分函数(score function)，
常用符号 :math:`U` 表示。

.. math::

   U_j = \frac{\partial \ell}{\partial \beta_j}
  = \sum_{i=1}^N \frac{y_i-\mu_i}{a(\phi) \nu(\mu_i) } \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{ij}


:math:`U` 的表达式中只有 :math:`y_i` 是随机变量的样本，其它都是数值变量，
:math:`U` 是一个关于样本的函数，所以它是一个统计量(statistic)，
得分函数(score function)有时也叫作得分统计量(score statistic)，
统计量也是随机变量。
我们知道 :math:`\mathbb{E}[y_i]=\mu_i`，
而统计量 :math:`U` 是变量 :math:`y` 的函数，因此 :math:`U` 期望值为：

.. math::


   \mathbb{E}_{y}[U_j] &= \mathbb{E}_{y} \left [ \frac{\partial \ell}{\partial \beta_j} \right ]

   &= \mathbb{E}_{y} \left [ \sum_{i=1}^N \frac{y_i-\mu_i}{a(\phi) \nu(\mu_i) }
         \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{ij}  \right ]

   &= \sum_{i=1}^N \frac{ \mathbb{E}[y_i]-\mu_i}{a(\phi) \nu(\mu_i) } \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{ij}


   &= 0

统计量 :math:`U` 的方差 :math:`\mathcal{J}=\mathbb{E}\{(U-\mathbb{E}[U])(U-\mathbb{E}[U])^T \}=\mathbb{E}[UU^T]`
又被称为费希尔信息(Fisher information)，或者信息矩阵(information matrix)，

.. math::


    \mathcal{J}_{jk} &= \mathbb{E}[U_jU_k]

    &= \mathbb{E}_{y} \left [
    \sum_{i=1}^N \frac{y_i-\mu_i}{a(\phi) \nu(\mu_i) } \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{ij}
    \cdot
    \sum_{l=1}^N \frac{y_l-\mu_l}{a(\phi) \nu(\mu_l) } \left ( \frac{\partial \mu}{\partial \eta} \right )_l x_{lk}
    \right ]

    &= \mathbb{E}_{y} \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i
    \frac{ (y_i-\mu_i)^2}{ [a(\phi) \nu(\mu_i)]^2 }   x_{ij} x_{ik}
    + \mathbb{E}_{y} \left [
    \sum_{i=1}^N \sum_{l=1}^N   \frac{y_i-\mu_i}{a(\phi) \nu(\mu_i) } \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{ij}
    \frac{y_l-\mu_l}{a(\phi) \nu(\mu_l) } \left ( \frac{\partial \mu}{\partial \eta} \right )_l x_{lk}
    \right ]_{l\ne i}


    &= \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i
    \frac{ \mathbb{E}_{y}[(y_i-\mu_i)^2]}{ [a(\phi) \nu(\mu_i)]^2 }
    x_{ij} x_{ik}
    +  \underbrace{\left [
    \sum_{i=1}^N \sum_{l=1}^N   \frac{ \mathbb{E}_{y}[(y_i-\mu_i)(y_l-\mu_l)]}{a(\phi)^2 \nu(\mu_i) \nu(\mu_l) } \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{ij}
     \left ( \frac{\partial \mu}{\partial \eta} \right )_l x_{lk}
    \right ]_{l\ne i}}_{0}



:math:`\mathbb{E}[(y_i-\mu_i)(y_l-\mu_l)]`
是 :math:`y_i` 与 :math:`y_l` 的协方差，
根据样本独立性假设 :math:`y_i \perp \!\!\! \perp  y_l,\ l \ne i`
，:math:`y_i` 与 :math:`y_l` 的协方差为0，
因此有 :math:`\mathbb{E}[(y_i-\mu_i)(y_l-\mu_l)]=0`
。而 :math:`\mathbb{E}_{y}[(y_i-\mu_i)^2]` 表示 :math:`y_i`
的方差，有 :math:`\mathbb{E}_{y}[(y_i-\mu_i)^2]=Var(y_i)=a(\phi)\nu(\mu_i)`
。最终化简为

.. math::
    :label: eq_glm_estimate_019

    \mathcal{J}_{jk} = \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i
    \frac{1}{ a(\phi) \nu(\mu_i) }
    x_{ij} x_{ik}




通过令 :math:`U=0` 求得参数估计值，这个等式被称为估计等式(estimating equation)，
有的资料中也叫正规方程(normal equation)。

.. math::
    :label: eq_glm_estimate_020

       U_j
       = \sum_{i=1}^N \frac{y_i-\mu_i}{a(\phi) \nu(\mu_i) }
        \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{ij}
       = 0

如果是传统线性回归模型，相当于 :math:`y_i` 是高斯分布
:math:`y_i \sim \mathcal{N}(\mu_i,\sigma^2=1)`
，连接函数是恒等函数 :math:`\mu_i=\eta_i`
此时 :math:`U` 中的几项都是常量。

.. math::

    \frac{\partial \mu_i }{\partial \eta_i} = 1

    \nu(\mu) = 1

    a(\phi) = \sigma^2=1


此时 :math:`U_j` 简化为

.. math::

   U_j
   = \sum_{i=1}^N (y_i-\mu_i ) x_{ij}
   = 0

上式是单个参数 :math:`\beta_j` 的得分统计量 :math:`U_j`
，转成向量为

.. math::

    \pmb{U} = (\pmb{y}-\pmb{u})^T \pmb{X}
    = (\pmb{y}- \pmb{X}\pmb{\beta})^T\pmb{X}
    = \pmb{X}^T \pmb{y} - \pmb{X}^T X \pmb{\beta}
    = \pmb{0}


移项可解的参数的估计值

.. math::

    \hat{\pmb{\beta}} = ( \pmb{X}^T \pmb{X})^{-1}\pmb{X}^T \pmb{y}


我们发现标准连接函数的高斯模型，估计等式 :math:`U=0` 可以得到解析解，
只有采用标准连接函数时才有这个特性。
GLM中，采用标准连接函数的情况下有 :math:`\theta=\eta`
，此时对数似然函数的一阶导数 :math:`U` 可以简化。

.. math::

    U_j = \frac{ \partial \ell}{\beta_j} &= \sum_{i=1}^N
    \left ( \frac{\partial \ell_i}{\partial \theta_i} \right )
    \left ( \frac{\partial \theta_i}{\partial \mu_i} \right )
    \left ( \frac{\partial \mu_i}{\partial \eta_i} \right )
    \left ( \frac{\partial \eta_i}{\partial \beta_j} \right )

    &= \sum_{i=1}^N
    \left ( \frac{\partial \ell_i}{\partial \eta_i} \right )
    \left ( \frac{\partial \eta_i}{\partial \mu_i} \right )
    \left ( \frac{\partial \mu_i}{\partial \eta_i} \right )
    \left ( \frac{\partial \eta_i}{\partial \beta_j} \right )

    &= \sum_{i=1}^N
    \left ( \frac{\partial \ell_i}{\partial \eta_i} \right )
    \left ( \frac{\partial \eta_i}{\partial \beta_j} \right )

    &= \sum_{i=1}^N \frac{y_i-\mu_i}{a(\phi)} x_{ji}

当采用标准连接函数时，就是可以通过令上式等于0求得最大似然估计值，
上式中 :math:`\mu_i` 是模型的输出值 :math:`\mu_i=x_i^T\beta=\hat{\mu}_i=\hat{y_i}`
。

泰勒级数
############################

最大似然的求解需要求解正规方程，
然而在GLM中，正规方程并不是一定存在解析解的，需要满足一些限制条件才行，
解析解的方式并不具备通用性，我们需要采用更一般的方法，逼近法，也叫迭代法。
迭代法又可以简单分为一阶导(梯度下降法系列)和二阶导(牛顿法系列)，实际这两种都可以通过泰勒级数(Taylor series)进行推导。
泰勒级数有很多个名字，泰勒公式(Taylor formula)、泰勒级数(Taylor series)、
泰勒展开(Taylor explanation)、泰勒定理(Taylor theory)等，都是一回事。







设 :math:`n` 是一个正整数。如果定义在一个包含 :math:`x_0` 的区间上的函数f在 :math:`x_0`
处 :math:`n+1` 次可导，那么对于这个区间上的任意x，都有

.. math::

        f(x)_{Taylor}  &= \sum_{n=0}^{\infty} \frac{f^{(n)}(x_0)}{n!}  (x - x_0)^n

         &= f(x_0) + \frac{f'(x_0)}{1!}(x-x_0) + \frac{f^{(2)}(x_0)}{2!}(x-x_0)^2+ \cdots + \frac{f^{(n)}(x_0)}{n!}(x-x_0)^n + R_i(x)


其中 :math:`f^{(n)}` 表示 :math:`f` 的 :math:`n` 阶导数，
泰勒展开表达的就是 :math:`f(x)` 可以用其附近的点 :math:`f(x_0)` 近似的表示。

.. hint::

    注意，本书讨论的迭代求解算法默认目标函数都是凸函数，也就是函数有唯一的极值点。
    关于非凸函数以及带约束的优化问题，请读者参考其它资料。




梯度下降法
#######################################


我们把对数似然函数按照泰勒公式进行展开，但是我们只展开到一阶导数，把更高阶导数的和看做一个常数量constant，


.. math::

    f(x)_{Taylor} = f(x_0) + f'(x_0)(x-x_0) +constant


现在我们把对数似然函数按照上式进行展开：

.. math::
    :label: eq_34_30

    \ell(\beta^{(t+1)}) = \ell(\beta^t) + \ell'(\beta^t)(\beta^{(t+1)} - \beta^t) + constant

假设 :math:`\beta^{(t+1)}` 是对数似然函数的极值点，也就是参数的最优解，
:math:`\beta^t` 是其附近的一个点。
现在把这个式子进行简单的移项和变换，


.. math::

    \ell(\beta^{(t+1)}) -  \ell(\beta^t) =\ell'(\beta^t)(\beta^{(t+1)} - \beta^t) +constant

显然 :math:`\ell(\beta^{(t+1)})` 应该是大于等于 :math:`\ell(\beta^t)` 的，
因此有

.. math::

    \ell(\beta^{(t+1)}) -  \ell(\beta^t) =\ell'(\beta^t)(\beta^{(t+1)} - \beta^t) +constant \ge 0


对上述公式进行移项处理，可得：

.. math::
    :label: eq_34_31

    \beta^{(t+1)} \ge \beta^t - \frac{constant}{\ell'(\beta^t)}

我们给参数 :math:`\beta` 设置一个初始值，然后通过上式不停的迭代计算新的 :math:`\beta`
，:math:`t` 表示迭代计算的轮次，直到等号成立的时候，就找到了参数的最优解。


通常我们把一阶导 :math:`\ell'(\beta^t)` 称为梯度(gradient)，
:eq:`eq_34_31` 说明只要 :math:`\beta^{(t+1)}` 沿着 :math:`\beta^t` 的负梯度方向进行移动，我们终将能达到极值点。
注意 :math:`\frac{constant}{\ell'(\beta^t)}` **的绝对值的大小影响着前进的速度，**
**其方向(正负号)决定目标函数是否向着极大值点移动。**
所以和下面的公式是等价的，:math:`\alpha` 称为学习率(learning rate)，是一个人工设置参数，控制的迭代的速度。


.. math::
    :label: eq_34_32

    \beta^{(t+1)} = \beta^t - \alpha \ell'(\beta^t)


利用 :eq:`eq_34_32` 进行参数迭代求解的方法就称为梯度上升法，
梯度上升法的核心就是让参数变量沿着负梯度的方向前进。
虽然理论上最终一定能到达极值点，但是实际上会受到学习率参数 :math:`\alpha` 的影响，
学习率可以理解成每次迭代前进的步长(step size)，步长越大前进的越快，收敛性速度就越快；反之，步长越小，收敛越慢。
但是步长如果大了，就会造成震荡现象，即一步迭代就越过了终点(极值点)，并且在极值点附近往返震荡，永远无法收敛。
为了保证算法能一定收敛，通常会为 :math:`\alpha` 设定一个较小的值。
关于 :math:`\alpha` 的更多讨论请参考其它资料。

.. todo:: 图反了，重新换个图。

.. _fg_34_3:

.. figure:: pictures/34_3.png
    :scale: 70 %
    :align: center

    梯度下降法中学习率的影响(图片来自网络)





牛顿法
############################################

梯度下降法虽然也能收敛到最优解，但是如果学习率设置(通常人工设置)不合理，可能会造成收敛速度太慢或者无法收敛的问题，
其收敛速度难以有效的控制。
现在我们讨论另一中迭代算法，牛顿–拉夫森方法(Newton–Raphson)，一般简称牛顿法。
还是从泰勒展开公式开始，让我们考虑二阶泰勒展开：

.. math::
    :label: eq_34_33

    \ell(\beta^{(t+1)}) = \ell(\beta^t) + \ell'(\beta^t)(\beta^{(t+1)} - \beta^t) +
    \frac{1}{2}\ell''(\beta^t)(\beta^{(t+1)} - \beta^t)^2 + constant



我们知道目标函数在极值点处的导数应该为0，
所以如果 :math:`\beta^{(t+1)}` 是极值点，那么有 :math:`\ell'(\beta^{(t+1)})=0`
。我们对 :eq:`eq_34_33` 进行求导，注意 :math:`\beta^{(t+1)}` 才是函数未知量，
:math:`\beta_t` 和 :math:`\ell(\beta^t)` 都是已知量。

.. math::

    \ell'(\beta^{(t+1)})= \ell'(\beta^t) + \ell''(\beta^t)(\beta^{(t+1)}-\beta^t)=0


通过移项可得：

.. math::
    :label: eq_34_34

    \beta^{(t+1)} = \beta^t - \frac{\ell'(\beta^t)}{\ell''(\beta^t)}

这个迭代等式中，需要同时使用到对数似然函数的一阶导和二阶导数，
二阶偏导数可以在一阶导数的基础上再次求导得到，上一节已经讲过，
对数似然函数的一阶导数又称为得分统计量。

.. math::

   U_j = \frac{\partial \ell}{\partial \beta_j}
  = \sum_{i=1}^N \frac{y_i-\mu_i}{a(\phi) \nu(\mu_i) } \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{ij}

我们对 :math:`U_j` 继续求导就是对数似然函数的二阶导数。

.. math::
    :label: eq_34_36

    \left (\frac{\partial^2 \ell }{\partial \beta_j \partial \beta_k} \right )
    &= \frac{\partial U_j}{\partial \beta_k}

    &=
    \sum_{i=1}^N \frac{1}{a(\phi)} \left (  \frac{\partial}{\partial \beta_k}   \right )
    \left \{ \frac{y_i-\mu_i}{\nu(\mu_i)} \left ( \frac{\partial \mu}{\partial \eta} \right)_i x_{jn} \right \}


    &= \sum_{i=1}^N \frac{1}{a(\phi)} \left [
        \left ( \frac{\partial \mu }{\partial \eta} \right )_i
        \left \{
            \left (  \frac{\partial  }{\partial \mu} \right )_i
            \left ( \frac{\partial \mu }{\partial \eta} \right )_i
            \left (  \frac{\partial \eta }{\partial \beta_k} \right )_i
        \right \} \frac{y_i-\mu_i}{\nu(\mu_i)}
        + \frac{y_i-\mu_i}{\nu(\mu_i)}
            \left \{
                    \left ( \frac{\partial  }{\partial \eta} \right )_i
                    \left ( \frac{\partial \eta }{\partial \beta_k} \right )_i
            \right \}
        \left ( \frac{\partial \mu }{\partial \eta} \right )_i
    \right ] x_{jn}


    &= -\sum_{i=1}^N \frac{1}{a(\phi)}
    \left [
        \frac{1}{\nu(\mu_i)}  \left ( \frac{\partial \mu}{\partial \eta} \right )_i^2
        -(\mu_i-y_i)
            \left \{
                \frac{1}{\nu(\mu_i)^2}  \left ( \frac{\partial \mu }{\partial \eta} \right )_i^2 \frac{\partial \nu(\mu_i)}{\partial \mu}
                - \frac{1}{\nu(\mu_i)}  \left ( \frac{\partial^2 \mu}{\partial \eta^2} \right )_i
            \right \}
    \right ] x_{jn}x_{kn}


对数似然函数的二阶偏导数是一个矩阵，这个矩阵又叫海森矩阵 ``Hessian matrix`` ，
常用符号 :math:`H` 表示。牛顿法的迭代公式可以写成如下形式，

.. math::
    :label: eq_34_35

     \beta^{(t+1)} = \beta^{(t)} - H(\beta^{(t)})^{-1} U(\beta^{(t)})


和梯度下降法的 :eq:`eq_34_32` 对比下发现，两者非常相似，不同的是牛顿法用Hessian矩阵的逆矩阵 :math:`H(\beta^{(t)})^{-1}`
替代了学习率参数，避免了需要人工设置学习率的问题。相比梯度下降法，牛顿法收敛速度更快，并且也没有震荡无法收敛的问题。

观察下 :eq:`eq_34_36` ，
GLM的海森矩阵计算难度是比较大的，为了解决这个问题，
有时候会用海森的矩阵的期望 :math:`\mathbb{E}[H]` 替代。
从 :eq:`eq_34_36` 可以看到，海森矩阵是一个关于响应变量 :math:`Y`
的函数，所以可以对海森矩阵求关于 :math:`Y` 的期望。


.. math::
    :label: eq_glm_estimate_030

    \mathbb{E}_{y}[H]_{jk} &= \mathbb{E}_{y} \left [
    -\sum_{i=1}^N \frac{1}{a(\phi)}
    \left [
        \frac{1}{\nu(\mu_i)}  \left ( \frac{\partial \mu}{\partial \eta} \right )_i^2
        -(\mu_i-y_i)
            \left \{
                \frac{1}{\nu(\mu_i)^2}  \left ( \frac{\partial \mu }{\partial \eta} \right )_i^2 \frac{\partial \nu(\mu_i)}{\partial \mu}
                - \frac{1}{\nu(\mu_i)}  \left ( \frac{\partial^2 \mu}{\partial \eta^2} \right )_i
            \right \}
    \right ] x_{ij}x_{ik}
    \right ]

    &=
    -\sum_{i=1}^N \frac{1}{a(\phi)}
    \left [
        \frac{1}{\nu(\mu_i)}  \left ( \frac{\partial \mu}{\partial \eta} \right )_i^2
        -(\mu_i- \mathbb{E} [y_i])
            \left \{
                \frac{1}{\nu(\mu_i)^2}  \left ( \frac{\partial \mu }{\partial \eta} \right )_i^2 \frac{\partial \nu(\mu_i)}{\partial \mu}
                - \frac{1}{\nu(\mu_i)}  \left ( \frac{\partial^2 \mu}{\partial \eta^2} \right )_i
            \right \}
    \right ] x_{ij}x_{ik}

    &= -\sum_{i=1}^N \frac{ x_{ij}x_{ik}}{a(\phi)\nu(\mu_i)}
        \left ( \frac{\partial \mu}{\partial \eta} \right )_i^2


在参数的迭代过程中使用 :math:`\mathbb{E}[H]` 和使用 :math:`H`
在参数收敛效果上没有太大区别，二者是类似的，但是 :math:`\mathbb{E}[H]` 的计算要简化了很多。
原始海森矩阵 :math:`H` 的计算依赖观测样本 :math:`y_i` ，
所以通常会把原始海森矩阵称为观测海森矩阵(observed Hessian)
，他的期望矩阵称为期望海森(expected Hessian) 。

.. math::
    :label: eq_glm_estimate_031

     \beta^{(t+1)} = \beta^{(t)} - \mathbb{E}[H(\beta^{(t)})]^{-1} U(\beta^t)


对比下信息矩阵 :eq:`eq_glm_estimate_019` 和期望海森 :eq:`eq_glm_estimate_030`
，二者只差一个负号，是相反数的关系，这和我们在
:numref:`ch_2_Fisher_Information` 讨论的结论是一致的，

.. math::

    \mathcal{J} = - \mathbb{E}[H]

因此牛顿法的迭代过程 :eq:`eq_glm_estimate_031`
经常也会写成

.. math::

         \beta^{(t+1)} = \beta^{(t)} + \mathcal{J}(\beta^{(t)})^{-1} U(\beta^t)

在 :numref:`ch_2_Fisher_Information` 讨论过，参数的最大似然估计估计量是一个统计量，
并且其渐进服从正态分布，其方差可以通过信息矩阵 :math:`\mathcal{J}` 计算得到。
最终，Newton–Raphson 提供了如下功能：

1. 为所有单参数的GLM成员模型提供一个参数估计算法。
2. 参数估计值的标准误(standard errors)的计算：负的 Hessian matrix 逆矩阵的对角线元素的平方根。

我们这里描述的 Newton–Raphson 算法不支持分散参数(dispersion parameter)， :math:`\phi`
，的估计，一些 Newton–Raphson 的扩展算法可以提供分散参数的ML估计。




**迭代初始值的设定**

要实现 Newton–Raphson 迭代法，
我们必须对参数初始值有一个猜测。
但目前没有用于获得良好参数初值的全局机制，
但是有一个合理的解决方案可以在模型中存在"常数项系数"时获得起始值。

这里的"常数项"指的是线性预测器中截距部分


.. math::

    \eta = \beta_0 \times 1 + \beta_1 x_1 +\dots + \beta_px_p

其中 :math:`\beta_0` 就是常数项系数。
如果模型包含常数项，则通常的做法是找到仅包含常数项系数的模型的估计值。
我们令：

.. math::

    \eta = \beta_0

然后令对数似然函数的一阶导数 :eq:`eq_34_jac` 为0，找到 :math:`\beta_0`
的解析解。

.. math::
    :label: eq_34_37

    \sum_{i=1}^N \frac{y_i-\mu_i}{a(\phi) \nu(\mu_i) } \left ( \frac{\partial \mu}{\partial \eta} \right )_i
    =0

通过上式是可以得到 :math:`\beta_0` 的一个估计值的。
比如如果是逻辑回归模型，则有：

.. math::

    a(\phi) &= 1

    \nu(\mu) &= \mu(1-\mu)

    \mu &= \text{sigmoid}(\eta_i) = \text{sigmoid}(\beta_0)

    \frac{\partial \mu}{\partial \eta} &= \frac{\partial }{\partial \eta} \text{sigmoid} (\eta) = \mu(1-\mu)

代入到 :eq:`eq_34_37` 可得：


.. math::

    \sum_{i=1}^N \frac{(y_i- \mu_i ) }{\mu_i(1-\mu_i)} \mu_i(1-\mu_i) &= 0

     &\Downarrow

    \sum_{i=1}^N (y_i- \mu_i) &=0

     &\Downarrow

    \sum_{i=1}^N (y_i- \frac{1}{1+e^{-\beta_0}}) &=0

     &\Downarrow

     \underbrace{\frac{1}{N}\sum_{i=1}^N y_i}_{\text{均值}\bar{y}} &=  \frac{1}{1+e^{-\beta_0}}


    &\Downarrow{\text{sigmoid反函数求解}}

    \hat{\beta}_0 &= \ln \left (  \frac{\bar{y}}{1-\bar{y}}   \right )

然后我们就用 :math:`\beta=(\hat{\beta}_0,0,0,\dots,0)^T` 作为 Newton–Raphson 算法首次迭代时参数向量的初始值。
使用这种方法为我们提供了两个优点。
首先，我们从参数空间的合理子集开始迭代。
其次，对于ML，因为我们知道仅常数项系数模型的解决方案，
所以可以将训练模型的对数似然与算法初始步骤中获得的仅常数项系数模型的对数似然进行比较。
此比较是每个协变量（常数项系数除外）均为零的似然比检验，在后续章节会介绍什么是似然比检验。
如果模型中没有常量项系数，或者如果我们无法解析法求解纯常数项系数模型，则必须使用更复杂的方法，
比如使用搜索方法寻找合理的初始点来开始我们的 Newton-Raphson 算法。




迭代重加权最小二乘(IRLS)
#####################################################

使用牛顿法对GLM中的模型进行参数估计时，
需要把每个模型的对数似然函数通过 :math:`\beta` 进行参数化，
然后求出对数似然函数的偏导数，并且在迭代开始前需要给
:math:`\beta` 一个初始值，这种方法过于繁琐，
本节我们介绍牛顿法在GLM中的一个变种算法，
迭代重加权最小二乘(iterative weighted least squares,IRLS)算法，
IRLS算法是GLM的一个通用型参数估计算法，可用于任意的指数族分布和连接函数，
并且不需要对 :math:`\beta` 进行初始化。


算法推导
============================================

采用期望海森矩阵的牛顿法的参数迭代等式为

.. math::
    \beta^{(t+1)} = \beta^{(t)} + [\mathcal{J}^{(t)}]^{-1} U^{(t)}



等式两边同时乘以信息矩阵 :math:`\mathcal{J}` ，

.. math::

    \mathcal{J}^{(t)}\beta^{(t+1)} = \mathcal{J}^{(t)} \beta^{(t)} +  U^{(t)}

假设协变量参数 :math:`\beta` 的数量是 :math:`p`
，则信息矩阵 :math:`\mathcal{J}` 是一个 :math:`p\times p`
的方阵，其中每个元素 :math:`\mathcal{J}_{jk}` 为

.. math::
    \mathcal{J}_{jk}=
    \sum_{i=1}^N
    \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i  \frac{  x_{ij} x_{ik}}{ a(\phi) \nu(\mu_i) }



仔细观察 :math:`\mathcal{J}_{jk}` 的计算公式，
假设有一个 :math:`N\times N` 的对角矩阵
，每个对角元素为

.. math::

    W_{ii} = \text{diag} \left \{ \frac{ 1}{ a(\phi) \nu(\mu_i) }
    \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i
    \right \}_{(N\times N)}


方阵 :math:`\mathcal{J}` 就相当于三个矩阵的乘法

.. math::
    :label: eq_glm_estimate_041

    \mathcal{J} = X^T W X





这个等式我们先记录下，之后再使用。
现在看下 :math:`\mathcal{J} \beta` 的结果是什么。
参数 :math:`\beta` 是一个 :math:`p \times 1`
的列向量，下标 :math:`j` 表示行坐标，下标 :math:`k` 表示列坐标。
方阵 :math:`\mathcal{J}` 和列向量 :math:`\beta`
相乘的计算过程是方阵 :math:`\mathcal{J}` 的每一行向量和列向量 :math:`\beta`
进行內积运算，因此行向量 :math:`\mathcal{J}_j` 和
列向量 :math:`\beta` 的內积结果为

.. math::

    \mathcal{J}_{j} \beta
    &=
    \sum_{i=1}^N
    \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i  \frac{  x_{ij} x_{i}\beta}{ a(\phi) \nu(\mu_i) }

    &=    \sum_{i=1}^N
    \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i  \frac{  x_{ij} \eta_i}{ a(\phi) \nu(\mu_i) }




现在我们把 :eq:`eq_34_35` 稍微变换一下，并且我们用 :math:`I(\beta^{(t)})` 替换
:math:`- H(\beta^{(t)})` 。

.. math::
    :label: eq_34_45

       \Delta \beta^{(t)} = \beta^{(t+1)} - \beta^{(t)} &=  - H(\beta^{(t)})^{-1} \ell'(\beta^{(t)})

     & \Downarrow{\text{移项}}

      - H(\beta^{(t)})  \Delta \beta^{(t)} &= \ell'(\beta^{(t)})

     & \Downarrow{\text{Hessian的期望}}

    - \mathbb{E}[H(\beta^{(t)})] \Delta \beta^{(t)} &= \ell'(\beta^{(t)})

    & \Downarrow{\text{信息矩阵}}

    I(\beta^{(t)})\Delta \beta^{(t)} &= \ell'(\beta^{(t)})


现在我们把 :eq:`eq_34_jac` 和 :eq:`eq_34_44` 代入上式，得到一个等式：

.. math::
    :label: eq_34_46

    \left \{
    \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i  \frac{ 1}{ a(\phi) \nu(\mu_i) }   x_{jn} x_{kn}
    \right \}
    \Delta \beta^{(t)} =
     \sum_{i=1}^N \frac{y_i-\mu_i}{a(\phi) \nu(\mu_i) } \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{n}^T
    \ \ \ \ \text{(等式A)}


:eq:`eq_34_46` 先保留，我们记为等式A，我还需要借助另外一个等式。
我们知道，对于每条样本线性预测器的方程为：

.. math::

    \eta_i^{(t)} =  x_i^T \beta^{(t)}


我们把 :eq:`eq_34_46` 中的 :math:`\Delta \beta^{(t)}`
换成 :math:`\beta^{(t)}`
，并结合线性预测器，可以得到如下等式。

.. math::
    :label: eq_34_47

    & \left \{
    \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i  \frac{ 1}{ a(\phi) \nu(\mu_i) }   x_{jn} x_{kn}
    \right \} \beta^{(t)}

    &= \left \{
    \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i  \frac{ 1}{ a(\phi) \nu(\mu_i) }  x_i  x_i^T
    \right \} \beta^{(t)}

    &=
    \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i  \frac{ 1}{ a(\phi) \nu(\mu_i) } \beta^{(t)T}  x_i  x_i^T


    &=
    \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i  \frac{ 1}{ a(\phi) \nu(\mu_i) } \eta_i^{(t)}  x_i^T



去掉 :eq:`eq_34_47` 的中间推导过程，直接得到如下等式，我们记为等式B。

.. math::
    :label: eq_34_48

    \left \{
    \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i  \frac{ 1}{ a(\phi) \nu(\mu_i) }   x_{jn} x_{kn}
    \right \} \beta^{(t)}
    =
    \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i  \frac{ 1}{ a(\phi) \nu(\mu_i) } \eta_i^{(t)}  x_i^T
    \ \ \ \ \text{(等式B)}

现在我们把等式A( :eq:`eq_34_46` )和等式B( :eq:`eq_34_48` )的等号两边相加：

.. math::
    :label: eq_34_49

    \left \{
    \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i  \frac{ 1}{ a(\phi) \nu(\mu_i) }   x_{jn} x_{kn}
    \right \} (\beta^{(t)} + \Delta \beta^{(t)} ) &=
    \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i \frac{ 1}{ a(\phi) \nu(\mu_i) }
    \left \{
    (y_i-\mu_i)\left ( \frac{\partial \eta}{\partial \mu}_i \right) + \eta_i^{(t)}
    \right \} x_i^T


     & \Downarrow

    \underbrace{ \left \{
    \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i  \frac{ 1}{ a(\phi) \nu(\mu_i) }   x_{jn} x_{kn}
    \right \} }_{\text{矩阵}}
    \beta^{(t+1)}
    &=
    \sum_{i=1}^N \left ( \frac{\partial \mu}{\partial \eta} \right )^2_i \frac{ 1}{ a(\phi) \nu(\mu_i) }
    \left \{
    (y_i-\mu_i)\left ( \frac{\partial \eta}{\partial \mu} \right)_i+ \eta_i^{(t)}
    \right \} x_i^T


上式看上去很复杂，但其实可以转化成矩阵的乘法，我们定义如下两个矩阵：

.. math::


    W^{(t)} &= \text{diag} \left \{ \frac{ 1}{ a(\phi) \nu(\mu) }
    \left ( \frac{\partial \mu}{\partial \eta} \right )^2
    \right \}_{(n\times n)}  \ \ \ \ \text{对角矩阵}


    Z^{(t)} &= \left \{ (y-\mu)  \left ( \frac{\partial \eta}{\partial \mu} \right) + \eta^{(t)}
    \right \}_{(n\times 1 )}


其中，:math:`a(\phi)` 是分散函数，:math:`\nu(\mu)` 是方差函数，
:math:`\frac{\partial \mu}{\partial \eta}` 是响应函数 :math:`r` 的导数，
等价于连接函数 :math:`g` 的导数的负数。
:math:`\frac{\partial \eta}{\partial \mu}` 是连接函数 :math:`g` 对 :math:`\mu` 的导数。
:eq:`eq_34_49` 就可以改写成矩阵乘积的形式：

.. math::
    :label: eq_34_49_1

    (X^TW^{(t)} X) \beta^{(t+1)} &= X^T W^{(t)} Z^{(t)}

     & \Downarrow{\text{移项}}


    \beta^{(t+1)} &= (X^TW^{(t)} X)^{-1} X^T W^{(t)} Z^{(t)}



:eq:`eq_34_49_1` 就是最终参数向量更新的公式，它在形式上等价于加权的最小二乘法，
其中 :math:`W` 是权重矩阵，并且每一次迭代都要重新计算 :math:`W`
，所以我们把这个算法称为迭代重加权最小二乘法(Iteratively Reweighted Least Square,IRLS)，
"reweighted" 指的就是每次迭代重新计算权重矩阵。

使用对数似然函数的二阶偏导数的 Hessian 矩阵，是用观测样本值计算得到的，所以称为观测海森矩阵(observed Hessian matrix)，
有时也叫观测信息矩阵(observed information Matrix,OIM)，
牛顿法就是采用的OIM。

另一种方法就是用海森矩阵的期望矩阵(expected Hessian matrix)，
期望海森矩阵又被称为费歇尔信息矩阵(Fisher information matrix)，
所以这种方法也称为期望信息矩阵(expected information matrix,EIM)，IRLS算法就是使用EIM。
IRLS和牛顿法的区别就是，牛顿法是用的是OIM，IRLS算法使用的是EIM，
一般情况下两种算法的估计值是一致的。



迭代初始值的设定
====================================================

对比下 Newton–Raphson 算法的参数迭代公式( :eq:`eq_34_35` )
和IRLS算法的参数迭代公式( :eq:`eq_34_49_1` )，
可以发现IRLS算法并不需要直接在 :math:`\beta^{(t)}` 的基础上进行参数迭代，
**IRLS算法的参数迭代仅仅依赖** :math:`\mu` **和** :math:`\eta`
，因此与 Newton–Raphson 算法不同的是，IRLS 不需要对参数向量 :math:`\beta`
进行初始值的猜测，只需要给 :math:`\mu` 和 :math:`\eta` 赋予一个初始值即可。

- 对于二项式分布，可以令 :math:`\mu_i^{(0)}=k_i(y_i+0.5)/(k_i+1)`
  ，:math:`\eta_i^{(0)}=g(\mu_i^{(0)})` 。

- 对于非二项式分布，可以令 :math:`\mu_i^{(0)}=y_i`
  ， :math:`\eta_i^{(0)}=g(\mu_i^{(0)})` 。


IRLS算法在更新时，只依赖期望 :math:`\mu` 和 线性预测器 :math:`\eta` ，
鉴于这一特性，可以使用期望 :math:`\mu` 对GLM模型的概率函数进行参数化，而不需要细化到 :math:`\beta`
，这可以极大的降低GLM模型概率函数的复杂性。

.. code-block:: python3
   :linenos:

   𝜇={𝑦+𝑚𝑒𝑎𝑛(𝑦)}/2  # 初始化参数 𝜇
   𝜂=𝑔(𝜇)  # 初始化参数 𝜂

   WHILE(abs(Δ Dev)>tolerance){
      W = 1/(𝑎(𝜙) 𝜈 g'^2)   #计算W矩阵  g'^2 是连接函数一阶导数的平方
      Z = 𝜂 +(y-𝜇)g'
      β=Inverse(X^T W X) X^T W Z  # 更新新的参数值
      η=Xβ   # 计算新的线性预测器
      μ=r(η)  # 计算新的预测结果
      OldDev = Dev
      Dev = deviance function() # 计算新的偏差值
      ΔDev = Dev - OldDev  # 偏差值的变化量
   }
   χ^2= ∑ (y−μ)^2⁄v







收敛性判断
====================================================

在迭代的过程中，我们可以检查参数 :math:`\beta` 的相对变化来决定是否结束算法。

.. math::

    \sqrt{\frac{ (\beta^{new}-\beta^{old})^T (\beta^{new}-\beta^{old})  }{ \beta^{old^T} \beta^{new} } } < \epsilon

也可以通过相对偏差来判断。

.. math::

    \left|\frac{D(y-\mu^{new})-D(y,\mu^{old})   }{D(y,\mu^{old})} \right| <\epsilon



估计量的标准误差
====================================================

回顾一下在 :numref:`ch_2_MLE_estimator` 我们讲的最大似然估计量的评价，
我们知道最大似然估计量的协方差矩阵就是 :math:`I(\beta)^{-1}`
，显然在IRLS算法过程中已经计算出了 :math:`I(\beta)^{-1}=- \mathbb{E}[H(\beta)]=(X^TW^{(t)} X)^{-1}`
，所以使用IRLS我们可以很方便的得到估计量的标准误差。

.. math::

    SSE = \sqrt{ \text{diag} [{(X^TW^{(t)} X)}^{-1} ]}











分散参数的估计
====================================================

虽然IRLS算法本身并不包含对分散参数的估计，但我们可以通过  Pearson :math:`\mathcal{X}^2` 统计来得到 :math:`a(\phi)`
。

.. math::

    \hat{a}(\phi) = \frac{1}{N-p} \sum_{i=1}^N \frac{ (y_i - \hat{\mu}_i)^2}{\nu(\hat{\mu}_i)}


或者使用偏差：

.. math::

    \hat{a}(\phi) = \frac{D(y,\hat{\mu})}{N-p}


:math:`N` 是观测样本的数量，:math:`p` 是参数向量 :math:`\beta` 的长度，
:math:`\hat{\mu}_i` 是第n条样本的模型预测值，
:math:`\hat{a}(\phi)` 服从自由度为 :math:`n-p` 的 :math:`\mathcal{X}^2_{n-p}` 分布。





标准连接函数
========================================

当模型采用规范连接函数时，OIM会退化成EIM，此时牛顿法和IRLS算法是等价的。

对数似然函数的一阶导数(score function)为：

.. math::
   :label: eq_glm_estimate_score_2


    \frac{ \partial \ell}{\beta_j} &= \sum_{i=1}^N \left ( \frac{\partial \ell_i}{\partial \theta_i} \right )
    \left ( \frac{\partial \theta_i}{\partial \mu_i} \right )
    \left ( \frac{\partial \mu_i}{\partial \eta_i} \right )
    \left ( \frac{\partial \eta_i}{\partial \beta_j} \right )

    &= \sum_{i=1}^N \left \{ \frac{y_i-b'(\beta_i)}{a(\phi)}   \right \}
    \left \{ \frac{1}{\nu(\mu_i)} \right \} \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{jn}

    &= \sum_{i=1}^N \frac{y_i-\mu_i}{a(\phi) \nu(\mu_i) } \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{jn}

根据规范连接函数的定义，当模型采用规范连接函数时，就有 :math:`\theta=\eta` 。
此时 :eq:`eq_glm_estimate_score_2` 就可以简化为：

.. math::
   :label: eq_glm_estimate_score_3

    \frac{ \partial \ell}{\beta_j}
   &= \sum_{i=1}^N \left ( \frac{\partial \ell_i}{\partial \theta_i} \right )
    \left ( \frac{\partial \theta_i}{\partial \mu_i} \right )
    \left ( \frac{\partial \mu_i}{\partial \eta_i} \right )
    \left ( \frac{\partial \eta_i}{\partial \beta_j} \right )

   &= \sum_{i=1}^N \left ( \frac{\partial \ell_i}{\partial \eta_i} \right )
      \left ( \frac{\partial \eta_i}{\partial \mu_i} \right )
      \left ( \frac{\partial \mu_i}{\partial \eta_i} \right )
      \left ( \frac{\partial \eta_i}{\partial \beta_j} \right )

   &= \sum_{i=1}^N \left ( \frac{\partial \ell_i}{\partial \eta_i} \right )
      \left ( \frac{\partial \eta_i}{\partial \beta_j} \right )


   &= \sum_{i=1}^N \frac{y_i-\mu_i}{a(\phi) } x_{jn}
   = S(\beta_j)


现在我们对S继续求导，得到的就是对数似然函数的二阶导数，也称为观测信息矩阵(observed information matrix)。

.. math::

   OIM=S(\beta_k)' &= \sum_{i=1}^N  \frac{\partial S_i}{\partial \mu_i}
      \frac{\partial \mu_i}{\partial \eta_i} \frac{\partial \eta_i}{\partial \beta_k}

   &= \sum_{i=1}^N  \frac{-x_{jn}}{a(\phi)} \left ( \frac{\partial \mu_i}{\partial \eta_i} \right )  x_{kn}

   &= -\sum_{i=1}^N  \frac{x_{jn}x_{kn}}{a(\phi)} \left ( \frac{\partial \mu_i}{\partial \eta_i} \right )



OIM中已经不再包含变量 :math:`y` ，所以OIM关于变量 :math:`y` 的期望仍然是它自己，没有变化。

.. math::

   EIM = \mathbb{E}_{y}[OIM] = OIM

最终我们证明当GLM中模型采用规范连接函数是，OIM与EIM是等价的。

标准误差(standard error)
#################################################


但是，非规范链接会带来更高的标准错误(standard error)的问题。
在对观测值相对较少的数据集进行建模时，
我们发现最好在IRLS算法中调整权重以构造观测信息矩阵(observed information matrix)OIM或使用ML方法对数据建模（也使用OIM）。
如果没有进行任何调整，则将基于（3.66）中给出的EIM留下预期的信息矩阵（EIM）标准误差


当训练样本集相对较大时，使用EIM产生标准误差将不会对标准误差产生重大影响。
究竟有多大取决于多种因素，包括模型中预测变量的数量以及数据的平衡方式（例如，二进制响应中1到0的比较数）。
但是，即使对于具有许多预测变量的较小的不平衡数据集，所得的标准误差通常在两个估计过程之间也不会有太大的变化。
由于提高标准误差的准确性是研究人员的头等大事，因此，尽可能使用OIM作为标准误差的基础是可取的。


goodness of fit
#################################################












我们知道，模型的参数越多对数据的拟合程度就越好，极端情况下，模型参数的数量和样本的数量相同，
这时就相当于对每条样本都有一个独立的参数(模型)去拟合它，理论上可以完美拟合所有的样本。
我们把这样的模型成为之饱和模型(saturated model)，也可以称为
完整模型(full model)或者最大模型(maximal model)。
饱和模型虽然能完美拟合数据集，但它并没有从数据集中学习出任何的统计信息(统计规律)，所不具备泛化能力，
俗称过拟合(over-fitted)。
通过为饱和模型中的参数添加约束，比如令一些参数值为0，相当于去掉了一个参数，这样就得到了简化的模型。
简化模型对数据集拟合度下降了，但是其泛化能力会得到提升，
更少的参数数量可以得到更大的泛化能力。
但是参数数量变少，会降低拟合程度，参数数量越少拟合度就越差，所以也不是参数越少越好。

在开发一个模型时，我们希望模型的预测值 :math:`\hat{y}` 尽可能的接近数据的真实值 :math:`y`
，对于一个规模为N的观测值样本，我们可以考虑参数数量在 :math:`[1,N]` 之间的候选模型，
最简单的模型是只有一个参数的模型，但它对所有的样本的预测值都是一样的，缺乏拟合能力。
最复杂的模型是含有N个参数的模型，它可以完美拟合所有样本，但是它缺乏泛化能力。
理论上，我们期望得到一个参数数量尽可能少，又能保持拟合能力的模型。


在统计学中，似然比检验(likelihood-ratio test,LRT)用来对比两个模型对于当前数据集的拟合程度，
其是利用似然比(likelihood-ratio LR)的值来比较两个模型的优劣。
LRT的计算公式如下：


.. math::

    LR = 2 \ln \frac{L1}{L2} = 2 (\ln L1-\ln L2)

其中L1为复杂模型最大似然值，L2为简单模型最大似然值。
从公式可以看出，似然比就是两个模型的似然值之比的对数，也可以看成是两个模型对数似然值的差值。
似然(likelihood)，实际上也可以翻译为可能性，表示的是样本发生的概率，显然似然值越大的模型对数据的拟合也就越好。
似然比就是直接比较两个模型的似然值大小。
但是并不是任意两个模型都可以应用似然比去比较，只有在特定条件下似然比才有意义。

1. 两个模型采用同一份数据集，样本的数量和特征都是相同的。这很好理解，不同数据集似然值自然是不同的，没有比较的意义。
2. 两个模型是嵌套关系(nested)。所谓嵌套关系就是，其中一个模型是通过把另一个模型中的部分参数设置为0而得到的。


当样本足够大时，似然比是渐进服从卡方分布的，其自由度等于两个模型的参数数量之差(参数值为0的参数的数量)。
这样根据卡方分布临界值表，我们就可以判断模型差异是否显著。












在GLM中，我们定义一个评估模型拟合优度(Goodness of fit)的指标，称之为偏差(deviance)。
**偏差的计算方法就是饱和模型和拟合模型之间的似然比。**
我们用符号 :math:`L_m` 表示我们拟合出的目标模型的似然值，
用符号 :math:`L_f` 表示饱和模型的似然值。
用符号 :math:`D` 表示偏差，其通过下式给出：


.. math::
    :label: eq_34_50

    D = 2 (\ln L_f -\ln L_m)


我们知道在GLM中，模型的预测值 :math:`\hat{y}` 就是分布 :math:`p(y|x)` 的期望值
:math:`\mathbb{E}[p(y|x)]=\hat{\mu}` ，即 :math:`\hat{y}=\hat{\mu}` 。
所以这里我们用 :math:`\hat{\mu}` 表示模型的预测值。
并且我们知道，指数族形式的自然参数 :math:`\theta` 可以看做是一个关于均值参数 :math:`\mu` 的函数，
因此，在GLM框架下，目标模型的似然值为：


.. math::
    :label: eq_34_51

    L_m = \exp \left \{  \sum_{i=1}^N \frac{y_i \theta(\hat{\mu}_i) -b(\theta(\hat{\mu}_i))}{a(\phi)}
    + \sum_{i=1}^N  c(y_i;\phi) \right \}



对于饱和模型，每条样本的预测值就是样本的真实值，即 :math:`\hat{y_i}=y_i` ，换句话说，
对于饱和模型，满足 :math:`\hat{y_i}=\hat{\mu}_i=y_i`
。因此，饱和模型的似然值为：


.. math::
    :label: eq_34_52

    L_f = \exp \left \{  \sum_{i=1}^N \frac{y_i \theta(y_i) -b(\theta(y_i))}{a(\phi)}
    + \sum_{i=1}^N  c(y_i;\phi) \right \}


把 :eq:`eq_34_51` 和 :eq:`eq_34_52` 代入到 :eq:`eq_34_50`
可得到GLM的偏差：


.. math::

    D &= 2 (\ln L_f -\ln L_m)

    &= \frac{2}{a(\phi)} \sum_{i=1}^N  [ y_i \{ \theta(y_i) - \theta(\hat{\mu}_i) \} - b\{\theta(y_i)\} + b\{\theta(\hat{\mu}_i)\} ]

    &\triangleq 2 \sum_{i=1}^N  [ y_i \{ \theta(y_i) - \theta(\hat{\mu}_i) \} - b\{\theta(y_i)\} + b\{\theta(\hat{\mu}_i)\} ]


由于 :math:`a(\phi)` 与样本和参数都无关，是一个常量，所以通常会被省略掉。
对于一个特定的样本集和模型，饱和模型的似然值是一个常数值，
因此
**最大化似然函数和最小化偏差是等价的**
**，在进行参数学习时可以用最小化偏差替代最大化对数似然函数。**


在统计中，偏差(deviance)是统计模型的拟合优度统计；
它通常用于统计假设检验。
它是将普通最小二乘中的残差平方和用于通过最大似然实现模型拟合的情况的概括。
它在指数弥散模型和广义线性模型中起着重要作用。


https://newonlinecourses.science.psu.edu/stat504/node/220/


https://en.wikipedia.org/wiki/Deviance_(statistics)


https://www.xiaofandajie.top/2018/03/06/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E6%B3%95%E4%B8%8Elogistic%E5%9B%9E%E5%BD%92/

https://bookdown.org/hezhijian/book/est.html#section-30



