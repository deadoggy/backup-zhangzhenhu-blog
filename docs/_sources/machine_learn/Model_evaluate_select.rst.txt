=================
模型评估
=================

概述
========================

机器学习的一般过程是：

首先，我们获得了一个数据集、一个明确的任务（回归、分类、聚类等），我们希望通过模型挖掘出该数据集的隐含特征，进而来对新出现的数据进行数值回归、分类、聚类等。

此时，我们主要面临以下两个问题：

1. 数据集划分

2. 模型评估指标的选择。

下面从以上两个部分进行展开。


数据集划分
========================

为什么要进行数据集划分？

最主要原因：防止过拟合

为了寻找最能体现数据内在规律的模型，我们就要对所构造的模型进行评估，选择评估指标最优的模型。
如果不对数据集进行划分，数据集整体既作为训练集也作为测试集，则会导致过拟合，无法找到泛化能力强的模型，这是很严重的方法论错误。

以下介绍最常用的数据集划分方式：

1. 留出法（hold-out）

  直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T。需要注意的是为了避免因为数据划分引入的偏差而影响最终结果，
  在划分的时候要尽可能保证数据分布的一致性，即分层法。

  但是样本的不同划分方式会导致模型评估的相应结果也会有差别，因此通常我们都会进行多次随机划分、重复进行实验评估后取平均值作为留出法的评估结果，
  例如LOO（Leave One Out）、LPO（Leave P Out)。

  当原始样本的数据有多种不同的来源时，如多个病人的多组测试数据，我们要保证同源数据不被切分到训练集测试集中。
  有以下两种方式：Leave One Group Out、Leave P Groups Out。

2. k折交叉验证（K-fold）

  通常把数据集D分为k份，其中的k-1份作为训练集，剩余的那一份作为测试集，这样就可以获得k组训练/测试集，可以进行k次训练与测试，最终返回的是k个测试结果的均值。

  为保证划分的结果保证数据分布的一致性，划分方式同留出法一样选择分层采样的方式。

  对于交叉验证法，其k值的选取往往决定了评估结果的稳定性和保真性。通常k值选取10。
  与留出法类似，通常我们会进行多次划分得到多个k折交叉验证，最终的评估结果是这多次交叉验证的平均值。

  当原始样本的数据有多种不同的来源时，如多个病人的多组测试数据，我们要保证同源数据不被切分到训练集测试集中。此时，采取 Group k-fold这一方式。

3. 自助法

  自助法使用有放回重复采样的方式进行数据采样，重点在于有放回，即我们每次从数据集D中取一个样本作为训练集中的元素，然后把该样本放回，重复该行为m次，这样我们就可以得到大小为m的训练集，
  在这里面有的样本重复出现，有的样本则没有出现过，我们把那些没有出现过的样本作为测试集。最终，在D中约有36.8%的数据没有在训练集中出现过 。

  这种方法对于那些数据集小、难以有效划分训练/测试集时很有用，但是由于该方法改变了数据的初始分布导致会引入估计偏差。



模型评估指标的选择
========================

在进行了数据集的划分后，我们就要根据不同的任务选择不同的评估指标，来定量的描述模型的预测效果。

1. 分类问题

- 0-1损失（Zero one loss）

.. math::
    L_{0-1}(y, \hat{y}) = 1(y\ne\hat{y}) \tag{1}

上式中 :math:`\hat{y}` 是样本预测值， y是样本真实值。

- 正确率（Accuracy score）：

.. math::
    accuracy(y, \hat{y}) = \frac{1}{n_{samples}}\sum_{i=0}^{n_{samples}-1}1(y=\hat{y}) \tag{2}

上式中 :math:`\hat{y}` 是样本预测值， y是样本真实值。

- 样本平衡正确率（Balanced accuracy score）：

.. math::

    \hat{\omega_i} = \frac{\omega_i}{\sum_j 1(y_j=y_i)\omega_j} \tag{3}

.. math::

    balanced-accuracy(y, \hat{y}) = \frac{1}{\sum\hat{\omega_i}} \sum_i 1(\hat{y_i}=y_i)\omega_i \tag{4}

上式中 :math:`\hat{y}` 是样本预测值， y是样本真实值， :math:`\omega` 是样本权重， :math:`\hat{\omega}` 是样本对应的类别样本权重。

- 混淆矩阵（Confusion matrix）：

.. figure:: _static/confusion_matrix.png
    :align: center

对于二分类问题来讲，经常会提到以下四个术语：

TP（True positives：真正类）：真实标签为正，预测为正。

FP(False positives：假正类)：真实标签为负，预测为正。

FN(False negatives：假负类)：真实标签为正，预测为负。

TN（True negatives：真负类）：真实标签为负，预测为负。

- 汉明损失（Hamming loss）：

.. math::
    L_{hamming}(y, \hat{y}) = \frac{1}{n_{samples}}\sum_{i=0}^{n_{samples}-1}1(y_i\ne\hat{y_i}) \tag{5}

上式中 :math:`\hat{y}` 是样本预测值， y是样本真实值。

- 折页损失（Hinge loss）：

对于二分类{-1, 1}来讲：

.. math::
    L_{hinge}(y, w) = max(1-yw, 0) = |1-yw| \tag{6}

上式中 w是样本预测值， y是样本真实值。

对于多分类来讲：

.. math::
    L_{hinge}(y_w, y_t)= max(1+y_t-y_w, 0) \tag{7}

上式中 :math:`y_t` 样本预测为其他种类的最大值， :math:`y_w` 是样本预测为真实类别的值。

- 对数损失（Log loss）：

对数损失又称为逻辑回归损失、交叉熵损失

对于二分类{1, 0}来讲：

.. math::
    L_{log}(y, p) = -(ylog(p)+(1-y)(log(1-p))) \tag{8}

上式中p是样本预测值， y是样本真实值。

对于多分类来讲：

.. math::
    L_{log}(y, p) = -\frac{1}{N}\sum_{i=0}^{N-1}\sum_{k=0}^{K-1}y_{i,k}logp_{i,k} \tag{9}

上式中p是样本预测值， y是样本真实值，N为样本数量，K为类别数量。

- 精确率（Precision）, 召回率（recall） and F-measures：

对于二分类{正类、负类}问题， 下面是二分类的混淆矩阵：

.. figure:: _static/binary_confusion_matrix.png
    :align: center

.. math::
    precision = \frac{tp}{tp+fp} \tag{10}

.. math::
    recall = \frac{tp}{tp+fn} \tag{11}

.. math::
    F_{\beta} = (1+\beta^2)\frac{precision*recall}{\beta^2*precision+recall} \tag{12}

对于多分类问题：

我们有以下几种方式进行多分类指标的计算：

a) micro:

全局计算tp、fp、fn，并计算评估指标。表示为 :math:`P(y, \hat{y})`。

b) macro:

对每一个类别，分别计算tp、fp、fn，并计算评估指标，最后对所有的类别的评估指标取平均。
表示为 :math:`\frac{1}{|L|} \sum_{l \in L}P(y_l, \hat{y_l})`。

c) wighted:

对每一个类别，分别计算tp、fp、fn，并计算评估指标，最后对所有的类别的评估指标取加权平均。
表示为 :math:`\frac{1}{\sum_{l \in L}|\hat{y_l}|} \sum_{l \in L} |\hat{y_l}|P(y_l, \hat{y_l})`。

d) samples:

对每个样本计算评估指标，最后对所有样本的评估指标取平均。
表示为 :math:`\frac{1}{|S|} \sum_{s \in S}P(y_s, \hat{y_s})`。

- 受试者工作特征(ROC: Receiver operating characteristic):

分析ROC需要用到两个评估指标：TPR（rue positive rate）称为真正类率或敏感性、FPR（false positive rate）称为假正类率，1 - FPR也称作特异性。

:math:`TPR=\frac{TP}{TP+FN}` ，  :math:`FPR=\frac{FP}{FP+TN}`

ROC图是指通过设定一组阈值，得到对应的一组TPR、FPR对，以FPR作为横坐标，TPR作为纵坐标绘制的图像。

图像下与坐标轴围城的面积即为AUC值（0-1之间），对于多分类问题，我们可以利用计算precision、recall的四种方式来计算多分类问题的AUC值。

- Matthews相关系数（Matthews correlation coefficient）：

Matthews相关系数，用于度量二分类的质量。它会考虑TP/FP/TN/FP的情况，是一个平衡度量方式	，MCC数值上介于［－1，+1］之间。
相关系数为+1，表示是一个完美的预测，0表示是一个平均随机预测，而-1表示是一个逆预测。公式如下：

.. math::
    MCC = \frac{tp*tn-fp*fn}{\sqrt{(tp+fp)(tp+fn)(tn+fp)(tn+fn)}} \tag{13}


2. 回归问题

- 可释方差值（Explained variance score）：

.. math::
    explained\ variance(y, \hat{y}) = 1 - \frac{Var\{y-\hat{y}\}}{Var\{y\}} \tag{1}

上式中 :math:`\hat{y}` 是样本预测值， y是样本真实值，Var是方差。

- 平均绝对误差（Mean absolute error）：

.. math::
    MAE(y, \hat{y}) = \frac{1}{n_{samples}} \sum_{i=0}^{n_{samples}-1} |y_i - \hat{y_i}| \tag{2}

上式中 :math:`\hat{y}` 是样本预测值， y是样本真实值。

- 均方误差（Mean squared error）：

.. math::
    MSE(y, \hat{y}) = \frac{1}{n_{samples}} \sum_{i=0}^{n_{samples}-1} (y_i - \hat{y_i})^2 \tag{3}

上式中 :math:`\hat{y}` 是样本预测值， y是样本真实值。

- 均方根误差（Root Mean squared error）：

.. math::
    RMSE(y, \hat{y}) = \sqrt{MSE(y, \hat{y})} \tag{4}

上式中 :math:`\hat{y}` 是样本预测值， y是样本真实值。

- 中值绝对误差（Median absolute error）：

.. math::
    MedAE(y, \hat{y}) = median(|y_1 - \hat{y_1}|,|y_2 - \hat{y_2}|,......,|y_n - \hat{y_n}|) \tag{5}

上式中 :math:`\hat{y}` 是样本预测值， y是样本真实值。该指标具有鲁棒性，可以有效解决极端值的情况。

- 均方对数误差（Mean squared logarithmic error）：

.. math::
    MSLE(y, \hat{y}) = \frac{1}{n_{samples}} \sum_{i=0}^{n_{samples}-1} (log_e(1+y_i) - log_e(1+\hat{y_i}))^2 \tag{6}

上式中 :math:`\hat{y}` 是样本预测值， y是样本真实值。该指标可以解决样本值呈指数增长的情况。

- R方值，确定系数（ R² score, the coefficient of determination）：

.. math::
    R^2(y, \hat{y}) = 1 - \frac{\sum_{i=0}^{n_{samples}-1}(y_i - \hat{y_i})^2}{\sum_{i=0}^{n_{samples}-1}(y_i - \overline{y})^2}  \tag{7}

上式中 :math:`\hat{y}` 是样本预测值， y是样本真实值。该指标用来度量未来的样本是否可能通过模型被很好地预测。

- AIC（Akaike information criterion）：

.. math::
    AIC = 2ln(f(y|\theta_k)) - 2K \tag{8}

上式中前半部分为似然值，后半部分K表示模型参数个数，该指标用来选择似然值高且模型参数较少的模型，降低模型的结构风险，降低过拟合风险。

- BIC（Bayesian information criterion）：

.. math::
    BIC = 2ln(f(y|\theta_k)) - Klog(n) \tag{9}

上式中前半部分为似然值，后半部分K表示模型参数个数，n表示模型训练数据量，该指标用来选择似然值高且模型参数较少的模型，降低模型的结构风险，降低过拟合风险，同时解决AIC在数据量大时倾向于选择复杂模型的缺点。

3. 聚类问题

聚类性能的评估（度量）分为两大类：

- 外部评估（external evaluation）：将结果与某个“参考模型”（reference model）进行比较；

- 内部评估（internal evaluation）：直接考虑聚类结果而不利用任何参考模型。

3.1 外部评估

对有n个元素的数据集 D={x1,x2,⋯,xn}

假定聚类结果： X={X1,X2,⋯,Xn}

假定参考结果： Y={Y1,Y2,⋯,Yn}

C是数据的参考类别集合，K是聚类结果的类别集合。

那么将样本两两配对得：

a=|SS|, 如果一对样本（xi,xj）的聚类类别是相同的且存在于C中，同时满足（xi,xj）的参考类别是相同的，且存在于K中，则+1；

b=|SD|, 如果一对样本（xi,xj）的聚类类别是相同的且存在于C中，同时满足（xi,xj）的参考类别是不同的，且存在于K中，则+1；

c=|DS|, 如果一对样本（xi,xj）的聚类类别是不同的且存在于C中，同时满足（xi,xj）的参考类别是相同的，且存在于K中，则+1；

d=|DD|, 如果一对样本（xi,xj）的聚类类别是不同的且存在于C中，同时满足（xi,xj）的参考类别是不同的，且存在于K中，则+1；

那么所有配对的总数，即集合中可以组成样本对的对数为：

a+b+c+d=n(n−1)/2

- 兰德指数（Rand index）：

.. math::
    RI = \frac{a+d}{C_{2}^{n_{samples}}} \tag{1}

然而上式并没有保证随机猜测的RI值接近零，特殊情况：若类别数同样本数量在一个数量级下，则 :math:`2d\approx{n(n-1)}` 。
为了解决上述情况，减去随机猜测的RI期望（E(RI)），定义调整兰德指数（Adjusted Rand index）如下：

.. math::
    ARI = \frac{RI-E(RI)}{max(RI)-E(RI)} \tag{2}

- 调整互信息（Adjusted Mutual Information：AMI）：

.. math::
    H(C) = -\sum_{i=1}^{|C|} P(i)logP(i) \tag{3}

上式中 :math:`P(i)` 代表了类别标签为i的样本占总样本的比例，同样形式可定义H(K)：

.. math::
    H(K) = -\sum_{j=1}^{|K|} P(j)logP(j) \tag{4}

则C与K的互信息MI可定义如下：

.. math::
    MI(C,K) = \sum_{i=1}^{|C|} \sum_{j=1}^{|K|} P(i,j) log(\frac{p(i,j)}{p(i)p(j)}) \tag{5}

标准化MI定义如下：

.. math::
    NMI(C,K) = \frac{MI(C,K)}{mean(H(C),H(K))} \tag{6}

在样本类别数量增加时，更倾向与获得较大的MI、NMI，因此定义调整互信息（adjusted mutual information）公式如下：

.. math::
    AMI = \frac{MI-E(MI)}{mean(H(C), H(K))-E(MI)} \tag{7}

.. math::
    E[MI(C,K)] = \sum_{i=1}^{|C|} \sum_{j=1}^{|K|} \sum_{n_{ij}=(a_i+b_j-N)}^{min(a_i,b_j)}
    \frac{n_{ij}}{N} log(\frac{Nn_{ij}}{a_ib_j}) \frac{a_i!b_j!(N-a_i)!(N-b_j)!}{N!n_{ij}!(a_i-n_{ij})!(b_j-n_{ij})!(N-a_i-b_j+n_{ij})!} \tag{8}


- 同质性（Homogeneity），完整性（Completeness） and 同质性-完整性调和系数（V-measure）：

同质性（Homogeneity）描述的是一个簇是只包含一个类别的样本，可近似理解为precision，定义如下：

.. math::
    h = 1-\frac{H(C|K)}{H(C)} \tag{9}

完整性（Completeness）同类别样本被归类到相同簇中，可近似理解为recall，定义如下：

.. math::
    c = 1-\frac{H(K|C)}{H(K)} \tag{10}

其中条件熵定义如下：

.. math::
    H(C|K) = -\sum_{c=1}^{|C|} \sum_{k=1}^{|K|} p(c,k) log(p(c|k)) \tag{11}

同质性-完整性调和系数（V-measure）可理解为F1调和系数：

.. math::
    v = 2·\frac{c·h}{c+h} \tag{12}

- Fowlkes-Mallows index（FMI）:

FMI是precision和recall的调和系数，定义如下：

.. math::
    FMI = \sqrt{P·R} \tag{13}

但是precision与recall的定义较二分类不同，precision定义为：真实标签相同的数据对，同样具有相同预测标签占真实标签相同的数据对的比例，
recall定义为：真实标签相同的数据对，同样具有相同预测标签占预测标签相同的数据对的比例。

3.2 内部评估

对有n个元素的数据集 D={x1,x2,⋯,xn}

假定聚类结果： X={X1,X2,⋯,Xn}，不存在参考结果，则需要通过模型本身进行效果评估。以下是三种常用内部评估方法。

- 轮廓系数（Silhouette coefficient）：

轮廓系数（Silhouette coefficient）是对每一个样本点计算一个值，由以下两个数值组成:

a: 该点与同类别中的其他样本点的平均距离。

b: 该点到与其最近的类别中的所有样本点的平均距离。

.. math::
    s = \frac{b-a}{max(a,b)} \tag{14}

整体的轮廓系数用每个样本轮廓系数的均值表示，该值越大越好。

- CH（Calinski-Harabaz）：

类内散度：

.. math::
    W_k = \sum_{q=1}^{k} \sum_{x \in C_q} (x-c_q)(x-c_q)^T \tag{15}

其中 :math:`C_q` 是类q的样本集，:math:`c_q` 是类q的样本中心。

类间散度：

.. math::
    B_k = \sum_q n_q(c_q-c)(c_q-c)^T \tag{16}

其中 :math:`n_q` 是类q的样本集数量，:math:`c` 是整个数据集的样本中心。

CH：

.. math::
    s(k) = \frac{Tr(B_k)}{Tr(W_k)}*\frac{N-k}{k-1} \tag{17}

其中 :math:`N` 整个样本集的样本数量。

- DBI（Davies-Bouldin Index）：

该指标是评估两个类（i，j）的相似性，定义如下：

.. math::
    R_(ij) = \frac{s_i+s_j}{d_{ij}} \tag{18}

其中 :math:`s_i` 表示类i的直径（类内样本与类中心的平均距离）， :math:`d_{ij}` 表示（i，j）两类中心点的距离。

所以整个样本集的DBI表示如下：

.. math::
    DB = \frac{1}{k} \sum_{i=1}^{k} max_{i \ne j}R_{ij} \tag{19}

该值越接近零越好。


应用场景评估指标的选择
========================

1. 推荐系统

- 准确性指标

a) 对于商品推荐这类二值情况（喜欢、不喜欢）等，可以采用传统的二分类指标：precision、recall等；

b) 对于电影评分这类数值场景，可以采用回归这类评估指标：RMSE、MAE等；

- 非准确性指标

a) 覆盖率：覆盖率测量的是推荐系统推荐给所有用户的物品数占总物品数的比例

b) 整体多样性：利用用户的推荐列表间的重叠度来定义整体多样性

c) 个体多样性：用户的推荐列表列内的所有物品的平均相似度

d) 新颖性: 计算推荐列表中物品的平均流行度


2. 语音识别

- 词错误率(WER：Word Error Rate):

对于一段正确文本T，我们识别出的文本为R，则词错误率定义如下：

.. math::
    WER = \frac{I+S+D}{N} \tag{1}

其中I、S、D表示从R转换为T需要经过I次增加词、S次替换词、D次删除词操作，N为T的文本长度。

- 句错误率（SER：Sentence Error Rate）：

计算方式：若句子中如果有一个词识别错误，那么这个句子被认为识别错误，最后句子识别错误的的个数，除以总的句子个数即为SER。

3. CTR(点击率)预估

- Loss计算

使用KL散度，又称作相对熵，KL散度的物理意义是：使用分布Q来对真实分布为P的事件进行编码，导致平均编码长度增加了多少。通俗理解为相同事件空间里两个概率分布的相异情况。KL散度越小，预测分布越接近真实分布。

设真实的点击率是tctr，预测的点击率是pctr。因此真实的二项分布P是（tctr,1-tctr），预测的二项分布Q是(pctr,1-pctr)。因此KL散度公式可以写成如下：KL散度定义如下：

.. math::
    KL(tctr||pctr) = tctr·log(\frac{tctr}{pctr}) + (1-tctr)·log(\frac{1-tctr}{1-pctr}) \tag{2}

- 二分类常用指标

precision、recall、auc等。

4. 信息检索

- 无序信息检索

不考虑返回结果的位置信息。

a) 准确率（Precision）是返回的结果中相关文档所占的比例。

b) 召回率（Recall）是返回的相关文档占所有相关文档的比例。

c) F1值

- 有序信息检索

考虑返回结果的位置信息。

a) MAP

对于单个查询AveP（平均准确率）定义如下：

.. math::
    AveP = \frac{1}{R} \sum_{i=1}^R \frac{i}{position(i)} \tag{3}

其中R是返回结果中相关文档的个数，position(i)是每个相关文档在返回结果中的位置。

对于对组查询来讲，可得MAP（mean of AveP）：

.. math::
    MAP = \frac{\sum_{i=1}^Q Avep(i)}{Q} \tag{4}

其中Q为查询语句的数量。

b) nDCG

- DCG

.. math::
    DCG_p = \sum_{i=1}^P \frac{2^{rel_i}-1}{log_2(i+1)} \tag{5}

其中 :math:`rel_i` 为排名为i的文档的相关度评分。

- Ideal DCG(IDCG)：

IDCG是理想情况下的DCG，即对于一个查询语句和p来说，DCG的最大值。公式如下：

.. math::
    IDCG_p = \sum_{i=1}^{|REL|} \frac{2^{rel_i}-1}{log_2(i+1)} \tag{6}

其中 :math:`|REL|` 表示将文档按照相关性从大到小的顺序排序，取前p个文档组成的集合。也就是按照最优的方式对文档进行排序。

- Normalize DCG(nDCG)：

由于每个查询语句所能检索到的结果文档集合长度不一，p值的不同会对DCG的计算有较大的影响。
所以不能对不同查询语句的DCG进行求平均，需要进行归一化处理。nDCG就是用IDCG进行归一化处理，公式如下：

.. math::
    nDCG_p = \frac{DCG_p}{IDCG_p} \tag{7}




