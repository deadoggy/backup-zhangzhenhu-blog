.. _ch_Imagen:


########################################################
Imagen
########################################################



待补充





Imagen展示了冻结的大型预训练语言模型作为使用扩散模型生成文本到图像的文本编码器的有效性。
我们观察到，缩放这些语言模型的大小比缩放U-Net大小对整体性能的影响要大得多，
这鼓励了未来探索更大的语言模型作为文本编码器的研究方向。
此外，通过Imagen，我们再次强调了无分类器引导的重要性，并引入了动态阈值，这允许使用比以前工作中看到的高得多的引导权重。
有了这些新颖的组件，Imagen产生了1024×1024个样本，具有前所未有的真实感和与文本的对齐 :footcite:`imagen` 。